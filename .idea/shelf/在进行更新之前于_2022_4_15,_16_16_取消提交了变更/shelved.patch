Index: model_Sept/Dual_Adarnn.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2022 Apple, Inc. All Rights Reserved \n#\n# @Time    : 2022/4/12 11:03\n# @Author  : SeptKing\n# @Email   : WJH0923@mail.dlut.edu.cn\n# @File    : Dual_Adarnn.py\n# @Software: PyCharm\nimport torch\nimport torch.nn as nn\nimport random\nfrom loss.nloss_transfer import TransferLoss\nimport torch.nn.functional as F\nimport numpy as np\nfrom untils.support import numpy_to_tvar\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\nclass Dual_Adarnn(nn.Module):\n    def __init__(self, share_encoder, decoder,output_dim,len_seq, device):\n        super(Dual_Adarnn, self).__init__()\n        self.share_encoder = share_encoder\n        self.decoder = decoder\n        self.device = device\n        self.output_dim = output_dim\n        self.len_seq = len_seq\n        self.device = device\n\n    def for_custom_pre(self, src_left, src_right, trg, teacher_forcing_ratio, len_win=0):\n\n        batch_size = src_left.shape[1]  ##应该就是正常的batch_size\n        max_len = trg.shape[0]  ##需要预测的长度6\n        outputs = torch.zeros(max_len, batch_size,\n                              self.output_dim).to(device)  ##(6,2,1)\n\n        ##注意力状态\n        decoder_att = torch.zeros(max_len, batch_size,\n                                  self.len_seq * 2).to(device)  ##可以是(6,2,10)\n        ##双向输入且具有分布学习的编码层\n        encoder_outputs_left, encoder_outputs_right, out_weight_list_before, out_weight_list_after, hidden, hidden_decoder, loss_transfer = self.share_encoder.forward_pre_train(\n            src_left, src_right, len_win)  ##（12，2，128）,hidden(2,2,64)##10，2，16，10，2，16\n\n        ##选取最后一个时间节点的y\n        output = src_left[-1, :, 2]  ##选取的是最后一个时间节点的第一个元素\n\n        for t in range(0, max_len):\n            output, hidden, attn_weight = self.decoder(output, hidden, hidden_decoder,\n                                                       encoder_outputs_left,\n                                                       encoder_outputs_right)  ##返回的output是[ys,yt],hidden是(1,2,64),a是(2,64)\n            decoder_att[t] = attn_weight.squeeze()\n            outputs[t] = output.unsqueeze(1)\n            teacher_force = random.random() < teacher_forcing_ratio\n            output = (trg[t].view(-1) if teacher_force else output)  ##下一步的输入是output还是目标output\n\n        output_all = outputs.permute(1, 0, 2)  ##2,6,1\n        output_s = output_all[0:output_all.size(0) // 2]  ##1,6,1\n        output_t = output_all[output_all.size(0) // 2:]\n        # output_s = output_s.permute(1, 0, 2)\n        # output_t = output_t.permute(1, 0, 2)\n\n        return output_s, output_t, out_weight_list_before, out_weight_list_after, decoder_att, loss_transfer\n\n    def for_Boosting(self, src_left, src_right, trg, teacher_forcing_ratio=0.5, weight_mat_before=None,\n                     weight_mat_after=None):\n        batch_size = src_left.shape[1]  ##应该就是正常的batch_size\n        max_len = trg.shape[0]  ##需要预测的长度6\n        outputs = torch.zeros(max_len, batch_size,\n                              self.output_dim).to(device)  ##(6,2,1)\n\n        ##注意力状态\n        decoder_att = torch.zeros(max_len, batch_size,\n                                  self.len_seq * 2).to(device)  ##可以是(6,2,12)\n        ##双向输入且具有分布学习的编码层\n        encoder_outputs_left, encoder_outputs_right, weight_before, weight_after, hidden, hidden_decoder, loss_transfer, dist_mat_before, dist_mat_after = self.share_encoder.forward_boosting(\n            src_left, src_right, weight_mat_before, weight_mat_after)  ##（12，2，128）,hidden(2,2,64)\n        ##选取最后一个时间节点的y\n        output = src_left[-1, :, 2]  ##选取的是最后一个时间节点的第一个元素\n\n        for t in range(0, max_len):\n            output, hidden, attn_weight = self.decoder(output, hidden, hidden_decoder,\n                                                       encoder_outputs_left,\n                                                       encoder_outputs_right)  ##返回的output是[ys,yt],hidden是(1,2,64),a是(2,64)\n            decoder_att[t] = attn_weight.squeeze()\n            outputs[t] = output.unsqueeze(1)\n            teacher_force = random.random() < teacher_forcing_ratio\n            output = (trg[t].view(-1) if teacher_force else output)  ##下一步的输入是output还是目标output\n\n        output_all = outputs.permute(1, 0, 2)  ##2,6,1\n        output_s = output_all[0:output_all.size(0) // 2]  ##1,6,1\n        output_t = output_all[output_all.size(0) // 2:]\n        # output_s = output_s.permute(1, 0, 2)\n        # output_t = output_t.permute(1, 0, 2)\n\n        return output_s, output_t, decoder_att, loss_transfer, dist_mat_before, dist_mat_after, weight_before, weight_after\n\n    def update_weight_Boosting(self, weight_mat_before, dist_old_before, dist_new_before, weight_mat_after,\n                               dist_old_after, dist_new_after):\n        epsilon = 1e-5\n        ##左端\n        dist_old_before = dist_old_before.detach()\n        dist_new_before = dist_new_before.detach()\n        ind = dist_new_before > dist_old_before + epsilon\n        weight_mat_before[ind] = weight_mat_before[ind] * \\\n                                 (1 + torch.sigmoid(dist_new_before[ind] - dist_old_before[ind]))\n\n        weight_norm_b = torch.norm(weight_mat_before, dim=1, p=1)\n        weight_mat_before = weight_mat_before / weight_norm_b.t().unsqueeze(1).repeat(1, self.len_seq)\n        ##右端\n        dist_old_after = dist_old_after.detach()\n        dist_new_after = dist_new_after.detach()\n        ind = dist_new_after > dist_old_after + epsilon\n        weight_mat_after[ind] = weight_mat_after[ind] * \\\n                                (1 + torch.sigmoid(dist_new_after[ind] - dist_old_after[ind]))\n\n        weight_norm_a = torch.norm(weight_mat_after, dim=1, p=1)\n        weight_mat_after = weight_mat_after / weight_norm_a.t().unsqueeze(1).repeat(1, self.len_seq)\n\n        return weight_mat_before, weight_mat_after\n\n    def predict_ts(self, src_left, src_right, trg, teacher_forcing_ratio=0.5):\n        tst_left = src_left.permute(1, 0, 2)\n        tst_right = src_right.permute(1, 0, 2)\n        tst_trg = trg.permute(1, 0, 2)\n        batch_size = tst_left.shape[1]  ##应该就是正常的batch_size\n        max_len = tst_trg.shape[0]  ##需要预测的长度6\n        outputs = torch.zeros(max_len, batch_size,\n                              self.output_dim).to(self.device)  ##(6,2,1)\n        decoder_att = torch.zeros(max_len, batch_size,\n                                  self.len_seq * 2).to(self.device)  ##可以是(6,2,12)\n        encoder_outputs_left, encoder_outputs_right, hidden, hidden_decoder = self.share_encoder.predict(\n            tst_left, tst_right)\n        output = tst_left[-1, :, 2]  ##选取的是最后一个时间节点的第一个元素\n        for t in range(0, max_len):\n            output, hidden, attn_weight = self.decoder(output, hidden, hidden_decoder,\n                                                       encoder_outputs_left,\n                                                       encoder_outputs_right)  ##返回的output是[ys,yt],hidden是(1,2,64),a是(2,64)\n            decoder_att[t] = attn_weight.squeeze()\n            outputs[t] = output.unsqueeze(1)\n            teacher_force = random.random() < teacher_forcing_ratio\n            output = (tst_trg[t].view(-1) if teacher_force else output)  ##下一步的输入是output还是目标output\n\n        output_all = outputs.permute(1, 0, 2)  ##1,6,1\n        # output_all = output_all.permute(1, 0, 2)\n        # output_all = output_all.squeeze()\n        return output_all, decoder_att\n\n\nclass Share_Encoder(nn.Module):\n    def __init__(self, n_input=128, n_hiddens=[64,64], dec_layers=1,dropout=0.1, len_seq=10, model_type='DualAdarnn',\n                 trans_loss='mmd'):\n        super(Share_Encoder, self).__init__()\n        self.n_input = n_input\n        self.num_layers = len(n_hiddens)  ##2\n        self.model_type = model_type\n        self.trans_loss = trans_loss\n        self.len_seq = len_seq  ##序列长度\n        self.dropout = dropout\n        self.hiddens = n_hiddens\n        self.enc_hid_dim = n_hiddens[0]\n        self.dec_hid_dim = n_hiddens[0]\n        self.dec_layers = dec_layers\n        ##新增了输入的全联接\n        self.input_linear = nn.Linear(self.n_input, self.enc_hid_dim)\n        in_size_l = self.enc_hid_dim  ##输入要的维度\n        in_size_r = self.enc_hid_dim\n\n        features_left = nn.ModuleList()\n        for hidden in n_hiddens:\n            rnn_l = nn.GRU(input_size=in_size_l,\n                           num_layers=1,\n                           hidden_size=hidden,\n                           bidirectional=True,\n                           )\n            features_left.append(rnn_l)\n            in_size_l = hidden * 2\n        self.features_left = nn.Sequential(*features_left)\n\n        features_right = nn.ModuleList()\n        for hidden in n_hiddens:\n            rnn_r = nn.GRU(input_size=in_size_r,\n                           num_layers=1,\n                           hidden_size=hidden,\n                           bidirectional=True,\n                           )\n            features_right.append(rnn_r)\n            in_size_r = hidden * 2\n        self.features_right = nn.Sequential(*features_right)\n\n        self.output_linear_left = nn.Linear(self.enc_hid_dim * 2,\n                                            self.dec_hid_dim)  ##128,64\n        self.output_linear_right = nn.Linear(self.enc_hid_dim * 2,\n                                             self.dec_hid_dim)  ##128,64\n        self.dropout = nn.Dropout(self.dropout)\n\n        if self.model_type == 'DualAdarnn':\n            gate = nn.ModuleList()\n            for i in range(len(n_hiddens)):\n                gate_weight = nn.Linear(\n                    len_seq * self.hiddens[i] * 4, len_seq)\n                gate.append(gate_weight)\n            self.gate = gate\n\n            bnlst = nn.ModuleList()\n            for i in range(len(n_hiddens)):\n                bnlst.append(nn.BatchNorm1d(len_seq))\n\n            self.bn_lst = bnlst\n            self.softmax = torch.nn.Softmax(dim=0)\n            self.init_layers()\n\n    def init_layers(self):\n        for i in range(len(self.hiddens)):\n            self.gate[i].weight.data.normal_(0, 0.05)\n            self.gate[i].bias.data.fill_(0.0)\n\n\n    ##假设batch = 1的话，input_before表示的是[24,2,16]这里12表示的是一个batch的seq\n\n    def forward_pre_train(self, input_before, input_after, len_win=0):\n\n        ##左侧输入以及迁移权重计算\n        input_l = self.input_linear(input_before)\n        outputs_before, hidden_before, out_lis_before, out_weight_list_before = self.gru_features_left(input_l)\n        ##通过cat将hidden中前向和后向的部分拼接在一起(2,128)2表示的是batch,然后通过线性变换形成(2,64),最后通过tanh激活函数进行调整为(-1,1)之间\n        hidden_before = torch.tanh(\n            self.output_linear_left(\n                torch.cat((hidden_before[-2, :, :], hidden_before[-1, :, :]),\n                          dim=1)))\n\n        input_r = self.input_linear(input_after)\n        outputs_after, hidden_after, out_lis_after, out_weight_list_after = self.gru_features_right(input_r)\n        hidden_after = torch.tanh(\n            self.output_linear_right(\n                torch.cat((hidden_after[-2, :, :], hidden_after[-1, :, :]),\n                          dim=1)))\n\n        ##我们只使用前向输入的hidden来初始化gru\n        hidden_decoder_l = hidden_before.repeat(self.dec_layers, 1, 1)  ##(1,2,64)\n        hidden_decoder_r = hidden_after.repeat(self.dec_layers, 1, 1)\n        hidden_decoder = torch.cat((hidden_decoder_l,hidden_decoder_r),dim=0)\n\n        ##计算迁移损失\n        out_lis_before_s, out_lis_before_t = self.get_features(out_lis_before)\n        loss_transfer_before = torch.zeros((1,)).to(device)\n        for i in range(len(out_lis_before_s)):  ##长度为2\n            criterion_transder = TransferLoss(\n                loss_type=self.trans_loss, input_dim=out_lis_before_s[i].shape[2])  ##输入维度为64\n            h_start = 0\n            for j in range(h_start, self.len_seq, 1):  ##从1到12每次增加1\n                i_start = j - len_win if j - len_win >= 0 else 0  ##0\n                i_end = j + len_win if j + len_win < self.len_seq else self.len_seq - 1  ##0\n                for k in range(i_start, i_end + 1):\n                    weight = out_weight_list_before[i][j] if self.model_type == 'DualAdaRNN' else 1 / (\n                            self.len_seq - h_start) * (2 * len_win + 1)\n                    loss_transfer_before = loss_transfer_before + weight * criterion_transder.compute(\n                        out_lis_before_s[i][:, j, :], out_lis_before_t[i][:, k, :])\n        ##计算右端输入transfter\n        out_lis_after_s, out_lis_after_t = self.get_features(out_lis_after)\n        loss_transfer_after = torch.zeros((1,)).to(device)\n        for i in range(len(out_lis_after_s)):  ##长度为2\n            criterion_transder = TransferLoss(\n                loss_type=self.trans_loss, input_dim=out_lis_after_s[i].shape[2])  ##输入维度为64\n            h_start = 0\n            for j in range(h_start, self.len_seq, 1):  ##从1到24每次增加1\n                i_start = j - len_win if j - len_win >= 0 else 0  ##0\n                i_end = j + len_win if j + len_win < self.len_seq else self.len_seq - 1  ##0\n                for k in range(i_start, i_end + 1):\n                    weight = out_weight_list_after[i][j] if self.model_type == 'DualAdaRNN' else 1 / (\n                            self.len_seq - h_start) * (2 * len_win + 1)\n                    loss_transfer_after = loss_transfer_after + weight * criterion_transder.compute(\n                        out_lis_before_s[i][:, j, :], out_lis_before_t[i][:, k, :])\n        loss_transfer = loss_transfer_before + loss_transfer_after\n\n        return outputs_before, outputs_after, out_weight_list_before, out_weight_list_after, hidden_decoder_l,hidden_decoder, loss_transfer\n\n    def predict(self, input_before, input_after):\n        input_bp = self.input_linear(input_before)\n        outputs_before, hidden_before, out_lis_before, out_weight_list_before = self.gru_features_left(input_bp,predict=True)\n        hidden_before = torch.tanh(\n            self.output_linear_left(\n                torch.cat((hidden_before[-2, :, :], hidden_before[-1, :, :]),\n                          dim=1)))\n\n        input_ap = self.input_linear(input_after)\n        outputs_after, hidden_after, out_lis_after, out_weight_list_after = self.gru_features_right(input_ap,predict=True)\n\n        hidden_decoder_l = hidden_before.repeat(self.dec_layers, 1, 1)  ##(1,2,64)\n        hidden_decoder_r = hidden_after.repeat(self.dec_layers, 1, 1)\n        hidden_decoder = torch.cat((hidden_decoder_l, hidden_decoder_r), dim=0)\n\n        return outputs_before, outputs_after, hidden_decoder_l, hidden_decoder\n\n    def forward_boosting(self, input_before, input_after, weight_mat_before=None, weight_mat_after=None):\n        ##左侧输入以及迁移权重计算\n        ##(10,4,128),(2,4,64),[(4,10,128),(4,10,128)],[(10),(10)]\n        input_l = self.input_linear(input_before)\n        outputs_before, hidden_before, out_lis_before, out_weight_list_before = self.gru_features_left(input_l)\n\n        ##通过cat将hidden中前向和后向的部分拼接在一起(2,128)2表示的是batch,然后通过线性变换形成(2,64),最后通过tanh激活函数进行调整为(-1,1)之间\n        hidden_before = torch.tanh(\n            self.output_linear_left(\n                torch.cat((hidden_before[-2, :, :], hidden_before[-1, :, :]),\n                          dim=1)))\n\n        input_r = self.input_linear(input_after)\n        outputs_after, hidden_after, out_lis_after, out_weight_list_after = self.gru_features_right(input_r)\n        hidden_after = torch.tanh(\n            self.output_linear_right(\n                torch.cat((hidden_after[-2, :, :], hidden_after[-1, :, :]),\n                          dim=1)))\n\n        ##我们只使用前向输入的hidden来初始化gru\n        hidden_decoder_l = hidden_before.repeat(self.dec_layers, 1, 1)  ##(1,2,64)\n        hidden_decoder_r = hidden_after.repeat(self.dec_layers, 1, 1)\n        hidden_decoder = torch.cat((hidden_decoder_l, hidden_decoder_r), dim=0)\n\n        ##计算迁移损失\n        out_lis_before_s, out_lis_before_t = self.get_features(out_lis_before)\n        loss_transfer_before = torch.zeros((1,)).to(device)\n        if weight_mat_before is None:\n            weight_before = (1.0 / self.len_seq *\n                             torch.ones(self.num_layers, self.len_seq)).to(device)\n        else:\n            weight_before = weight_mat_before\n\n        dist_mat_before = torch.zeros(self.num_layers, self.len_seq).to(device)\n        for i in range(len(out_lis_before_s)):\n            criterion_transder = TransferLoss(\n                loss_type=self.trans_loss, input_dim=out_lis_before_s[i].shape[2])\n            for j in range(self.len_seq):\n                loss_trans_before = criterion_transder.compute(\n                    out_lis_before_s[i][:, j, :], out_lis_before_t[i][:, j, :])\n                loss_transfer_before = loss_transfer_before + weight_before[i, j] * loss_trans_before\n                dist_mat_before[i, j] = loss_trans_before\n\n        ##计算右侧\n        out_lis_after_s, out_lis_after_t = self.get_features(out_lis_after)\n        loss_transfer_after = torch.zeros((1,)).to(device)\n        if weight_mat_after is None:\n            weight_after = (1.0 / self.len_seq *\n                            torch.ones(self.num_layers, self.len_seq)).to(device)\n        else:\n            weight_after = weight_mat_after\n\n        dist_mat_after = torch.zeros(self.num_layers, self.len_seq).to(device)\n        for i in range(len(out_lis_after_s)):\n            criterion_transder = TransferLoss(\n                loss_type=self.trans_loss, input_dim=out_lis_after_s[i].shape[2])\n            for j in range(self.len_seq):\n                loss_trans_after = criterion_transder.compute(\n                    out_lis_after_s[i][:, j, :], out_lis_after_t[i][:, j, :])\n                loss_transfer_after = loss_transfer_after + weight_after[i, j] * loss_trans_after\n                dist_mat_after[i, j] = loss_trans_after\n        loss_transfer = loss_transfer_before + loss_transfer_after\n        return outputs_before, outputs_after, weight_before, weight_after, hidden_decoder_l,hidden_decoder, loss_transfer, dist_mat_before, dist_mat_after\n\n    def gru_features_left(self, x, predict=False):\n        x_input = x\n        out = None\n        hidden = None\n        out_lis = []\n\n        out_weight_list = [] if (self.model_type == 'DualAdarnn') else None\n\n        for i in range(self.num_layers):\n            ##这里面输出是(10,2,128),hidden的构成是(2,2,64)\n            out, hidden = self.features_left[i](x_input.float())\n            x_input = out\n            out_l = out.permute(1, 0, 2)  ##将输出恢复到(batch_size,leq,dim)上\n            out_lis.append(out_l)\n\n            if self.model_type == 'DualAdarnn' and predict == False:\n                ##将输出调整回(batch,seq,dim)为计算transformloss作准备(2,12,128)\n                x_input_m = x_input.permute(1, 0, 2)\n                out_gate = self.process_gate_weight(x_input_m, i)\n                out_weight_list.append(out_gate)\n        return out, hidden, out_lis, out_weight_list\n\n    def gru_features_right(self, x, predict=False):\n        x_input = x\n        out = None\n        hidden = None\n        out_lis = []\n        out_weight_list = [] if (self.model_type == 'DualAdarnn') else None\n        for i in range(self.num_layers):\n            out, hidden = self.features_right[i](x_input.float())\n            x_input = out\n            out_l = out.permute(1, 0, 2)  ##将输出恢复到(batch_size,leq,dim)上\n            out_lis.append(out_l)\n\n            if self.model_type == 'DualAdarnn' and predict == False:\n                x_input_m = x_input.permute(1, 0, 2)\n                out_gate = self.process_gate_weight(x_input_m, i)\n                out_weight_list.append(out_gate)\n\n        return out, hidden, out_lis, out_weight_list\n    ##计算迁移权重\n    def process_gate_weight(self, out, index):\n        x_s = out[0: int(out.shape[0] // 2)]\n        x_t = out[out.shape[0] // 2: out.shape[0]]\n        x_all = torch.cat((x_s, x_t), 2)  ##这部分的维度是1，10，128*2\n        x_all = x_all.view(x_all.shape[0], -1)  ##维度已经调整（1，10*128*2）\n        weight = self.gate[index](x_all.float())\n        weight = self.bn_lst[index](weight)\n        weight = torch.sigmoid(weight)  ##将双向gru输出的结果通过线性层转化为(1,10),然后通过bn_lst进行归一化然后通过sigmoid进行进一步处理\n        weight = torch.mean(weight, dim=0)  # 对权重在batch_size层面上求均值\n        res = self.softmax(weight).squeeze()  ##通过softmax求的权重和为1得到12个小时的不同维度\n        return res\n\n    def get_features(self, output_list):\n        fea_lis_src, fea_list_tar = [], []\n        for fea in output_list:\n            fea_lis_src.append(fea[0:fea.size(0) // 2])\n            fea_list_tar.append(fea[fea.size(0) // 2:])\n\n        return fea_lis_src, fea_list_tar\n\nclass Cross_Attention(nn.Module):\n    def __init__(self, n_hiddens):\n        super(Cross_Attention, self).__init__()\n\n        self.enc_hid_dim = n_hiddens[0]  # 50\n        self.dec_hid_dim = n_hiddens[0]  # 50\n\n        self.attn = nn.Linear(self.enc_hid_dim * 2 + self.dec_hid_dim,\n                              self.dec_hid_dim)  ##(64*3,64)\n        self.v = nn.Parameter(torch.rand(self.dec_hid_dim))  ##随机创建64个变量\n\n    ##hidden的dim为(1,2,64),输入是(24,2,128)\n\n    def forward(self, hidden, encoder_outputs):\n        batch_size = encoder_outputs.shape[1]  ##2\n        src_len = encoder_outputs.shape[0]  ##20\n\n        # only pick up last layer hidden from decoder\n        hidden = torch.unbind(hidden, dim=0)[0]  ##只取最近层的hidden信息,是按照维度做切片,(2,64)\n\n        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)  ##2,24,64\n\n        encoder_outputs = encoder_outputs.permute(1, 0, 2)  ##2,24,128\n\n        energy = torch.tanh(\n            self.attn(torch.cat((hidden, encoder_outputs),\n                                dim=2)))  ##主要操作是将hidden的一维向量重复24次作为上一阶段的状态s，然后与h粘贴生成（(2,24,64*3)通过全联接生成(2,24,64)\n\n        energy = energy.permute(0, 2, 1)  ##选取20行的各个特征维度进行重构形成(2,64,24)\n\n        v = self.v.repeat(batch_size, 1).unsqueeze(1)\n\n        attention = torch.bmm(v, energy).squeeze(1)  ##生成（b,n,d）(2,24)\n\n        return F.softmax(attention, dim=1)\n\n\nclass Decoder(nn.Module):\n    def __init__(self, output_dim, n_hiddens, dec_layers, dropout, attention):  ##1,60,60,1\n        super(Decoder, self).__init__()\n\n        self.enc_hid_dim = n_hiddens[0]\n        self.dec_hid_dim = n_hiddens[0]\n        self.output_dim = output_dim\n        self.dec_layers = dec_layers\n        self.dropout = dropout\n        self.attention = attention\n        self.input_dec = nn.Linear(self.output_dim, self.dec_hid_dim)\n        self.gru = nn.GRU(input_size=self.enc_hid_dim * 2 + self.dec_hid_dim,\n                          hidden_size=self.dec_hid_dim,\n                          num_layers=self.dec_layers)\n        self.out = nn.Linear(\n            self.enc_hid_dim * 2 + self.dec_hid_dim + self.dec_hid_dim,\n            self.output_dim)\n        self.dropout = nn.Dropout(self.dropout)\n\n    def get_features(self, output_list):\n        fea_list_src, fea_list_tar = [], []\n        for fea in output_list:\n            fea_list_src.append(fea[0: fea.size(0) // 2])\n            fea_list_tar.append(fea[fea.size(0) // 2:])\n\n    ##输入一组y\n\n    def forward(self, input, hidden,hidden_decoder,encoder_outputs_left, encoder_outputs_right):\n        input = input.unsqueeze(0)\n        input = torch.unsqueeze(input, 2)  ##(1,2,1)按照当前的batch有两个y被提取出来\n        embedded = self.dropout(torch.tanh(self.input_dec(input)))  ##(1,2,64)\n        ##将前向的和后向的在0维进行拼接\n        encoder_outputs = torch.cat(\n            (encoder_outputs_left, encoder_outputs_right), dim=0)  ##(20,1,128)\n        a = self.attention(hidden_decoder, encoder_outputs)  ##生成权重a(2，24)输入的hidden是(1,2,64)\n        a = a.unsqueeze(1)  ##(2,1,20)，（4，1，20）\n        encoder_outputs = encoder_outputs.permute(1, 0, 2)  ##(2,20,128)，还原一个batch20h\n\n        weighted = torch.bmm(a, encoder_outputs)  ##(2,1,128)这个就是ct\n        weighted = weighted.permute(1, 0, 2)  ##(1,2,128)\n        gru_input = torch.cat((embedded, weighted), dim=2)  ##(1,2,64*3)将y和ct链接\n        output, hidden = self.gru(gru_input, hidden)  ##OK这里面就是将yt-1，ct，st-1投入的gru里\n\n        input_dec = embedded.squeeze(0)  ##(2,64)\n        output = output.squeeze(0)  ##(2,64)\n        weighted_f = weighted.squeeze(0)  ##(2,128)\n\n\n        output = self.out(torch.cat((output, weighted_f, input_dec), dim=1))  ##(2,1)\n\n        ##返回的output是[ys,yt],hidden是(1,2,64),a是(2,20)\n        return output.squeeze(1), hidden, a.squeeze(1)\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/model_Sept/Dual_Adarnn.py b/model_Sept/Dual_Adarnn.py
--- a/model_Sept/Dual_Adarnn.py	(revision 4d374eb052e73a15d49eb92596cef4473d6d2218)
+++ b/model_Sept/Dual_Adarnn.py	(date 1649934013380)
@@ -44,7 +44,7 @@
             src_left, src_right, len_win)  ##（12，2，128）,hidden(2,2,64)##10，2，16，10，2，16
 
         ##选取最后一个时间节点的y
-        output = src_left[-1, :, 2]  ##选取的是最后一个时间节点的第一个元素
+        output = src_left[-1, :, -1]  ##选取的是最后一个时间节点的第一个元素
 
         for t in range(0, max_len):
             output, hidden, attn_weight = self.decoder(output, hidden, hidden_decoder,
@@ -77,7 +77,7 @@
         encoder_outputs_left, encoder_outputs_right, weight_before, weight_after, hidden, hidden_decoder, loss_transfer, dist_mat_before, dist_mat_after = self.share_encoder.forward_boosting(
             src_left, src_right, weight_mat_before, weight_mat_after)  ##（12，2，128）,hidden(2,2,64)
         ##选取最后一个时间节点的y
-        output = src_left[-1, :, 2]  ##选取的是最后一个时间节点的第一个元素
+        output = src_left[-1, :, -1]  ##选取的是最后一个时间节点的第一个元素
 
         for t in range(0, max_len):
             output, hidden, attn_weight = self.decoder(output, hidden, hidden_decoder,
@@ -132,7 +132,7 @@
                                   self.len_seq * 2).to(self.device)  ##可以是(6,2,12)
         encoder_outputs_left, encoder_outputs_right, hidden, hidden_decoder = self.share_encoder.predict(
             tst_left, tst_right)
-        output = tst_left[-1, :, 2]  ##选取的是最后一个时间节点的第一个元素
+        output = tst_left[-1, :, -1]  ##选取的是最后一个时间节点的第一个元素
         for t in range(0, max_len):
             output, hidden, attn_weight = self.decoder(output, hidden, hidden_decoder,
                                                        encoder_outputs_left,
@@ -253,7 +253,7 @@
                 i_start = j - len_win if j - len_win >= 0 else 0  ##0
                 i_end = j + len_win if j + len_win < self.len_seq else self.len_seq - 1  ##0
                 for k in range(i_start, i_end + 1):
-                    weight = out_weight_list_before[i][j] if self.model_type == 'DualAdaRNN' else 1 / (
+                    weight = out_weight_list_before[i][j] if self.model_type == 'DualAdarnn' else 1 / (
                             self.len_seq - h_start) * (2 * len_win + 1)
                     loss_transfer_before = loss_transfer_before + weight * criterion_transder.compute(
                         out_lis_before_s[i][:, j, :], out_lis_before_t[i][:, k, :])
@@ -268,11 +268,12 @@
                 i_start = j - len_win if j - len_win >= 0 else 0  ##0
                 i_end = j + len_win if j + len_win < self.len_seq else self.len_seq - 1  ##0
                 for k in range(i_start, i_end + 1):
-                    weight = out_weight_list_after[i][j] if self.model_type == 'DualAdaRNN' else 1 / (
+                    weight = out_weight_list_after[i][j] if self.model_type == 'DualAdarnn' else 1 / (
                             self.len_seq - h_start) * (2 * len_win + 1)
                     loss_transfer_after = loss_transfer_after + weight * criterion_transder.compute(
                         out_lis_before_s[i][:, j, :], out_lis_before_t[i][:, k, :])
-        loss_transfer = loss_transfer_before + loss_transfer_after
+        loss_transfer = (loss_transfer_before + loss_transfer_after)/2
+
 
         return outputs_before, outputs_after, out_weight_list_before, out_weight_list_after, hidden_decoder_l,hidden_decoder, loss_transfer
 
Index: outputs_Jintang_DualAdarnn_weather_cosine_5_0.05_0.0005/run.log
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>[2022-04-12 15:02:46] - create model_king...\n[2022-04-12 15:02:46] - Epoch: 0\n[2022-04-12 15:02:46] - training...\n[2022-04-12 15:11:51] - create model_king...\n[2022-04-12 15:11:51] - Epoch: 0\n[2022-04-12 15:11:51] - training...\n[2022-04-12 15:19:49] - create model_king...\n[2022-04-12 15:19:49] - Epoch: 0\n[2022-04-12 15:19:49] - training...\n[2022-04-12 15:23:48] - create model_king...\n[2022-04-12 15:23:48] - Epoch: 0\n[2022-04-12 15:23:48] - training...\n[2022-04-12 15:24:28] - create model_king...\n[2022-04-12 15:24:28] - Epoch: 0\n[2022-04-12 15:24:28] - training...\n[2022-04-12 15:24:51] - create model_king...\n[2022-04-12 15:24:51] - Epoch: 0\n[2022-04-12 15:24:51] - training...\n[2022-04-12 15:26:40] - create model_king...\n[2022-04-12 15:26:40] - Epoch: 0\n[2022-04-12 15:26:40] - training...\n[2022-04-12 15:28:44] - create model_king...\n[2022-04-12 15:28:44] - Epoch: 0\n[2022-04-12 15:28:44] - training...\n[2022-04-12 15:30:24] - create model_king...\n[2022-04-12 15:30:24] - Epoch: 0\n[2022-04-12 15:30:24] - training...\n[2022-04-12 15:31:14] - create model_king...\n[2022-04-12 15:31:14] - Epoch: 0\n[2022-04-12 15:31:14] - training...\n[2022-04-12 15:32:46] - create model_king...\n[2022-04-12 15:32:46] - Epoch: 0\n[2022-04-12 15:32:46] - training...\n[2022-04-12 15:34:42] - create model_king...\n[2022-04-12 15:34:42] - Epoch: 0\n[2022-04-12 15:34:42] - training...\n[2022-04-12 15:34:49] - create model_king...\n[2022-04-12 15:34:49] - Epoch: 0\n[2022-04-12 15:34:49] - training...\n[2022-04-12 15:48:17] - create model_king...\n[2022-04-12 15:52:00] - create model_king...\n[2022-04-12 15:52:14] - create model_king...\n[2022-04-12 15:52:47] - create model_king...\n[2022-04-12 15:52:56] - create model_king...\n[2022-04-12 15:52:56] - Epoch: 0\n[2022-04-12 15:52:56] - training...\n[2022-04-12 15:53:45] - create model_king...\n[2022-04-12 15:53:45] - Epoch: 0\n[2022-04-12 15:53:45] - training...\n[2022-04-12 15:54:05] - [1.71731941e+00 1.97520086e-01 2.58862471e-09] 0.18163611074643476\n[2022-04-12 15:54:05] - evaluating...\n[2022-04-12 15:54:09] - valid_l1 0.166377, test_l1 0.091030\n[2022-04-12 15:54:09] - valid_dtw 0.431440, test_dtw 0.242492\n[2022-04-12 15:54:09] - Epoch: 1\n[2022-04-12 15:54:09] - training...\n[2022-04-12 15:54:28] - [-1.04711218e+00 -1.97649162e-01 -2.13767467e-09] 0.10982194183660406\n[2022-04-12 15:54:28] - evaluating...\n[2022-04-12 15:54:31] - valid_l1 0.114844, test_l1 0.091678\n[2022-04-12 15:54:31] - valid_dtw 0.298686, test_dtw 0.240541\n[2022-04-12 15:54:31] - Epoch: 2\n[2022-04-12 15:54:31] - training...\n[2022-04-12 15:54:50] - [-1.27776392e+00 -1.97178859e-01 -5.92135449e-09] 0.11782952078751155\n[2022-04-12 15:54:50] - evaluating...\n[2022-04-12 15:54:54] - valid_l1 0.111818, test_l1 0.073902\n[2022-04-12 15:54:54] - valid_dtw 0.290375, test_dtw 0.192904\n[2022-04-12 15:54:54] - Epoch: 3\n[2022-04-12 15:54:54] - training...\n[2022-04-12 15:55:14] - [-1.80465850e+00 -2.61204259e-01 -2.13648859e-09] 0.09487929501171623\n[2022-04-12 15:55:14] - evaluating...\n[2022-04-12 15:55:18] - valid_l1 0.112971, test_l1 0.068680\n[2022-04-12 15:55:18] - valid_dtw 0.294987, test_dtw 0.175410\n[2022-04-12 15:55:18] - Epoch: 4\n[2022-04-12 15:55:18] - training...\n[2022-04-12 15:55:36] - [-2.33284904e+00 -3.06956232e-01 -7.24329999e-09] 0.07701409674648728\n[2022-04-12 15:55:36] - evaluating...\n[2022-04-12 15:55:40] - valid_l1 0.082258, test_l1 0.061601\n[2022-04-12 15:55:40] - valid_dtw 0.225062, test_dtw 0.160690\n[2022-04-12 15:55:40] - Epoch: 5\n[2022-04-12 15:55:40] - training...\n[2022-04-12 15:55:59] - [-2.50591376e+00 -2.77809023e-01  8.13549236e-04] 0.08852251951715776\n[2022-04-12 15:55:59] - evaluating...\n[2022-04-12 15:56:02] - valid_l1 0.113390, test_l1 0.078645\n[2022-04-12 15:56:02] - valid_dtw 0.305496, test_dtw 0.201489\n[2022-04-12 15:56:02] - Epoch: 6\n[2022-04-12 15:56:02] - training...\n[2022-04-12 15:56:21] - [-2.80971417e+00 -3.29375952e-01 -4.93774523e-09] 0.06627072500331062\n[2022-04-12 15:56:21] - evaluating...\n[2022-04-12 15:56:25] - valid_l1 0.071731, test_l1 0.070670\n[2022-04-12 15:56:25] - valid_dtw 0.203223, test_dtw 0.181264\n[2022-04-12 15:56:25] - Epoch: 7\n[2022-04-12 15:56:25] - training...\n[2022-04-12 15:56:44] - [-2.38916119e+00 -2.67739772e-01 -4.91159258e-09] 0.08877425713996802\n[2022-04-12 15:56:44] - evaluating...\n[2022-04-12 15:56:48] - valid_l1 0.079856, test_l1 0.054179\n[2022-04-12 15:56:48] - valid_dtw 0.226684, test_dtw 0.142683\n[2022-04-12 15:56:48] - Epoch: 8\n[2022-04-12 15:56:48] - training...\n[2022-04-12 15:57:08] - [-2.82994978e+00 -3.15363859e-01 -2.56946666e-09] 0.07150056984807764\n[2022-04-12 15:57:08] - evaluating...\n[2022-04-12 15:57:13] - valid_l1 0.055335, test_l1 0.047061\n[2022-04-12 15:57:13] - valid_dtw 0.166083, test_dtw 0.124780\n[2022-04-12 15:57:13] - Epoch: 9\n[2022-04-12 15:57:13] - training...\n[2022-04-12 15:57:32] - [-2.79830799e+00 -2.98596014e-01 -2.31514649e-10] 0.08022835797497205\n[2022-04-12 15:57:32] - evaluating...\n[2022-04-12 15:57:36] - valid_l1 0.055370, test_l1 0.051639\n[2022-04-12 15:57:36] - valid_dtw 0.170794, test_dtw 0.135156\n[2022-04-12 15:57:36] - Epoch: 10\n[2022-04-12 15:57:36] - training...\n[2022-04-12 15:57:55] - [-2.49489750e+00 -3.01840787e-01 -3.63010815e-09] 0.07853055825190884\n[2022-04-12 15:57:55] - evaluating...\n[2022-04-12 15:57:59] - valid_l1 0.088603, test_l1 0.060045\n[2022-04-12 15:57:59] - valid_dtw 0.245890, test_dtw 0.156313\n[2022-04-12 15:57:59] - Epoch: 11\n[2022-04-12 15:57:59] - training...\n[2022-04-12 15:58:19] - [-2.80432745e+00 -3.24258998e-01 -6.32281100e-10] 0.06947734033954996\n[2022-04-12 15:58:19] - evaluating...\n[2022-04-12 15:58:24] - valid_l1 0.053135, test_l1 0.040328\n[2022-04-12 15:58:24] - valid_dtw 0.163551, test_dtw 0.107255\n[2022-04-12 15:58:24] - Epoch: 12\n[2022-04-12 15:58:24] - training...\n[2022-04-12 15:58:43] - [-2.82715410e+00 -3.28638318e-01 -5.56852713e-09] 0.06835730653256178\n[2022-04-12 15:58:43] - evaluating...\n[2022-04-12 15:58:47] - valid_l1 0.055285, test_l1 0.051360\n[2022-04-12 15:58:47] - valid_dtw 0.154251, test_dtw 0.131947\n[2022-04-12 15:58:47] - Epoch: 13\n[2022-04-12 15:58:47] - training...\n[2022-04-12 15:59:07] - [-2.52654326e+00 -3.20493711e-01 -8.28435772e-09] 0.06864942663482257\n[2022-04-12 15:59:07] - evaluating...\n[2022-04-12 15:59:11] - valid_l1 0.067972, test_l1 0.045569\n[2022-04-12 15:59:11] - valid_dtw 0.197682, test_dtw 0.119548\n[2022-04-12 15:59:11] - Epoch: 14\n[2022-04-12 15:59:11] - training...\n[2022-04-12 15:59:30] - [-2.88142318e+00 -3.34395899e-01 -4.47094373e-09] 0.06473323104104825\n[2022-04-12 15:59:30] - evaluating...\n[2022-04-12 15:59:34] - valid_l1 0.076377, test_l1 0.057614\n[2022-04-12 15:59:34] - valid_dtw 0.216062, test_dtw 0.148690\n[2022-04-12 15:59:34] - best val score: 0.006192531670852699 @ 12\n[2022-04-12 15:59:34] - inference...\n[2022-04-12 15:59:38] - MSE: train 0.039600, valid 0.006304, test 0.004859\n[2022-04-12 15:59:38] - L1:  train 0.143334, valid 0.054865, test 0.052814\n[2022-04-12 15:59:38] - RMSE: train 0.193078, valid 0.068424, test 0.064598\n[2022-04-12 15:59:38] - DTW: train 0.483899, valid 0.154731, test 0.133569\n[2022-04-12 15:59:38] - TDI: train 0.307971, valid 0.391710, test 0.463721\n[2022-04-12 15:59:38] - Finished.\n[2022-04-12 16:16:47] - create model_king...\n[2022-04-12 16:17:02] - create model_king...\n[2022-04-12 16:17:02] - Epoch: 0\n[2022-04-12 16:17:02] - training...\n[2022-04-12 16:17:23] - [ 6.38998829e+00  7.39349449e-01 -2.55448481e-09] 0.23698111071384378\n[2022-04-12 16:17:23] - evaluating...\n[2022-04-12 16:19:22] - create model_king...\n[2022-04-12 16:19:22] - Epoch: 0\n[2022-04-12 16:19:22] - training...\n[2022-04-12 16:19:44] - [ 6.38998829e+00  7.39349449e-01 -2.55448481e-09] 0.23698111071384378\n[2022-04-12 16:19:44] - evaluating...\n[2022-04-12 16:19:48] - valid_l1 0.203046, test_l1 0.125532\n[2022-04-12 16:19:48] - valid_dtw 0.529032, test_dtw 0.334542\n[2022-04-12 16:19:48] - Epoch: 1\n[2022-04-12 16:19:48] - training...\n[2022-04-12 16:20:06] - [ 5.29913673e-02 -1.72252409e-01  4.25747437e-10] 0.11571763469172376\n[2022-04-12 16:20:06] - evaluating...\n[2022-04-12 16:20:10] - valid_l1 0.150337, test_l1 0.119063\n[2022-04-12 16:20:10] - valid_dtw 0.391236, test_dtw 0.314677\n[2022-04-12 16:20:10] - Epoch: 2\n[2022-04-12 16:20:10] - training...\n[2022-04-12 16:20:29] - [-6.93908382e-01 -2.04749907e-01 -7.23770685e-09] 0.10800076063190188\n[2022-04-12 16:20:29] - evaluating...\n[2022-04-12 16:20:33] - valid_l1 0.125574, test_l1 0.100439\n[2022-04-12 16:20:33] - valid_dtw 0.326104, test_dtw 0.264072\n[2022-04-12 16:20:33] - Epoch: 3\n[2022-04-12 16:20:33] - training...\n[2022-04-12 16:20:52] - [-1.15421648e+00 -2.10096949e-01 -1.40496667e-08] 0.10708553290792874\n[2022-04-12 16:20:52] - evaluating...\n[2022-04-12 16:20:57] - valid_l1 0.104228, test_l1 0.090790\n[2022-04-12 16:20:57] - valid_dtw 0.269690, test_dtw 0.234720\n[2022-04-12 16:20:57] - Epoch: 4\n[2022-04-12 16:20:57] - training...\n[2022-04-12 16:21:16] - [-1.47232241e+00 -1.97323587e-01 -8.08920194e-09] 0.10951162076422147\n[2022-04-12 16:21:16] - evaluating...\n[2022-04-12 16:21:20] - valid_l1 0.091112, test_l1 0.092507\n[2022-04-12 16:21:20] - valid_dtw 0.240636, test_dtw 0.238857\n[2022-04-12 16:21:20] - Epoch: 5\n[2022-04-12 16:21:20] - training...\n[2022-04-12 16:21:38] - [-1.81890195e+00 -2.09646176e-01 -8.73356213e-10] 0.10281040672478932\n[2022-04-12 16:21:38] - evaluating...\n[2022-04-12 16:21:42] - valid_l1 0.072993, test_l1 0.070711\n[2022-04-12 16:21:42] - valid_dtw 0.195809, test_dtw 0.183281\n[2022-04-12 16:21:42] - Epoch: 6\n[2022-04-12 16:21:42] - training...\n[2022-04-12 16:22:01] - [-2.26049809e+00 -2.66866692e-01 -4.91601134e-09] 0.08571676923228162\n[2022-04-12 16:22:01] - evaluating...\n[2022-04-12 16:22:05] - valid_l1 0.084114, test_l1 0.080409\n[2022-04-12 16:22:05] - valid_dtw 0.228169, test_dtw 0.204562\n[2022-04-12 16:22:05] - Epoch: 7\n[2022-04-12 16:22:05] - training...\n[2022-04-12 16:22:23] - [-2.67853240e+00 -3.23273930e-01 -3.61485324e-09] 0.06580048160893577\n[2022-04-12 16:22:23] - evaluating...\n[2022-04-12 16:22:27] - valid_l1 0.062799, test_l1 0.064128\n[2022-04-12 16:22:27] - valid_dtw 0.181114, test_dtw 0.165759\n[2022-04-12 16:22:27] - Epoch: 8\n[2022-04-12 16:22:27] - training...\n[2022-04-12 16:22:46] - [-2.41149527e+00 -2.70662824e-01 -3.98965892e-10] 0.08438249378065978\n[2022-04-12 16:22:46] - evaluating...\n[2022-04-12 16:22:49] - valid_l1 0.081421, test_l1 0.082726\n[2022-04-12 16:22:49] - valid_dtw 0.223822, test_dtw 0.213624\n[2022-04-12 16:22:49] - Epoch: 9\n[2022-04-12 16:22:49] - training...\n[2022-04-12 16:23:08] - [-2.67958740e+00 -2.98213680e-01 -3.22171369e-09] 0.0766887489839324\n[2022-04-12 16:23:08] - evaluating...\n[2022-04-12 16:23:12] - valid_l1 0.067880, test_l1 0.065556\n[2022-04-12 16:23:12] - valid_dtw 0.195141, test_dtw 0.167184\n[2022-04-12 16:23:12] - Epoch: 10\n[2022-04-12 16:23:12] - training...\n[2022-04-12 16:23:31] - [-2.54487884e+00 -3.03930660e-01 -2.35745977e-09] 0.0751054659485817\n[2022-04-12 16:23:31] - evaluating...\n[2022-04-12 16:23:34] - valid_l1 0.077971, test_l1 0.080777\n[2022-04-12 16:23:34] - valid_dtw 0.218346, test_dtw 0.208767\n[2022-04-12 16:23:34] - Epoch: 11\n[2022-04-12 16:23:34] - training...\n[2022-04-12 16:23:53] - [-2.81201447e+00 -3.37307620e-01  1.05689540e-09] 0.06248934127922569\n[2022-04-12 16:23:53] - evaluating...\n[2022-04-12 16:23:57] - valid_l1 0.057082, test_l1 0.053286\n[2022-04-12 16:23:57] - valid_dtw 0.168791, test_dtw 0.139208\n[2022-04-12 16:23:57] - Epoch: 12\n[2022-04-12 16:23:57] - training...\n[2022-04-12 16:24:15] - [-2.83176533e+00 -3.22103810e-01 -1.83410081e-10] 0.06784803500132901\n[2022-04-12 16:24:15] - evaluating...\n[2022-04-12 16:24:19] - valid_l1 0.064349, test_l1 0.052776\n[2022-04-12 16:24:19] - valid_dtw 0.182413, test_dtw 0.138877\n[2022-04-12 16:24:19] - Epoch: 13\n[2022-04-12 16:24:19] - training...\n[2022-04-12 16:24:38] - [-2.77140954e+00 -3.25097105e-01 -3.60864185e-09] 0.06592728164313096\n[2022-04-12 16:24:38] - evaluating...\n[2022-04-12 16:24:41] - valid_l1 0.058331, test_l1 0.051480\n[2022-04-12 16:24:41] - valid_dtw 0.176900, test_dtw 0.133510\n[2022-04-12 16:24:41] - Epoch: 14\n[2022-04-12 16:24:41] - training...\n[2022-04-12 16:25:01] - [-2.86195570e+00 -3.26798053e-01 -2.13775074e-09] 0.06875191682151385\n[2022-04-12 16:25:01] - evaluating...\n[2022-04-12 16:25:05] - valid_l1 0.050053, test_l1 0.042155\n[2022-04-12 16:25:05] - valid_dtw 0.152656, test_dtw 0.110154\n[2022-04-12 16:25:05] - best val score: 0.0062636861203875585 @ 14\n[2022-04-12 16:25:05] - inference...\n[2022-04-12 16:25:08] - MSE: train 0.045794, valid 0.006029, test 0.003588\n[2022-04-12 16:25:08] - L1:  train 0.153717, valid 0.049091, test 0.043278\n[2022-04-12 16:25:08] - RMSE: train 0.206040, valid 0.065878, test 0.053026\n[2022-04-12 16:25:08] - DTW: train 0.517426, valid 0.150293, test 0.109706\n[2022-04-12 16:25:08] - TDI: train 0.436514, valid 0.351982, test 0.398938\n[2022-04-12 16:25:08] - Finished.\n[2022-04-12 16:26:37] - create model_king...\n[2022-04-12 16:26:37] - Epoch: 0\n[2022-04-12 16:26:37] - training...\n[2022-04-12 16:26:59] - [ 6.57962831e+00  7.67595156e-01 -5.53471748e-09] 0.2361668505306755\n[2022-04-12 16:26:59] - evaluating...\n[2022-04-12 16:27:04] - valid_l1 0.208659, test_l1 0.124744\n[2022-04-12 16:27:04] - valid_dtw 0.543630, test_dtw 0.332514\n[2022-04-12 16:27:04] - Epoch: 1\n[2022-04-12 16:27:04] - training...\n[2022-04-12 16:27:22] - [-7.30676369e-01 -2.73352917e-01 -2.98023225e-09] 0.11347564842019763\n[2022-04-12 16:27:22] - evaluating...\n[2022-04-12 16:27:26] - valid_l1 0.147268, test_l1 0.120896\n[2022-04-12 16:27:26] - valid_dtw 0.383159, test_dtw 0.318825\n[2022-04-12 16:27:26] - Epoch: 2\n[2022-04-12 16:27:26] - training...\n[2022-04-12 16:27:45] - [-1.55541954e+00 -3.01515864e-01 -1.78813940e-08] 0.11018587815176163\n[2022-04-12 16:27:45] - evaluating...\n[2022-04-12 16:27:49] - valid_l1 0.125119, test_l1 0.099044\n[2022-04-12 16:27:49] - valid_dtw 0.324815, test_dtw 0.260001\n[2022-04-12 16:27:49] - Epoch: 3\n[2022-04-12 16:27:49] - training...\n[2022-04-12 16:28:09] - [-2.14307381e+00 -3.16877599e-01 -1.57526565e-08] 0.10671692873750414\n[2022-04-12 16:28:09] - evaluating...\n[2022-04-12 16:28:13] - valid_l1 0.099945, test_l1 0.092436\n[2022-04-12 16:28:13] - valid_dtw 0.258226, test_dtw 0.238198\n[2022-04-12 16:28:13] - Epoch: 4\n[2022-04-12 16:28:13] - training...\n[2022-04-12 16:28:32] - [-2.43268399e+00 -2.92573339e-01 -4.68322213e-09] 0.11233348505837577\n[2022-04-12 16:28:32] - evaluating...\n[2022-04-12 16:28:36] - valid_l1 0.089284, test_l1 0.090989\n[2022-04-12 16:28:36] - valid_dtw 0.234210, test_dtw 0.233905\n[2022-04-12 16:28:36] - Epoch: 5\n[2022-04-12 16:28:36] - training...\n[2022-04-12 16:28:55] - [-3.03128912e+00 -3.32462331e-01 -1.38608613e-08] 0.09964051117588367\n[2022-04-12 16:28:55] - evaluating...\n[2022-04-12 16:28:59] - valid_l1 0.072261, test_l1 0.065159\n[2022-04-12 16:28:59] - valid_dtw 0.195520, test_dtw 0.166969\n[2022-04-12 16:28:59] - Epoch: 6\n[2022-04-12 16:28:59] - training...\n[2022-04-12 16:29:19] - [-3.54949596e+00 -4.14091667e-01 -8.34386837e-09] 0.07764269930443593\n[2022-04-12 16:29:19] - evaluating...\n[2022-04-12 16:29:24] - valid_l1 0.069558, test_l1 0.064695\n[2022-04-12 16:29:24] - valid_dtw 0.197681, test_dtw 0.163533\n[2022-04-12 16:29:24] - Epoch: 7\n[2022-04-12 16:29:24] - training...\n[2022-04-12 16:29:44] - [-4.03409840e+00 -4.66595093e-01  6.48758222e-10] 0.06139890091227634\n[2022-04-12 16:29:44] - evaluating...\n[2022-04-12 16:29:48] - valid_l1 0.074539, test_l1 0.067263\n[2022-04-12 16:29:48] - valid_dtw 0.207866, test_dtw 0.178483\n[2022-04-12 16:29:48] - Epoch: 8\n[2022-04-12 16:29:48] - training...\n[2022-04-12 16:30:08] - [-3.86254388e+00 -4.21538541e-01 -2.54565519e-09] 0.07918413562167968\n[2022-04-12 16:30:08] - evaluating...\n[2022-04-12 16:30:13] - valid_l1 0.062764, test_l1 0.058185\n[2022-04-12 16:30:13] - valid_dtw 0.180667, test_dtw 0.150713\n[2022-04-12 16:30:13] - Epoch: 9\n[2022-04-12 16:30:13] - training...\n[2022-04-12 16:30:32] - [-3.63469812e+00 -3.49254405e-01 -3.63724644e-09] 0.09571504080668092\n[2022-04-12 16:30:32] - evaluating...\n[2022-04-12 16:30:36] - valid_l1 0.086999, test_l1 0.073427\n[2022-04-12 16:30:36] - valid_dtw 0.238099, test_dtw 0.189092\n[2022-04-12 16:30:36] - Epoch: 10\n[2022-04-12 16:30:36] - training...\n[2022-04-12 16:30:55] - [-3.90574532e+00 -4.42186820e-01 -5.31139033e-09] 0.06796995510480233\n[2022-04-12 16:30:55] - evaluating...\n[2022-04-12 16:30:59] - valid_l1 0.058922, test_l1 0.054284\n[2022-04-12 16:30:59] - valid_dtw 0.177583, test_dtw 0.139808\n[2022-04-12 16:30:59] - Epoch: 11\n[2022-04-12 16:30:59] - training...\n[2022-04-12 16:31:19] - [-4.04544766e+00 -4.57603729e-01  2.24557595e-10] 0.06435778590717486\n[2022-04-12 16:31:19] - evaluating...\n[2022-04-12 16:31:23] - valid_l1 0.054910, test_l1 0.050549\n[2022-04-12 16:31:23] - valid_dtw 0.166312, test_dtw 0.130546\n[2022-04-12 16:31:23] - Epoch: 12\n[2022-04-12 16:31:23] - training...\n[2022-04-12 16:31:42] - [-3.60712856e+00 -4.17112885e-01 -4.06983257e-09] 0.08238337428442069\n[2022-04-12 16:31:42] - evaluating...\n[2022-04-12 16:31:46] - valid_l1 0.088043, test_l1 0.072681\n[2022-04-12 16:31:46] - valid_dtw 0.238735, test_dtw 0.187788\n[2022-04-12 16:31:46] - Epoch: 13\n[2022-04-12 16:31:46] - training...\n[2022-04-12 16:32:06] - [-4.03765836e+00 -4.70328989e-01 -7.67195696e-09] 0.05861822595553739\n[2022-04-12 16:32:06] - evaluating...\n[2022-04-12 16:32:09] - valid_l1 0.055391, test_l1 0.049953\n[2022-04-12 16:32:09] - valid_dtw 0.168048, test_dtw 0.129591\n[2022-04-12 16:32:09] - Epoch: 14\n[2022-04-12 16:32:09] - training...\n[2022-04-12 16:32:28] - [-4.22061415e+00 -4.70469058e-01 -6.18816414e-09] 0.0599099529374923\n[2022-04-12 16:32:28] - evaluating...\n[2022-04-12 16:32:32] - valid_l1 0.049427, test_l1 0.038964\n[2022-04-12 16:32:32] - valid_dtw 0.144917, test_dtw 0.102219\n[2022-04-12 16:32:32] - best val score: 0.0056543163398026465 @ 14\n[2022-04-12 16:32:32] - inference...\n[2022-04-12 16:32:36] - MSE: train 0.044030, valid 0.005547, test 0.003162\n[2022-04-12 16:32:36] - L1:  train 0.145629, valid 0.048778, test 0.039809\n[2022-04-12 16:32:36] - RMSE: train 0.202354, valid 0.064096, test 0.050551\n[2022-04-12 16:32:36] - DTW: train 0.507928, valid 0.142764, test 0.101222\n[2022-04-12 16:32:36] - TDI: train 0.367069, valid 0.359760, test 0.368807\n[2022-04-12 16:32:36] - Finished.\n[2022-04-12 16:48:37] - create model_king...\n[2022-04-12 16:48:37] - Epoch: 0\n[2022-04-12 16:48:37] - training...\n[2022-04-12 16:48:41] - [-1.23391160e-01 -1.23391160e-01 -4.76837183e-09] 0.11588546670973301\n[2022-04-12 16:48:41] - evaluating...\n[2022-04-12 16:48:44] - valid_l1 0.178841, test_l1 0.472082\n[2022-04-12 16:48:44] - valid_dtw 0.468914, test_dtw 1.223294\n[2022-04-12 16:48:44] - Epoch: 1\n[2022-04-12 16:48:44] - training...\n[2022-04-12 16:48:45] - [-2.30305215e-01 -2.30305215e-01 -8.34465061e-09] 0.08440500805154443\n[2022-04-12 16:48:45] - evaluating...\n[2022-04-12 16:48:48] - valid_l1 0.155579, test_l1 0.414304\n[2022-04-12 16:48:48] - valid_dtw 0.407325, test_dtw 1.070878\n[2022-04-12 16:48:48] - Epoch: 2\n[2022-04-12 16:48:48] - training...\n[2022-04-12 16:48:49] - [-2.03291099e-01 -2.03291099e-01 -8.34465048e-09] 0.09367384314537049\n[2022-04-12 16:48:49] - evaluating...\n[2022-04-12 16:48:52] - valid_l1 0.148398, test_l1 0.391320\n[2022-04-12 16:48:52] - valid_dtw 0.388510, test_dtw 1.010497\n[2022-04-12 16:48:52] - Epoch: 3\n[2022-04-12 16:48:52] - training...\n[2022-04-12 16:48:53] - [-2.19952350e-01 -2.19952350e-01 -8.34465035e-09] 0.09009117782115936\n[2022-04-12 16:48:53] - evaluating...\n[2022-04-12 16:48:56] - valid_l1 0.158087, test_l1 0.422237\n[2022-04-12 16:48:56] - valid_dtw 0.412242, test_dtw 1.088427\n[2022-04-12 16:48:56] - Epoch: 4\n[2022-04-12 16:48:56] - training...\n[2022-04-12 16:48:57] - [-2.31815897e-01 -2.31815897e-01 -1.19209278e-09] 0.0874772222712636\n[2022-04-12 16:48:57] - evaluating...\n[2022-04-12 16:49:00] - valid_l1 0.155848, test_l1 0.408851\n[2022-04-12 16:49:00] - valid_dtw 0.405572, test_dtw 1.052927\n[2022-04-12 16:49:00] - Epoch: 5\n[2022-04-12 16:49:00] - training...\n[2022-04-12 16:49:01] - [-2.33304463e-01 -2.33304463e-01 -5.35223523e-09] 0.08587031606584787\n[2022-04-12 16:49:01] - evaluating...\n[2022-04-12 16:49:04] - valid_l1 0.148503, test_l1 0.389963\n[2022-04-12 16:49:04] - valid_dtw 0.385961, test_dtw 1.003199\n[2022-04-12 16:49:04] - Epoch: 6\n[2022-04-12 16:49:04] - training...\n[2022-04-12 16:49:05] - [-2.44912588e-01 -2.44912588e-01 -3.56166032e-09] 0.08363984348252415\n[2022-04-12 16:49:05] - evaluating...\n[2022-04-12 16:49:08] - valid_l1 0.145418, test_l1 0.382115\n[2022-04-12 16:49:08] - valid_dtw 0.377531, test_dtw 0.982667\n[2022-04-12 16:49:08] - Epoch: 7\n[2022-04-12 16:49:08] - training...\n[2022-04-12 16:49:10] - [-2.56591132e-01 -2.56591132e-01 -4.79992257e-09] 0.08061410617083312\n[2022-04-12 16:49:10] - evaluating...\n[2022-04-12 16:49:12] - valid_l1 0.140414, test_l1 0.366885\n[2022-04-12 16:49:12] - valid_dtw 0.364268, test_dtw 0.943648\n[2022-04-12 16:49:13] - Epoch: 8\n[2022-04-12 16:49:13] - training...\n[2022-04-12 16:49:14] - [-2.60731970e-01 -2.60731970e-01 -2.67202729e-09] 0.07991017624735833\n[2022-04-12 16:49:14] - evaluating...\n[2022-04-12 16:49:17] - valid_l1 0.128153, test_l1 0.333242\n[2022-04-12 16:49:17] - valid_dtw 0.332849, test_dtw 0.858533\n[2022-04-12 16:49:17] - Epoch: 9\n[2022-04-12 16:49:17] - training...\n[2022-04-12 16:49:18] - [-2.63270293e-01 -2.63270293e-01 -8.99300145e-10] 0.07884305529296398\n[2022-04-12 16:49:18] - evaluating...\n[2022-04-12 16:49:21] - valid_l1 0.132865, test_l1 0.344639\n[2022-04-12 16:49:21] - valid_dtw 0.344146, test_dtw 0.887357\n[2022-04-12 16:49:21] - Epoch: 10\n[2022-04-12 16:49:21] - training...\n[2022-04-12 16:49:22] - [-2.66164834e-01 -2.66164834e-01 -6.20279592e-09] 0.07968863612040877\n[2022-04-12 16:49:22] - evaluating...\n[2022-04-12 16:49:25] - valid_l1 0.118654, test_l1 0.306700\n[2022-04-12 16:49:25] - valid_dtw 0.307843, test_dtw 0.792267\n[2022-04-12 16:49:25] - Epoch: 11\n[2022-04-12 16:49:25] - training...\n[2022-04-12 16:49:26] - [-2.70428997e-01 -2.70428997e-01 -4.46338602e-09] 0.07772337533533573\n[2022-04-12 16:49:26] - evaluating...\n[2022-04-12 16:49:29] - valid_l1 0.126623, test_l1 0.327318\n[2022-04-12 16:49:29] - valid_dtw 0.327421, test_dtw 0.843719\n[2022-04-12 16:49:29] - Epoch: 12\n[2022-04-12 16:49:29] - training...\n[2022-04-12 16:49:30] - [-2.74497963e-01 -2.74497963e-01 -5.07792657e-09] 0.07799774054437876\n[2022-04-12 16:49:30] - evaluating...\n[2022-04-12 16:49:33] - valid_l1 0.114237, test_l1 0.291921\n[2022-04-12 16:49:33] - valid_dtw 0.296038, test_dtw 0.755320\n[2022-04-12 16:49:33] - Epoch: 13\n[2022-04-12 16:49:33] - training...\n[2022-04-12 16:49:34] - [-2.75608378e-01 -2.75608378e-01 -5.98416883e-09] 0.07678404245525598\n[2022-04-12 16:49:34] - evaluating...\n[2022-04-12 16:49:37] - valid_l1 0.117969, test_l1 0.301410\n[2022-04-12 16:49:37] - valid_dtw 0.304790, test_dtw 0.778639\n[2022-04-12 16:49:37] - Epoch: 14\n[2022-04-12 16:49:37] - training...\n[2022-04-12 16:49:38] - [-2.82728623e-01 -2.82728623e-01 -4.70680372e-09] 0.07627545557916164\n[2022-04-12 16:49:38] - evaluating...\n[2022-04-12 16:49:41] - valid_l1 0.107272, test_l1 0.269770\n[2022-04-12 16:49:41] - valid_dtw 0.277533, test_dtw 0.698184\n[2022-04-12 16:49:41] - best val score: 0.017209272670152133 @ 14\n[2022-04-12 16:49:41] - inference...\n[2022-04-12 16:49:44] - MSE: train 0.016184, valid 0.017133, test 0.084342\n[2022-04-12 16:49:44] - L1:  train 0.117925, valid 0.107117, test 0.269616\n[2022-04-12 16:49:44] - RMSE: train 0.125118, valid 0.116060, test 0.281036\n[2022-04-12 16:49:44] - DTW: train 0.303077, valid 0.277122, test 0.697881\n[2022-04-12 16:49:44] - TDI: train 0.204911, valid 0.322937, test 0.084685\n[2022-04-12 16:49:44] - Finished.\n[2022-04-12 16:50:51] - create model_king...\n[2022-04-12 16:50:51] - Epoch: 0\n[2022-04-12 16:50:51] - training...\n[2022-04-12 16:50:55] - [-1.16411683e-01 -1.16411682e-01 -1.01327891e-08] 0.12072509434074163\n[2022-04-12 16:50:55] - evaluating...\n[2022-04-12 16:50:59] - valid_l1 0.121150, test_l1 0.331667\n[2022-04-12 16:50:59] - valid_dtw 0.315464, test_dtw 0.851265\n[2022-04-12 16:50:59] - Epoch: 1\n[2022-04-12 16:50:59] - training...\n[2022-04-12 16:51:01] - [-2.53784802e-01 -2.53784802e-01 -8.34464933e-09] 0.08025706373155117\n[2022-04-12 16:51:01] - evaluating...\n[2022-04-12 16:51:05] - valid_l1 0.104551, test_l1 0.273709\n[2022-04-12 16:51:05] - valid_dtw 0.273102, test_dtw 0.703711\n[2022-04-12 16:51:05] - Epoch: 2\n[2022-04-12 16:51:05] - training...\n[2022-04-12 16:51:07] - [-2.52624965e-01 -2.52624965e-01 -2.92062755e-08] 0.08243415849283338\n[2022-04-12 16:51:07] - evaluating...\n[2022-04-12 16:51:10] - valid_l1 0.104455, test_l1 0.275203\n[2022-04-12 16:51:10] - valid_dtw 0.272483, test_dtw 0.707493\n[2022-04-12 16:51:10] - Epoch: 3\n[2022-04-12 16:51:10] - training...\n[2022-04-12 16:51:12] - [-2.59331656e-01 -2.59331656e-01 -8.94069667e-09] 0.08039006199687719\n[2022-04-12 16:51:12] - evaluating...\n[2022-04-12 16:51:16] - valid_l1 0.103711, test_l1 0.276565\n[2022-04-12 16:51:16] - valid_dtw 0.270248, test_dtw 0.711053\n[2022-04-12 16:51:16] - Epoch: 4\n[2022-04-12 16:51:16] - training...\n[2022-04-12 16:51:18] - [-2.70263057e-01 -2.70263057e-01 -1.19209292e-08] 0.07619740488007665\n[2022-04-12 16:51:18] - evaluating...\n[2022-04-12 16:51:21] - valid_l1 0.096525, test_l1 0.257707\n[2022-04-12 16:51:21] - valid_dtw 0.251639, test_dtw 0.663418\n[2022-04-12 16:51:21] - Epoch: 5\n[2022-04-12 16:51:21] - training...\n[2022-04-12 16:51:23] - [-2.79335832e-01 -2.79335832e-01 -7.46464297e-09] 0.07391613526269794\n[2022-04-12 16:51:23] - evaluating...\n[2022-04-12 16:51:27] - valid_l1 0.091557, test_l1 0.244413\n[2022-04-12 16:51:27] - valid_dtw 0.238712, test_dtw 0.629940\n[2022-04-12 16:51:27] - Epoch: 6\n[2022-04-12 16:51:27] - training...\n[2022-04-12 16:51:29] - [-2.88432347e-01 -2.88432347e-01 -8.59188061e-09] 0.07122455118224025\n[2022-04-12 16:51:29] - evaluating...\n[2022-04-12 16:51:33] - valid_l1 0.084771, test_l1 0.222078\n[2022-04-12 16:51:33] - valid_dtw 0.220916, test_dtw 0.573272\n[2022-04-12 16:51:33] - Epoch: 7\n[2022-04-12 16:51:33] - training...\n[2022-04-12 16:51:35] - [-2.85437875e-01 -2.85437875e-01 -6.55571240e-09] 0.07316897511482238\n[2022-04-12 16:51:35] - evaluating...\n[2022-04-12 16:51:38] - valid_l1 0.082368, test_l1 0.219141\n[2022-04-12 16:51:38] - valid_dtw 0.214264, test_dtw 0.566217\n[2022-04-12 16:51:38] - Epoch: 8\n[2022-04-12 16:51:38] - training...\n[2022-04-12 16:51:40] - [-2.91841550e-01 -2.91841550e-01 -1.45843393e-08] 0.07154504507780075\n[2022-04-12 16:51:40] - evaluating...\n[2022-04-12 16:51:44] - valid_l1 0.080729, test_l1 0.216214\n[2022-04-12 16:51:44] - valid_dtw 0.209690, test_dtw 0.558853\n[2022-04-12 16:51:44] - Epoch: 9\n[2022-04-12 16:51:44] - training...\n[2022-04-12 16:51:46] - [-2.94026334e-01 -2.94026334e-01 -7.76062667e-09] 0.07046159999445081\n[2022-04-12 16:51:46] - evaluating...\n[2022-04-12 16:51:49] - valid_l1 0.077660, test_l1 0.215634\n[2022-04-12 16:51:49] - valid_dtw 0.201344, test_dtw 0.557860\n[2022-04-12 16:51:49] - Epoch: 10\n[2022-04-12 16:51:49] - training...\n[2022-04-12 16:51:51] - [-2.99252141e-01 -2.99252141e-01 -1.22397787e-08] 0.06930902004241943\n[2022-04-12 16:51:51] - evaluating...\n[2022-04-12 16:51:55] - valid_l1 0.072553, test_l1 0.187407\n[2022-04-12 16:51:55] - valid_dtw 0.186999, test_dtw 0.485227\n[2022-04-12 16:51:55] - Epoch: 11\n[2022-04-12 16:51:55] - training...\n[2022-04-12 16:51:57] - [-3.02243163e-01 -3.02243163e-01 -1.16566900e-08] 0.06888346457853914\n[2022-04-12 16:51:57] - evaluating...\n[2022-04-12 16:52:01] - valid_l1 0.073255, test_l1 0.195893\n[2022-04-12 16:52:01] - valid_dtw 0.188624, test_dtw 0.507055\n[2022-04-12 16:52:01] - Epoch: 12\n[2022-04-12 16:52:01] - training...\n[2022-04-12 16:52:03] - [-2.98071948e-01 -2.98071948e-01 -8.34660920e-09] 0.07037917925044894\n[2022-04-12 16:52:03] - evaluating...\n[2022-04-12 16:52:06] - valid_l1 0.066527, test_l1 0.165686\n[2022-04-12 16:52:06] - valid_dtw 0.170523, test_dtw 0.428184\n[2022-04-12 16:52:06] - Epoch: 13\n[2022-04-12 16:52:06] - training...\n[2022-04-12 16:52:08] - [-2.97922633e-01 -2.97922633e-01 -6.54060335e-09] 0.07042435705661773\n[2022-04-12 16:52:08] - evaluating...\n[2022-04-12 16:52:12] - valid_l1 0.062312, test_l1 0.159413\n[2022-04-12 16:52:12] - valid_dtw 0.159923, test_dtw 0.412178\n[2022-04-12 16:52:12] - Epoch: 14\n[2022-04-12 16:52:12] - training...\n[2022-04-12 16:52:14] - [-0.31370725 -0.31519745  0.02980412] 0.06419871132820845\n[2022-04-12 16:52:14] - evaluating...\n[2022-04-12 16:52:18] - valid_l1 0.074465, test_l1 0.206957\n[2022-04-12 16:52:18] - valid_dtw 0.190819, test_dtw 0.535994\n[2022-04-12 16:52:18] - best val score: 0.005634116351090294 @ 13\n[2022-04-12 16:52:18] - inference...\n[2022-04-12 16:52:21] - MSE: train 0.013899, valid 0.005974, test 0.031094\n[2022-04-12 16:52:21] - L1:  train 0.108959, valid 0.063901, test 0.158540\n[2022-04-12 16:52:21] - RMSE: train 0.116722, valid 0.072084, test 0.168161\n[2022-04-12 16:52:21] - DTW: train 0.280358, valid 0.164378, test 0.410236\n[2022-04-12 16:52:21] - TDI: train 0.282034, valid 0.384330, test 0.148577\n[2022-04-12 16:52:21] - Finished.\n[2022-04-12 16:53:29] - create model_king...\n[2022-04-12 16:53:29] - Epoch: 0\n[2022-04-12 16:53:29] - training...\n[2022-04-12 16:53:37] - [ 1.14868282e+00  3.82613130e-01 -2.25870239e-08] 0.23684507412345787\n[2022-04-12 16:53:37] - evaluating...\n[2022-04-12 16:53:41] - valid_l1 0.183820, test_l1 0.077103\n[2022-04-12 16:53:41] - valid_dtw 0.474110, test_dtw 0.201745\n[2022-04-12 16:53:41] - Epoch: 1\n[2022-04-12 16:53:41] - training...\n[2022-04-12 16:53:47] - [-1.00678964e-02 -9.15657298e-02 -2.44692754e-08] 0.18453172633522436\n[2022-04-12 16:53:47] - evaluating...\n[2022-04-12 16:53:50] - valid_l1 0.187281, test_l1 0.081491\n[2022-04-12 16:53:50] - valid_dtw 0.482869, test_dtw 0.212428\n[2022-04-12 16:53:50] - Epoch: 2\n[2022-04-12 16:53:50] - training...\n[2022-04-12 16:53:56] - [-2.72022192e-01 -1.69744785e-01 -1.81951023e-08] 0.1530212787421126\n[2022-04-12 16:53:56] - evaluating...\n[2022-04-12 16:53:59] - valid_l1 0.124298, test_l1 0.058199\n[2022-04-12 16:53:59] - valid_dtw 0.322940, test_dtw 0.149665\n[2022-04-12 16:53:59] - Epoch: 3\n[2022-04-12 16:53:59] - training...\n[2022-04-12 16:54:05] - [-5.76211452e-01 -2.18579867e-01 -2.07047721e-08] 0.13013209088852531\n[2022-04-12 16:54:05] - evaluating...\n[2022-04-12 16:54:08] - valid_l1 0.195691, test_l1 0.281960\n[2022-04-12 16:54:08] - valid_dtw 0.519728, test_dtw 0.742102\n[2022-04-12 16:54:08] - Epoch: 4\n[2022-04-12 16:54:08] - training...\n[2022-04-12 16:54:14] - [-7.17845422e-01 -2.80526471e-01 -1.19209287e-08] 0.08795360887521192\n[2022-04-12 16:54:14] - evaluating...\n[2022-04-12 16:54:17] - valid_l1 0.247163, test_l1 0.389709\n[2022-04-12 16:54:17] - valid_dtw 0.668569, test_dtw 1.041351\n[2022-04-12 16:54:17] - Epoch: 5\n[2022-04-12 16:54:17] - training...\n[2022-04-12 16:54:23] - [-7.74424211e-01 -3.03220736e-01 -2.24906912e-09] 0.07993643495597337\n[2022-04-12 16:54:23] - evaluating...\n[2022-04-12 16:54:26] - valid_l1 0.156673, test_l1 0.219847\n[2022-04-12 16:54:26] - valid_dtw 0.440431, test_dtw 0.579009\n[2022-04-12 16:54:26] - Epoch: 6\n[2022-04-12 16:54:26] - training...\n[2022-04-12 16:54:32] - [-0.69483795 -0.25919592  0.00243505] 0.0970369279384613\n[2022-04-12 16:54:32] - evaluating...\n[2022-04-12 16:54:35] - valid_l1 0.187682, test_l1 0.276025\n[2022-04-12 16:54:35] - valid_dtw 0.508919, test_dtw 0.735821\n[2022-04-12 16:54:35] - Epoch: 7\n[2022-04-12 16:54:35] - training...\n[2022-04-12 16:54:41] - [-7.01057618e-01 -2.80094421e-01 -1.47866213e-08] 0.08603481105283688\n[2022-04-12 16:54:41] - evaluating...\n[2022-04-12 16:54:44] - valid_l1 0.240071, test_l1 0.323198\n[2022-04-12 16:54:44] - valid_dtw 0.652557, test_dtw 0.857540\n[2022-04-12 16:54:44] - Epoch: 8\n[2022-04-12 16:54:44] - training...\n[2022-04-12 16:54:50] - [-7.37458248e-01 -3.08627253e-01 -6.29732463e-09] 0.07510313519129627\n[2022-04-12 16:54:50] - evaluating...\n[2022-04-12 16:54:53] - valid_l1 0.232888, test_l1 0.278311\n[2022-04-12 16:54:53] - valid_dtw 0.628142, test_dtw 0.737386\n[2022-04-12 16:54:53] - Epoch: 9\n[2022-04-12 16:54:53] - training...\n[2022-04-12 16:54:59] - [-6.75975873e-01 -2.66325367e-01 -1.18900224e-08] 0.09005618605174516\n[2022-04-12 16:54:59] - evaluating...\n[2022-04-12 16:55:02] - valid_l1 0.197876, test_l1 0.307910\n[2022-04-12 16:55:02] - valid_dtw 0.539508, test_dtw 0.820190\n[2022-04-12 16:55:02] - Epoch: 10\n[2022-04-12 16:55:02] - training...\n[2022-04-12 16:55:08] - [-6.92117439e-01 -2.49939711e-01 -5.36746243e-09] 0.09731000524602439\n[2022-04-12 16:55:08] - evaluating...\n[2022-04-12 16:55:11] - valid_l1 0.159970, test_l1 0.211785\n[2022-04-12 16:55:11] - valid_dtw 0.433372, test_dtw 0.561705\n[2022-04-12 16:55:11] - Epoch: 11\n[2022-04-12 16:55:11] - training...\n[2022-04-12 16:55:17] - [-6.77497219e-01 -2.53130092e-01 -8.14267182e-09] 0.09951247392516387\n[2022-04-12 16:55:17] - evaluating...\n[2022-04-12 16:55:20] - valid_l1 0.084768, test_l1 0.111357\n[2022-04-12 16:55:20] - valid_dtw 0.245596, test_dtw 0.285785\n[2022-04-12 16:55:20] - Epoch: 12\n[2022-04-12 16:55:20] - training...\n[2022-04-12 16:55:26] - [-6.97387628e-01 -2.54969358e-01 -8.82363590e-09] 0.09305856769022189\n[2022-04-12 16:55:26] - evaluating...\n[2022-04-12 16:55:29] - valid_l1 0.079222, test_l1 0.071626\n[2022-04-12 16:55:29] - valid_dtw 0.238466, test_dtw 0.185323\n[2022-04-12 16:55:29] - Epoch: 13\n[2022-04-12 16:55:29] - training...\n[2022-04-12 16:55:35] - [-7.55912567e-01 -2.75567470e-01 -3.24589081e-10] 0.08668547084456996\n[2022-04-12 16:55:35] - evaluating...\n[2022-04-12 16:55:38] - valid_l1 0.118019, test_l1 0.111773\n[2022-04-12 16:55:38] - valid_dtw 0.337642, test_dtw 0.288136\n[2022-04-12 16:55:38] - Epoch: 14\n[2022-04-12 16:55:38] - training...\n[2022-04-12 16:55:44] - [-7.32256610e-01 -2.89537778e-01 -4.73614060e-09] 0.07908642546910989\n[2022-04-12 16:55:44] - evaluating...\n[2022-04-12 16:55:48] - valid_l1 0.109328, test_l1 0.176430\n[2022-04-12 16:55:48] - valid_dtw 0.321640, test_dtw 0.463719\n[2022-04-12 16:55:48] - best val score: 0.010674074608444547 @ 12\n[2022-04-12 16:55:48] - inference...\n[2022-04-12 16:55:51] - MSE: train 0.013691, valid 0.010143, test 0.007938\n[2022-04-12 16:55:51] - L1:  train 0.079771, valid 0.076971, test 0.075696\n[2022-04-12 16:55:51] - RMSE: train 0.114641, valid 0.096112, test 0.084867\n[2022-04-12 16:55:51] - DTW: train 0.282413, valid 0.234049, test 0.192183\n[2022-04-12 16:55:51] - TDI: train 0.278468, valid 0.392059, test 0.514729\n[2022-04-12 16:55:51] - Finished.\n[2022-04-12 20:54:38] - create model_king...\n[2022-04-12 20:54:38] - Epoch: 0\n[2022-04-12 20:54:38] - training...\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/outputs_Jintang_DualAdarnn_weather_cosine_5_0.05_0.0005/run.log b/outputs_Jintang_DualAdarnn_weather_cosine_5_0.05_0.0005/run.log
--- a/outputs_Jintang_DualAdarnn_weather_cosine_5_0.05_0.0005/run.log	(revision 4d374eb052e73a15d49eb92596cef4473d6d2218)
+++ b/outputs_Jintang_DualAdarnn_weather_cosine_5_0.05_0.0005/run.log	(date 1649924095940)
@@ -647,3 +647,1055 @@
 [2022-04-12 20:54:38] - create model_king...
 [2022-04-12 20:54:38] - Epoch: 0
 [2022-04-12 20:54:38] - training...
+[2022-04-13 14:33:12] - create model_king...
+[2022-04-13 14:33:12] - Epoch: 0
+[2022-04-13 14:33:12] - training...
+[2022-04-13 14:33:20] - [ 1.14868282e+00  3.82613134e-01 -1.81951020e-08] 0.23684507392738996
+[2022-04-13 14:33:20] - evaluating...
+[2022-04-13 14:33:25] - valid_l1 0.183820, test_l1 0.077103
+[2022-04-13 14:33:25] - valid_dtw 0.474110, test_dtw 0.201745
+[2022-04-13 14:33:25] - Epoch: 1
+[2022-04-13 14:33:25] - training...
+[2022-04-13 14:33:30] - [-1.00678439e-02 -9.15657054e-02 -4.14095436e-08] 0.1845317290801751
+[2022-04-13 14:33:30] - evaluating...
+[2022-04-13 14:33:34] - valid_l1 0.187281, test_l1 0.081491
+[2022-04-13 14:33:34] - valid_dtw 0.482869, test_dtw 0.212428
+[2022-04-13 14:33:34] - Epoch: 2
+[2022-04-13 14:33:34] - training...
+[2022-04-13 14:33:39] - [-2.72022101e-01 -1.69744765e-01 -2.69789441e-08] 0.15302128070279172
+[2022-04-13 14:33:39] - evaluating...
+[2022-04-13 14:33:43] - valid_l1 0.124298, test_l1 0.058199
+[2022-04-13 14:33:43] - valid_dtw 0.322940, test_dtw 0.149665
+[2022-04-13 14:33:43] - Epoch: 3
+[2022-04-13 14:33:43] - training...
+[2022-04-13 14:33:49] - [-5.76211332e-01 -2.18579847e-01 -6.90159013e-09] 0.13013210971104472
+[2022-04-13 14:33:49] - evaluating...
+[2022-04-13 14:33:52] - valid_l1 0.195691, test_l1 0.281960
+[2022-04-13 14:33:52] - valid_dtw 0.519728, test_dtw 0.742101
+[2022-04-13 14:33:52] - Epoch: 4
+[2022-04-13 14:33:52] - training...
+[2022-04-13 14:33:58] - [-0.71784537 -0.28052665  0.        ] 0.08795353652615297
+[2022-04-13 14:33:58] - evaluating...
+[2022-04-13 14:34:02] - valid_l1 0.247163, test_l1 0.389709
+[2022-04-13 14:34:02] - valid_dtw 0.668567, test_dtw 1.041349
+[2022-04-13 14:34:02] - Epoch: 5
+[2022-04-13 14:34:02] - training...
+[2022-04-13 14:34:08] - [-7.74424727e-01 -3.03220828e-01 -1.47439444e-08] 0.079936394173848
+[2022-04-13 14:34:08] - evaluating...
+[2022-04-13 14:34:12] - valid_l1 0.156674, test_l1 0.219847
+[2022-04-13 14:34:12] - valid_dtw 0.440431, test_dtw 0.579010
+[2022-04-13 14:34:12] - Epoch: 6
+[2022-04-13 14:34:12] - training...
+[2022-04-13 14:34:18] - [-0.6948379  -0.25919597  0.00243592] 0.09703690127322548
+[2022-04-13 14:34:18] - evaluating...
+[2022-04-13 14:34:22] - valid_l1 0.187683, test_l1 0.276025
+[2022-04-13 14:34:22] - valid_dtw 0.508919, test_dtw 0.735822
+[2022-04-13 14:34:22] - Epoch: 7
+[2022-04-13 14:34:22] - training...
+[2022-04-13 14:34:27] - [-7.01057713e-01 -2.80094465e-01 -1.86371108e-09] 0.08603482693433762
+[2022-04-13 14:34:27] - evaluating...
+[2022-04-13 14:34:31] - valid_l1 0.240071, test_l1 0.323197
+[2022-04-13 14:34:31] - valid_dtw 0.652556, test_dtw 0.857540
+[2022-04-13 14:34:31] - Epoch: 8
+[2022-04-13 14:34:31] - training...
+[2022-04-13 14:34:36] - [-7.37458213e-01 -3.08627280e-01 -1.32090554e-08] 0.07510313195617575
+[2022-04-13 14:34:36] - evaluating...
+[2022-04-13 14:34:40] - valid_l1 0.232888, test_l1 0.278311
+[2022-04-13 14:34:40] - valid_dtw 0.628142, test_dtw 0.737386
+[2022-04-13 14:34:40] - Epoch: 9
+[2022-04-13 14:34:40] - training...
+[2022-04-13 14:34:46] - [-6.75976127e-01 -2.66325511e-01 -5.35900643e-09] 0.09005614095612575
+[2022-04-13 14:34:46] - evaluating...
+[2022-04-13 14:34:49] - valid_l1 0.197876, test_l1 0.307911
+[2022-04-13 14:34:49] - valid_dtw 0.539508, test_dtw 0.820191
+[2022-04-13 14:34:49] - Epoch: 10
+[2022-04-13 14:34:49] - training...
+[2022-04-13 14:34:55] - [-6.92117732e-01 -2.49940030e-01 -1.01052379e-08] 0.09730989995755647
+[2022-04-13 14:34:55] - evaluating...
+[2022-04-13 14:34:59] - valid_l1 0.159971, test_l1 0.211787
+[2022-04-13 14:34:59] - valid_dtw 0.433375, test_dtw 0.561710
+[2022-04-13 14:34:59] - Epoch: 11
+[2022-04-13 14:34:59] - training...
+[2022-04-13 14:35:04] - [-6.77496726e-01 -2.53129821e-01 -1.63756982e-08] 0.09951260823168252
+[2022-04-13 14:35:04] - evaluating...
+[2022-04-13 14:35:08] - valid_l1 0.084768, test_l1 0.111357
+[2022-04-13 14:35:08] - valid_dtw 0.245597, test_dtw 0.285786
+[2022-04-13 14:35:08] - Epoch: 12
+[2022-04-13 14:35:08] - training...
+[2022-04-13 14:35:13] - [-6.97387824e-01 -2.54969498e-01 -2.19848172e-09] 0.09305851102659576
+[2022-04-13 14:35:13] - evaluating...
+[2022-04-13 14:35:17] - valid_l1 0.079222, test_l1 0.071627
+[2022-04-13 14:35:17] - valid_dtw 0.238466, test_dtw 0.185324
+[2022-04-13 14:35:17] - Epoch: 13
+[2022-04-13 14:35:17] - training...
+[2022-04-13 14:35:23] - [-7.55912417e-01 -2.75567373e-01  4.43889804e-09] 0.08668546260971773
+[2022-04-13 14:35:23] - evaluating...
+[2022-04-13 14:35:26] - valid_l1 0.118020, test_l1 0.111774
+[2022-04-13 14:35:26] - valid_dtw 0.337644, test_dtw 0.288141
+[2022-04-13 14:35:26] - Epoch: 14
+[2022-04-13 14:35:26] - training...
+[2022-04-13 14:35:32] - [-7.32256381e-01 -2.89537485e-01 -4.10567335e-09] 0.07908651507214497
+[2022-04-13 14:35:32] - evaluating...
+[2022-04-13 14:35:35] - valid_l1 0.109328, test_l1 0.176431
+[2022-04-13 14:35:35] - valid_dtw 0.321640, test_dtw 0.463721
+[2022-04-13 14:35:35] - best val score: 0.010674149707968657 @ 12
+[2022-04-13 14:35:35] - inference...
+[2022-04-13 14:35:39] - MSE: train 0.013691, valid 0.010143, test 0.007938
+[2022-04-13 14:35:39] - L1:  train 0.079771, valid 0.076972, test 0.075697
+[2022-04-13 14:35:39] - RMSE: train 0.114642, valid 0.096112, test 0.084867
+[2022-04-13 14:35:39] - DTW: train 0.282414, valid 0.234050, test 0.192184
+[2022-04-13 14:35:39] - TDI: train 0.278468, valid 0.392059, test 0.514729
+[2022-04-13 14:35:39] - Finished.
+[2022-04-13 16:14:56] - create model_king...
+[2022-04-13 16:14:56] - Epoch: 0
+[2022-04-13 16:14:56] - training...
+[2022-04-13 17:36:05] - create model_king...
+[2022-04-13 17:36:05] - Epoch: 0
+[2022-04-13 17:36:05] - training...
+[2022-04-13 17:36:13] - [ 1.10695992e+00  3.66106134e-01 -1.75676852e-08] 0.2357358481538923
+[2022-04-13 17:36:13] - evaluating...
+[2022-04-13 17:36:18] - valid_l1 0.191663, test_l1 0.081598
+[2022-04-13 17:36:18] - valid_dtw 0.494681, test_dtw 0.212231
+[2022-04-13 17:36:18] - Epoch: 1
+[2022-04-13 17:36:18] - training...
+[2022-04-13 17:36:23] - [-2.15536332e-01 -1.73493771e-01 -2.94886143e-08] 0.18354491301273046
+[2022-04-13 17:36:23] - evaluating...
+[2022-04-13 17:36:27] - valid_l1 0.186165, test_l1 0.080183
+[2022-04-13 17:36:27] - valid_dtw 0.479761, test_dtw 0.208704
+[2022-04-13 17:36:27] - Epoch: 2
+[2022-04-13 17:36:27] - training...
+[2022-04-13 17:36:33] - [-5.30754865e-01 -2.64957879e-01 -2.63515277e-08] 0.15378367038149582
+[2022-04-13 17:36:33] - evaluating...
+[2022-04-13 17:36:37] - valid_l1 0.119959, test_l1 0.055446
+[2022-04-13 17:36:37] - valid_dtw 0.311115, test_dtw 0.142177
+[2022-04-13 17:36:37] - Epoch: 3
+[2022-04-13 17:36:37] - training...
+[2022-04-13 17:36:43] - [-9.01821638e-01 -3.26389894e-01 -2.32144403e-08] 0.1307175912355122
+[2022-04-13 17:36:43] - evaluating...
+[2022-04-13 17:36:46] - valid_l1 0.185307, test_l1 0.273083
+[2022-04-13 17:36:46] - valid_dtw 0.492743, test_dtw 0.718252
+[2022-04-13 17:36:46] - Epoch: 4
+[2022-04-13 17:36:46] - training...
+[2022-04-13 17:36:52] - [-1.06395586e+00 -3.91901074e-01 -2.25870228e-08] 0.09106410294771194
+[2022-04-13 17:36:52] - evaluating...
+[2022-04-13 17:36:56] - valid_l1 0.227706, test_l1 0.349577
+[2022-04-13 17:36:56] - valid_dtw 0.617366, test_dtw 0.933179
+[2022-04-13 17:36:56] - Epoch: 5
+[2022-04-13 17:36:56] - training...
+[2022-04-13 17:37:02] - [-1.1200923  -0.42262728  0.00158811] 0.08035951656730551
+[2022-04-13 17:37:02] - evaluating...
+[2022-04-13 17:37:05] - valid_l1 0.151810, test_l1 0.214640
+[2022-04-13 17:37:05] - valid_dtw 0.427050, test_dtw 0.564425
+[2022-04-13 17:37:05] - Epoch: 6
+[2022-04-13 17:37:05] - training...
+[2022-04-13 17:37:11] - [-1.03665511e+00 -3.76269888e-01 -2.23847338e-09] 0.09702720924427635
+[2022-04-13 17:37:11] - evaluating...
+[2022-04-13 17:37:15] - valid_l1 0.178051, test_l1 0.260008
+[2022-04-13 17:37:15] - valid_dtw 0.482718, test_dtw 0.691807
+[2022-04-13 17:37:15] - Epoch: 7
+[2022-04-13 17:37:15] - training...
+[2022-04-13 17:37:20] - [-1.05043235e+00 -4.06350963e-01 -1.12810085e-08] 0.08505096757098247
+[2022-04-13 17:37:20] - evaluating...
+[2022-04-13 17:37:24] - valid_l1 0.235968, test_l1 0.322914
+[2022-04-13 17:37:24] - valid_dtw 0.642904, test_dtw 0.856877
+[2022-04-13 17:37:24] - Epoch: 8
+[2022-04-13 17:37:24] - training...
+[2022-04-13 17:37:30] - [-1.08700282e+00 -4.31427656e-01  6.22332095e-09] 0.07535130432561825
+[2022-04-13 17:37:30] - evaluating...
+[2022-04-13 17:37:33] - valid_l1 0.221938, test_l1 0.263095
+[2022-04-13 17:37:33] - valid_dtw 0.598494, test_dtw 0.696312
+[2022-04-13 17:37:33] - Epoch: 9
+[2022-04-13 17:37:33] - training...
+[2022-04-13 17:37:39] - [-1.02072689e+00 -3.90186938e-01 -3.51674054e-09] 0.08820026583577457
+[2022-04-13 17:37:39] - evaluating...
+[2022-04-13 17:37:43] - valid_l1 0.199829, test_l1 0.309165
+[2022-04-13 17:37:43] - valid_dtw 0.545668, test_dtw 0.823036
+[2022-04-13 17:37:43] - Epoch: 10
+[2022-04-13 17:37:43] - training...
+[2022-04-13 17:37:49] - [-1.05621353e+00 -3.86204316e-01 -1.62395550e-09] 0.09152966973028685
+[2022-04-13 17:37:49] - evaluating...
+[2022-04-13 17:37:53] - valid_l1 0.213397, test_l1 0.307671
+[2022-04-13 17:37:53] - valid_dtw 0.576076, test_dtw 0.825211
+[2022-04-13 17:37:53] - Epoch: 11
+[2022-04-13 17:37:53] - training...
+[2022-04-13 17:37:58] - [-1.08202579e+00 -3.96314354e-01  1.56731302e-09] 0.08931507876044825
+[2022-04-13 17:37:58] - evaluating...
+[2022-04-13 17:38:02] - valid_l1 0.146676, test_l1 0.221845
+[2022-04-13 17:38:02] - valid_dtw 0.411316, test_dtw 0.586259
+[2022-04-13 17:38:02] - Epoch: 12
+[2022-04-13 17:38:02] - training...
+[2022-04-13 17:38:08] - [-1.05176311e+00 -3.99713161e-01 -1.69080704e-08] 0.08170162553065702
+[2022-04-13 17:38:08] - evaluating...
+[2022-04-13 17:38:12] - valid_l1 0.085939, test_l1 0.094227
+[2022-04-13 17:38:12] - valid_dtw 0.251653, test_dtw 0.243298
+[2022-04-13 17:38:12] - Epoch: 13
+[2022-04-13 17:38:12] - training...
+[2022-04-13 17:38:18] - [-1.10578814e+00 -3.89669275e-01 -8.16428445e-09] 0.08813301297394853
+[2022-04-13 17:38:18] - evaluating...
+[2022-04-13 17:38:21] - valid_l1 0.147473, test_l1 0.166443
+[2022-04-13 17:38:21] - valid_dtw 0.416581, test_dtw 0.435859
+[2022-04-13 17:38:21] - Epoch: 14
+[2022-04-13 17:38:21] - training...
+[2022-04-13 17:38:27] - [-1.03292699e+00 -3.84095879e-01 -3.59241993e-10] 0.08682168137870337
+[2022-04-13 17:38:27] - evaluating...
+[2022-04-13 17:38:31] - valid_l1 0.137830, test_l1 0.222822
+[2022-04-13 17:38:31] - valid_dtw 0.389167, test_dtw 0.589869
+[2022-04-13 17:38:31] - best val score: 0.01188134216160203 @ 12
+[2022-04-13 17:38:31] - inference...
+[2022-04-13 17:38:34] - MSE: train 0.012374, valid 0.011365, test 0.012964
+[2022-04-13 17:38:34] - L1:  train 0.074788, valid 0.083641, test 0.100042
+[2022-04-13 17:38:34] - RMSE: train 0.108601, valid 0.101402, test 0.109398
+[2022-04-13 17:38:34] - DTW: train 0.266930, valid 0.247287, test 0.254753
+[2022-04-13 17:38:34] - TDI: train 0.314642, valid 0.409098, test 0.549950
+[2022-04-13 17:38:34] - Finished.
+[2022-04-13 20:24:30] - create model_king...
+[2022-04-13 20:24:30] - Epoch: 0
+[2022-04-13 20:24:30] - training...
+[2022-04-13 20:24:39] - [ 1.10695992e+00  3.66106134e-01 -1.75676852e-08] 0.2357358481538923
+[2022-04-13 20:24:39] - evaluating...
+[2022-04-13 20:24:43] - valid_l1 0.191663, test_l1 0.081598
+[2022-04-13 20:24:43] - valid_dtw 0.494681, test_dtw 0.212231
+[2022-04-13 20:24:43] - Epoch: 1
+[2022-04-13 20:24:43] - training...
+[2022-04-13 20:24:50] - [-2.15536332e-01 -1.73493771e-01 -2.94886143e-08] 0.18354491301273046
+[2022-04-13 20:24:50] - evaluating...
+[2022-04-13 20:24:54] - valid_l1 0.186165, test_l1 0.080183
+[2022-04-13 20:24:54] - valid_dtw 0.479761, test_dtw 0.208704
+[2022-04-13 20:24:54] - Epoch: 2
+[2022-04-13 20:24:54] - training...
+[2022-04-13 20:25:01] - [-5.30754865e-01 -2.64957879e-01 -2.63515277e-08] 0.15378367038149582
+[2022-04-13 20:25:01] - evaluating...
+[2022-04-13 20:25:04] - valid_l1 0.119959, test_l1 0.055446
+[2022-04-13 20:25:04] - valid_dtw 0.311115, test_dtw 0.142177
+[2022-04-13 20:25:04] - Epoch: 3
+[2022-04-13 20:25:04] - training...
+[2022-04-13 20:25:11] - [-9.01821638e-01 -3.26389894e-01 -2.32144403e-08] 0.1307175912355122
+[2022-04-13 20:25:11] - evaluating...
+[2022-04-13 20:25:15] - valid_l1 0.185307, test_l1 0.273083
+[2022-04-13 20:25:15] - valid_dtw 0.492743, test_dtw 0.718252
+[2022-04-13 20:25:15] - Epoch: 4
+[2022-04-13 20:25:15] - training...
+[2022-04-13 20:25:22] - [-1.06395586e+00 -3.91901074e-01 -2.25870228e-08] 0.09106410294771194
+[2022-04-13 20:25:22] - evaluating...
+[2022-04-13 20:25:26] - valid_l1 0.227706, test_l1 0.349577
+[2022-04-13 20:25:26] - valid_dtw 0.617366, test_dtw 0.933179
+[2022-04-13 20:25:26] - Epoch: 5
+[2022-04-13 20:25:26] - training...
+[2022-04-13 20:25:33] - [-1.1200923  -0.42262728  0.00158811] 0.08035951656730551
+[2022-04-13 20:25:33] - evaluating...
+[2022-04-13 20:25:37] - valid_l1 0.151810, test_l1 0.214640
+[2022-04-13 20:25:37] - valid_dtw 0.427050, test_dtw 0.564425
+[2022-04-13 20:25:37] - Epoch: 6
+[2022-04-13 20:25:37] - training...
+[2022-04-13 20:25:44] - [-1.03665511e+00 -3.76269888e-01 -2.23847338e-09] 0.09702720924427635
+[2022-04-13 20:25:44] - evaluating...
+[2022-04-13 20:25:48] - valid_l1 0.178051, test_l1 0.260008
+[2022-04-13 20:25:48] - valid_dtw 0.482718, test_dtw 0.691807
+[2022-04-13 20:25:48] - Epoch: 7
+[2022-04-13 20:25:48] - training...
+[2022-04-13 20:25:55] - [-1.05043235e+00 -4.06350963e-01 -1.12810085e-08] 0.08505096757098247
+[2022-04-13 20:25:55] - evaluating...
+[2022-04-13 20:25:59] - valid_l1 0.235968, test_l1 0.322914
+[2022-04-13 20:25:59] - valid_dtw 0.642904, test_dtw 0.856877
+[2022-04-13 20:25:59] - Epoch: 8
+[2022-04-13 20:25:59] - training...
+[2022-04-13 20:26:06] - [-1.08700282e+00 -4.31427656e-01  6.22332095e-09] 0.07535130432561825
+[2022-04-13 20:26:06] - evaluating...
+[2022-04-13 20:26:09] - valid_l1 0.221938, test_l1 0.263095
+[2022-04-13 20:26:09] - valid_dtw 0.598494, test_dtw 0.696312
+[2022-04-13 20:26:09] - Epoch: 9
+[2022-04-13 20:26:09] - training...
+[2022-04-13 20:26:16] - [-1.02072689e+00 -3.90186938e-01 -3.51674054e-09] 0.08820026583577457
+[2022-04-13 20:26:16] - evaluating...
+[2022-04-13 20:26:20] - valid_l1 0.199829, test_l1 0.309165
+[2022-04-13 20:26:20] - valid_dtw 0.545668, test_dtw 0.823036
+[2022-04-13 20:26:20] - Epoch: 10
+[2022-04-13 20:26:20] - training...
+[2022-04-13 20:26:27] - [-1.05621353e+00 -3.86204316e-01 -1.62395550e-09] 0.09152966973028685
+[2022-04-13 20:26:27] - evaluating...
+[2022-04-13 20:26:30] - valid_l1 0.213397, test_l1 0.307671
+[2022-04-13 20:26:30] - valid_dtw 0.576076, test_dtw 0.825211
+[2022-04-13 20:26:30] - Epoch: 11
+[2022-04-13 20:26:30] - training...
+[2022-04-13 20:26:37] - [-1.08202579e+00 -3.96314354e-01  1.56731302e-09] 0.08931507876044825
+[2022-04-13 20:26:37] - evaluating...
+[2022-04-13 20:26:41] - valid_l1 0.146676, test_l1 0.221845
+[2022-04-13 20:26:41] - valid_dtw 0.411316, test_dtw 0.586259
+[2022-04-13 20:26:41] - Epoch: 12
+[2022-04-13 20:26:41] - training...
+[2022-04-13 20:26:48] - [-1.05176311e+00 -3.99713161e-01 -1.69080704e-08] 0.08170162553065702
+[2022-04-13 20:26:48] - evaluating...
+[2022-04-13 20:26:52] - valid_l1 0.085939, test_l1 0.094227
+[2022-04-13 20:26:52] - valid_dtw 0.251653, test_dtw 0.243298
+[2022-04-13 20:26:52] - Epoch: 13
+[2022-04-13 20:26:52] - training...
+[2022-04-13 20:26:59] - [-1.10578814e+00 -3.89669275e-01 -8.16428445e-09] 0.08813301297394853
+[2022-04-13 20:26:59] - evaluating...
+[2022-04-13 20:27:02] - valid_l1 0.147473, test_l1 0.166443
+[2022-04-13 20:27:02] - valid_dtw 0.416581, test_dtw 0.435859
+[2022-04-13 20:27:02] - Epoch: 14
+[2022-04-13 20:27:02] - training...
+[2022-04-13 20:27:09] - [-1.03292699e+00 -3.84095879e-01 -3.59241993e-10] 0.08682168137870337
+[2022-04-13 20:27:09] - evaluating...
+[2022-04-13 20:27:13] - valid_l1 0.137830, test_l1 0.222822
+[2022-04-13 20:27:13] - valid_dtw 0.389167, test_dtw 0.589869
+[2022-04-13 20:27:13] - best val score: 0.01188134216160203 @ 12
+[2022-04-13 20:27:13] - inference...
+[2022-04-13 20:27:16] - MSE: train 0.012374, valid 0.011365, test 0.012964
+[2022-04-13 20:27:16] - L1:  train 0.074788, valid 0.083641, test 0.100042
+[2022-04-13 20:27:16] - RMSE: train 0.108601, valid 0.101402, test 0.109398
+[2022-04-13 20:27:16] - DTW: train 0.266930, valid 0.247287, test 0.254753
+[2022-04-13 20:27:16] - TDI: train 0.314642, valid 0.409098, test 0.549950
+[2022-04-13 20:27:16] - Finished.
+[2022-04-14 10:02:57] - create model_king...
+[2022-04-14 10:02:57] - Epoch: 0
+[2022-04-14 10:02:57] - training...
+[2022-04-14 10:04:39] - create model_king...
+[2022-04-14 10:04:39] - Epoch: 0
+[2022-04-14 10:04:39] - training...
+[2022-04-14 10:07:37] - create model_king...
+[2022-04-14 10:07:37] - Epoch: 0
+[2022-04-14 10:07:37] - training...
+[2022-04-14 10:07:46] - [ 1.10695992e+00  3.66106134e-01 -1.75676852e-08] 0.2357358481538923
+[2022-04-14 10:07:46] - evaluating...
+[2022-04-14 10:07:51] - valid_l1 0.191663, test_l1 0.081598
+[2022-04-14 10:07:51] - valid_dtw 0.494681, test_dtw 0.212231
+[2022-04-14 10:07:51] - Epoch: 1
+[2022-04-14 10:07:51] - training...
+[2022-04-14 10:07:57] - [-2.15536332e-01 -1.73493771e-01 -2.94886143e-08] 0.18354491301273046
+[2022-04-14 10:07:57] - evaluating...
+[2022-04-14 10:08:01] - valid_l1 0.186165, test_l1 0.080183
+[2022-04-14 10:08:01] - valid_dtw 0.479761, test_dtw 0.208704
+[2022-04-14 10:08:01] - Epoch: 2
+[2022-04-14 10:08:01] - training...
+[2022-04-14 10:08:08] - [-5.30754865e-01 -2.64957879e-01 -2.63515277e-08] 0.15378367038149582
+[2022-04-14 10:08:08] - evaluating...
+[2022-04-14 10:08:12] - valid_l1 0.119959, test_l1 0.055446
+[2022-04-14 10:08:12] - valid_dtw 0.311115, test_dtw 0.142177
+[2022-04-14 10:08:12] - Epoch: 3
+[2022-04-14 10:08:12] - training...
+[2022-04-14 10:08:19] - [-9.01821638e-01 -3.26389894e-01 -2.32144403e-08] 0.1307175912355122
+[2022-04-14 10:08:19] - evaluating...
+[2022-04-14 10:08:23] - valid_l1 0.185307, test_l1 0.273083
+[2022-04-14 10:08:23] - valid_dtw 0.492743, test_dtw 0.718252
+[2022-04-14 10:08:23] - Epoch: 4
+[2022-04-14 10:08:23] - training...
+[2022-04-14 10:08:30] - [-1.06395586e+00 -3.91901074e-01 -2.25870228e-08] 0.09106410294771194
+[2022-04-14 10:08:30] - evaluating...
+[2022-04-14 10:08:33] - valid_l1 0.227706, test_l1 0.349577
+[2022-04-14 10:08:33] - valid_dtw 0.617366, test_dtw 0.933179
+[2022-04-14 10:08:33] - Epoch: 5
+[2022-04-14 10:08:33] - training...
+[2022-04-14 10:08:40] - [-1.1200923  -0.42262728  0.00158811] 0.08035951656730551
+[2022-04-14 10:08:40] - evaluating...
+[2022-04-14 10:08:44] - valid_l1 0.151810, test_l1 0.214640
+[2022-04-14 10:08:44] - valid_dtw 0.427050, test_dtw 0.564425
+[2022-04-14 10:08:44] - Epoch: 6
+[2022-04-14 10:08:44] - training...
+[2022-04-14 10:08:51] - [-1.03665511e+00 -3.76269888e-01 -2.23847338e-09] 0.09702720924427635
+[2022-04-14 10:08:51] - evaluating...
+[2022-04-14 10:08:54] - valid_l1 0.178051, test_l1 0.260008
+[2022-04-14 10:08:54] - valid_dtw 0.482718, test_dtw 0.691807
+[2022-04-14 10:08:54] - Epoch: 7
+[2022-04-14 10:08:54] - training...
+[2022-04-14 10:09:02] - [-1.05043235e+00 -4.06350963e-01 -1.12810085e-08] 0.08505096757098247
+[2022-04-14 10:09:02] - evaluating...
+[2022-04-14 10:09:06] - valid_l1 0.235968, test_l1 0.322914
+[2022-04-14 10:09:06] - valid_dtw 0.642904, test_dtw 0.856877
+[2022-04-14 10:09:06] - Epoch: 8
+[2022-04-14 10:09:06] - training...
+[2022-04-14 10:09:07] - create model_king...
+[2022-04-14 10:09:07] - Epoch: 0
+[2022-04-14 10:09:07] - training...
+[2022-04-14 10:09:12] - [-1.08700282e+00 -4.31427656e-01  6.22332095e-09] 0.07535130432561825
+[2022-04-14 10:09:12] - evaluating...
+[2022-04-14 10:09:15] - [ 1.10695992e+00  3.66106134e-01 -1.75676852e-08] 0.2357358481538923
+[2022-04-14 10:09:15] - evaluating...
+[2022-04-14 10:09:16] - valid_l1 0.221938, test_l1 0.263095
+[2022-04-14 10:09:16] - valid_dtw 0.598494, test_dtw 0.696312
+[2022-04-14 10:09:16] - Epoch: 9
+[2022-04-14 10:09:16] - training...
+[2022-04-14 10:09:19] - valid_l1 0.191663, test_l1 0.081598
+[2022-04-14 10:09:19] - valid_dtw 0.494681, test_dtw 0.212231
+[2022-04-14 10:09:19] - Epoch: 1
+[2022-04-14 10:09:19] - training...
+[2022-04-14 10:09:22] - [-1.02072689e+00 -3.90186938e-01 -3.51674054e-09] 0.08820026583577457
+[2022-04-14 10:09:22] - evaluating...
+[2022-04-14 10:09:25] - [-2.15536332e-01 -1.73493771e-01 -2.94886143e-08] 0.18354491301273046
+[2022-04-14 10:09:25] - evaluating...
+[2022-04-14 10:09:26] - valid_l1 0.199829, test_l1 0.309165
+[2022-04-14 10:09:26] - valid_dtw 0.545668, test_dtw 0.823036
+[2022-04-14 10:09:26] - Epoch: 10
+[2022-04-14 10:09:26] - training...
+[2022-04-14 10:09:29] - valid_l1 0.186165, test_l1 0.080183
+[2022-04-14 10:09:29] - valid_dtw 0.479761, test_dtw 0.208704
+[2022-04-14 10:09:29] - Epoch: 2
+[2022-04-14 10:09:29] - training...
+[2022-04-14 10:09:33] - [-1.05621353e+00 -3.86204316e-01 -1.62395550e-09] 0.09152966973028685
+[2022-04-14 10:09:33] - evaluating...
+[2022-04-14 10:09:34] - [-5.30754865e-01 -2.64957879e-01 -2.63515277e-08] 0.15378367038149582
+[2022-04-14 10:09:34] - evaluating...
+[2022-04-14 10:09:36] - valid_l1 0.213397, test_l1 0.307671
+[2022-04-14 10:09:36] - valid_dtw 0.576076, test_dtw 0.825211
+[2022-04-14 10:09:36] - Epoch: 11
+[2022-04-14 10:09:36] - training...
+[2022-04-14 10:09:38] - valid_l1 0.119959, test_l1 0.055446
+[2022-04-14 10:09:38] - valid_dtw 0.311115, test_dtw 0.142177
+[2022-04-14 10:09:38] - Epoch: 3
+[2022-04-14 10:09:38] - training...
+[2022-04-14 10:09:43] - [-1.08202579e+00 -3.96314354e-01  1.56731302e-09] 0.08931507876044825
+[2022-04-14 10:09:43] - evaluating...
+[2022-04-14 10:09:44] - [-9.01821638e-01 -3.26389894e-01 -2.32144403e-08] 0.1307175912355122
+[2022-04-14 10:09:44] - evaluating...
+[2022-04-14 10:09:47] - valid_l1 0.146676, test_l1 0.221845
+[2022-04-14 10:09:47] - valid_dtw 0.411316, test_dtw 0.586259
+[2022-04-14 10:09:47] - Epoch: 12
+[2022-04-14 10:09:47] - training...
+[2022-04-14 10:09:47] - valid_l1 0.185307, test_l1 0.273083
+[2022-04-14 10:09:47] - valid_dtw 0.492743, test_dtw 0.718252
+[2022-04-14 10:09:47] - Epoch: 4
+[2022-04-14 10:09:47] - training...
+[2022-04-14 10:09:53] - [-1.06395586e+00 -3.91901074e-01 -2.25870228e-08] 0.09106410294771194
+[2022-04-14 10:09:53] - evaluating...
+[2022-04-14 10:09:53] - [-1.05176311e+00 -3.99713161e-01 -1.69080704e-08] 0.08170162553065702
+[2022-04-14 10:09:53] - evaluating...
+[2022-04-14 10:09:56] - valid_l1 0.227706, test_l1 0.349577
+[2022-04-14 10:09:56] - valid_dtw 0.617366, test_dtw 0.933179
+[2022-04-14 10:09:56] - Epoch: 5
+[2022-04-14 10:09:56] - training...
+[2022-04-14 10:09:57] - valid_l1 0.085939, test_l1 0.094227
+[2022-04-14 10:09:57] - valid_dtw 0.251653, test_dtw 0.243298
+[2022-04-14 10:09:57] - Epoch: 13
+[2022-04-14 10:09:57] - training...
+[2022-04-14 10:10:02] - [-1.1200923  -0.42262728  0.00158811] 0.08035951656730551
+[2022-04-14 10:10:02] - evaluating...
+[2022-04-14 10:10:04] - [-1.10578814e+00 -3.89669275e-01 -8.16428445e-09] 0.08813301297394853
+[2022-04-14 10:10:04] - evaluating...
+[2022-04-14 10:10:06] - valid_l1 0.151810, test_l1 0.214640
+[2022-04-14 10:10:06] - valid_dtw 0.427050, test_dtw 0.564425
+[2022-04-14 10:10:06] - Epoch: 6
+[2022-04-14 10:10:06] - training...
+[2022-04-14 10:10:07] - valid_l1 0.147473, test_l1 0.166443
+[2022-04-14 10:10:07] - valid_dtw 0.416581, test_dtw 0.435859
+[2022-04-14 10:10:07] - Epoch: 14
+[2022-04-14 10:10:07] - training...
+[2022-04-14 10:10:12] - [-1.03665511e+00 -3.76269888e-01 -2.23847338e-09] 0.09702720924427635
+[2022-04-14 10:10:12] - evaluating...
+[2022-04-14 10:10:14] - [-1.03292699e+00 -3.84095879e-01 -3.59241993e-10] 0.08682168137870337
+[2022-04-14 10:10:14] - evaluating...
+[2022-04-14 10:10:16] - valid_l1 0.178051, test_l1 0.260008
+[2022-04-14 10:10:16] - valid_dtw 0.482718, test_dtw 0.691807
+[2022-04-14 10:10:16] - Epoch: 7
+[2022-04-14 10:10:16] - training...
+[2022-04-14 10:10:18] - valid_l1 0.137830, test_l1 0.222822
+[2022-04-14 10:10:18] - valid_dtw 0.389167, test_dtw 0.589869
+[2022-04-14 10:10:18] - best val score: 0.01188134216160203 @ 12
+[2022-04-14 10:10:18] - inference...
+[2022-04-14 10:10:22] - [-1.05043235e+00 -4.06350963e-01 -1.12810085e-08] 0.08505096757098247
+[2022-04-14 10:10:22] - evaluating...
+[2022-04-14 10:10:22] - MSE: train 0.012374, valid 0.011365, test 0.012964
+[2022-04-14 10:10:22] - L1:  train 0.074788, valid 0.083641, test 0.100042
+[2022-04-14 10:10:22] - RMSE: train 0.108601, valid 0.101402, test 0.109398
+[2022-04-14 10:10:22] - DTW: train 0.266930, valid 0.247287, test 0.254753
+[2022-04-14 10:10:22] - TDI: train 0.314642, valid 0.409098, test 0.549950
+[2022-04-14 10:10:22] - Finished.
+[2022-04-14 10:10:25] - valid_l1 0.235968, test_l1 0.322914
+[2022-04-14 10:10:25] - valid_dtw 0.642904, test_dtw 0.856877
+[2022-04-14 10:10:25] - Epoch: 8
+[2022-04-14 10:10:25] - training...
+[2022-04-14 10:10:31] - [-1.08700282e+00 -4.31427656e-01  6.22332095e-09] 0.07535130432561825
+[2022-04-14 10:10:31] - evaluating...
+[2022-04-14 10:10:34] - valid_l1 0.221938, test_l1 0.263095
+[2022-04-14 10:10:34] - valid_dtw 0.598494, test_dtw 0.696312
+[2022-04-14 10:10:34] - Epoch: 9
+[2022-04-14 10:10:34] - training...
+[2022-04-14 10:10:40] - [-1.02072689e+00 -3.90186938e-01 -3.51674054e-09] 0.08820026583577457
+[2022-04-14 10:10:40] - evaluating...
+[2022-04-14 10:10:43] - valid_l1 0.199829, test_l1 0.309165
+[2022-04-14 10:10:43] - valid_dtw 0.545668, test_dtw 0.823036
+[2022-04-14 10:10:43] - Epoch: 10
+[2022-04-14 10:10:43] - training...
+[2022-04-14 10:10:49] - [-1.05621353e+00 -3.86204316e-01 -1.62395550e-09] 0.09152966973028685
+[2022-04-14 10:10:49] - evaluating...
+[2022-04-14 10:10:52] - valid_l1 0.213397, test_l1 0.307671
+[2022-04-14 10:10:52] - valid_dtw 0.576076, test_dtw 0.825211
+[2022-04-14 10:10:52] - Epoch: 11
+[2022-04-14 10:10:52] - training...
+[2022-04-14 10:10:58] - [-1.08202579e+00 -3.96314354e-01  1.56731302e-09] 0.08931507876044825
+[2022-04-14 10:10:58] - evaluating...
+[2022-04-14 10:11:01] - valid_l1 0.146676, test_l1 0.221845
+[2022-04-14 10:11:01] - valid_dtw 0.411316, test_dtw 0.586259
+[2022-04-14 10:11:01] - Epoch: 12
+[2022-04-14 10:11:01] - training...
+[2022-04-14 10:11:07] - [-1.05176311e+00 -3.99713161e-01 -1.69080704e-08] 0.08170162553065702
+[2022-04-14 10:11:07] - evaluating...
+[2022-04-14 10:11:10] - valid_l1 0.085939, test_l1 0.094227
+[2022-04-14 10:11:10] - valid_dtw 0.251653, test_dtw 0.243298
+[2022-04-14 10:11:10] - Epoch: 13
+[2022-04-14 10:11:10] - training...
+[2022-04-14 10:11:15] - [-1.10578814e+00 -3.89669275e-01 -8.16428445e-09] 0.08813301297394853
+[2022-04-14 10:11:15] - evaluating...
+[2022-04-14 10:11:19] - valid_l1 0.147473, test_l1 0.166443
+[2022-04-14 10:11:19] - valid_dtw 0.416581, test_dtw 0.435859
+[2022-04-14 10:11:19] - Epoch: 14
+[2022-04-14 10:11:19] - training...
+[2022-04-14 10:11:24] - [-1.03292699e+00 -3.84095879e-01 -3.59241993e-10] 0.08682168137870337
+[2022-04-14 10:11:24] - evaluating...
+[2022-04-14 10:11:28] - valid_l1 0.137830, test_l1 0.222822
+[2022-04-14 10:11:28] - valid_dtw 0.389167, test_dtw 0.589869
+[2022-04-14 10:11:28] - best val score: 0.01188134216160203 @ 12
+[2022-04-14 10:11:28] - inference...
+[2022-04-14 10:11:32] - MSE: train 0.012374, valid 0.011365, test 0.012964
+[2022-04-14 10:11:32] - L1:  train 0.074788, valid 0.083641, test 0.100042
+[2022-04-14 10:11:32] - RMSE: train 0.108601, valid 0.101402, test 0.109398
+[2022-04-14 10:11:32] - DTW: train 0.266930, valid 0.247287, test 0.254753
+[2022-04-14 10:11:32] - TDI: train 0.314642, valid 0.409098, test 0.549950
+[2022-04-14 10:11:32] - Finished.
+[2022-04-14 12:13:56] - create model_king...
+[2022-04-14 12:13:56] - Epoch: 0
+[2022-04-14 12:13:56] - training...
+[2022-04-14 12:14:04] - [ 2.26660365e+00  7.81377925e-01 -6.90159097e-09] 0.2443375048276625
+[2022-04-14 12:14:04] - evaluating...
+[2022-04-14 12:14:08] - valid_l1 0.149814, test_l1 0.065470
+[2022-04-14 12:14:08] - valid_dtw 0.386744, test_dtw 0.175773
+[2022-04-14 12:14:08] - Epoch: 1
+[2022-04-14 12:14:08] - training...
+[2022-04-14 12:14:14] - [ 1.06371154e+00  2.76953069e-01 -2.44692752e-08] 0.18414642897091413
+[2022-04-14 12:14:14] - evaluating...
+[2022-04-14 12:14:18] - valid_l1 0.184165, test_l1 0.081027
+[2022-04-14 12:14:18] - valid_dtw 0.475380, test_dtw 0.212045
+[2022-04-14 12:14:18] - Epoch: 2
+[2022-04-14 12:14:18] - training...
+[2022-04-14 12:14:24] - [ 9.03447863e-01  2.39585377e-01 -2.44692754e-08] 0.1628395291535478
+[2022-04-14 12:14:24] - evaluating...
+[2022-04-14 12:14:28] - valid_l1 0.139101, test_l1 0.061208
+[2022-04-14 12:14:28] - valid_dtw 0.361190, test_dtw 0.159598
+[2022-04-14 12:14:28] - Epoch: 3
+[2022-04-14 12:14:28] - training...
+[2022-04-14 12:14:34] - [ 7.46279183e-01  2.07984122e-01 -1.69402673e-08] 0.14503816770095573
+[2022-04-14 12:14:34] - evaluating...
+[2022-04-14 12:14:42] - create model_king...
+[2022-04-14 12:14:42] - Epoch: 0
+[2022-04-14 12:14:42] - training...
+[2022-04-14 12:14:50] - [ 2.26660365e+00  7.81377925e-01 -6.90159097e-09] 0.2443375048276625
+[2022-04-14 12:14:50] - evaluating...
+[2022-04-14 12:14:54] - valid_l1 0.149814, test_l1 0.065470
+[2022-04-14 12:14:54] - valid_dtw 0.386744, test_dtw 0.175773
+[2022-04-14 12:14:54] - Epoch: 1
+[2022-04-14 12:14:54] - training...
+[2022-04-14 12:14:59] - [ 1.06371154e+00  2.76953069e-01 -2.44692752e-08] 0.18414642897091413
+[2022-04-14 12:14:59] - evaluating...
+[2022-04-14 12:15:03] - valid_l1 0.184165, test_l1 0.081027
+[2022-04-14 12:15:03] - valid_dtw 0.475380, test_dtw 0.212045
+[2022-04-14 12:15:03] - Epoch: 2
+[2022-04-14 12:15:03] - training...
+[2022-04-14 12:15:09] - [ 9.03447863e-01  2.39585377e-01 -2.44692754e-08] 0.1628395291535478
+[2022-04-14 12:15:09] - evaluating...
+[2022-04-14 12:15:12] - valid_l1 0.139101, test_l1 0.061208
+[2022-04-14 12:15:12] - valid_dtw 0.361190, test_dtw 0.159598
+[2022-04-14 12:15:12] - Epoch: 3
+[2022-04-14 12:15:12] - training...
+[2022-04-14 12:15:17] - [ 7.46279183e-01  2.07984122e-01 -1.69402673e-08] 0.14503816770095573
+[2022-04-14 12:15:17] - evaluating...
+[2022-04-14 12:15:21] - valid_l1 0.256716, test_l1 0.292115
+[2022-04-14 12:15:21] - valid_dtw 0.670299, test_dtw 0.762145
+[2022-04-14 12:15:21] - Epoch: 4
+[2022-04-14 12:15:21] - training...
+[2022-04-14 12:15:28] - [ 6.66663614e-01  1.56719132e-01 -3.82724565e-08] 0.09798314814504824
+[2022-04-14 12:15:28] - evaluating...
+[2022-04-14 12:15:32] - valid_l1 0.307673, test_l1 0.454919
+[2022-04-14 12:15:32] - valid_dtw 0.813251, test_dtw 1.202595
+[2022-04-14 12:15:32] - Epoch: 5
+[2022-04-14 12:15:32] - training...
+[2022-04-14 12:15:38] - [ 5.59203245e-01  1.36958963e-01 -7.88399862e-09] 0.08128770813345909
+[2022-04-14 12:15:38] - evaluating...
+[2022-04-14 12:15:42] - valid_l1 0.214654, test_l1 0.308271
+[2022-04-14 12:15:42] - valid_dtw 0.583364, test_dtw 0.817926
+[2022-04-14 12:15:42] - Epoch: 6
+[2022-04-14 12:15:42] - training...
+[2022-04-14 12:15:48] - [ 6.09871256e-01  1.86109434e-01 -1.47015107e-08] 0.10147643069687642
+[2022-04-14 12:15:48] - evaluating...
+[2022-04-14 12:15:52] - valid_l1 0.161838, test_l1 0.227498
+[2022-04-14 12:15:52] - valid_dtw 0.446481, test_dtw 0.605759
+[2022-04-14 12:15:52] - Epoch: 7
+[2022-04-14 12:15:52] - training...
+[2022-04-14 12:15:57] - [ 5.88215941e-01  1.60393146e-01 -1.58386153e-09] 0.09114673831745197
+[2022-04-14 12:15:57] - evaluating...
+[2022-04-14 12:16:01] - valid_l1 0.221901, test_l1 0.301982
+[2022-04-14 12:16:01] - valid_dtw 0.608059, test_dtw 0.804779
+[2022-04-14 12:16:01] - Epoch: 8
+[2022-04-14 12:16:01] - training...
+[2022-04-14 12:16:07] - [ 5.33359666e-01  1.35081626e-01 -7.87941424e-09] 0.0769810545209207
+[2022-04-14 12:16:07] - evaluating...
+[2022-04-14 12:16:11] - valid_l1 0.221952, test_l1 0.283578
+[2022-04-14 12:16:11] - valid_dtw 0.605527, test_dtw 0.752646
+[2022-04-14 12:16:11] - Epoch: 9
+[2022-04-14 12:16:11] - training...
+[2022-04-14 12:16:17] - [6.35443818e-01 1.58877997e-01 3.56716551e-10] 0.08805630807029574
+[2022-04-14 12:16:17] - evaluating...
+[2022-04-14 12:16:21] - valid_l1 0.226131, test_l1 0.364653
+[2022-04-14 12:16:21] - valid_dtw 0.616005, test_dtw 0.981499
+[2022-04-14 12:16:21] - Epoch: 10
+[2022-04-14 12:16:21] - training...
+[2022-04-14 12:16:27] - [ 5.78887060e-01  1.76669750e-01 -5.62438108e-09] 0.09685603293933366
+[2022-04-14 12:16:27] - evaluating...
+[2022-04-14 12:16:31] - valid_l1 0.222025, test_l1 0.320600
+[2022-04-14 12:16:31] - valid_dtw 0.601729, test_dtw 0.864916
+[2022-04-14 12:16:31] - Epoch: 11
+[2022-04-14 12:16:31] - training...
+[2022-04-14 12:16:36] - [ 5.51582692e-01  1.43030630e-01 -7.10308689e-09] 0.0832090750336647
+[2022-04-14 12:16:36] - evaluating...
+[2022-04-14 12:16:40] - valid_l1 0.150399, test_l1 0.251423
+[2022-04-14 12:16:40] - valid_dtw 0.430198, test_dtw 0.669575
+[2022-04-14 12:16:40] - Epoch: 12
+[2022-04-14 12:16:40] - training...
+[2022-04-14 12:16:46] - [ 5.87279080e-01  1.59677540e-01 -7.89187436e-09] 0.08104838274027172
+[2022-04-14 12:16:46] - evaluating...
+[2022-04-14 12:16:50] - valid_l1 0.084012, test_l1 0.088002
+[2022-04-14 12:16:50] - valid_dtw 0.248584, test_dtw 0.229059
+[2022-04-14 12:16:50] - Epoch: 13
+[2022-04-14 12:16:50] - training...
+[2022-04-14 12:16:56] - [ 5.09091662e-01  1.46910199e-01 -7.19892076e-09] 0.09032333701064713
+[2022-04-14 12:16:56] - evaluating...
+[2022-04-14 12:17:00] - valid_l1 0.133364, test_l1 0.108402
+[2022-04-14 12:17:00] - valid_dtw 0.380226, test_dtw 0.281190
+[2022-04-14 12:17:00] - Epoch: 14
+[2022-04-14 12:17:00] - training...
+[2022-04-14 12:17:06] - [5.31981528e-01 1.35147052e-01 6.56422257e-09] 0.08176220031945329
+[2022-04-14 12:17:06] - evaluating...
+[2022-04-14 12:17:09] - valid_l1 0.104104, test_l1 0.158568
+[2022-04-14 12:17:09] - valid_dtw 0.309413, test_dtw 0.415868
+[2022-04-14 12:17:09] - best val score: 0.011629762351124858 @ 12
+[2022-04-14 12:17:09] - inference...
+[2022-04-14 12:17:13] - MSE: train 0.012825, valid 0.011111, test 0.011572
+[2022-04-14 12:17:13] - L1:  train 0.074193, valid 0.081833, test 0.093107
+[2022-04-14 12:17:13] - RMSE: train 0.110773, valid 0.100288, test 0.103234
+[2022-04-14 12:17:13] - DTW: train 0.273160, valid 0.244934, test 0.239631
+[2022-04-14 12:17:13] - TDI: train 0.298137, valid 0.365378, test 0.515346
+[2022-04-14 12:17:13] - Finished.
+[2022-04-14 13:46:34] - create model_king...
+[2022-04-14 13:46:34] - Epoch: 0
+[2022-04-14 13:46:34] - training...
+[2022-04-14 13:46:42] - [ 2.18033073e+00  7.48780385e-01 -8.78384243e-09] 0.24282761133815112
+[2022-04-14 13:46:42] - evaluating...
+[2022-04-14 13:46:46] - valid_l1 0.157929, test_l1 0.067268
+[2022-04-14 13:46:46] - valid_dtw 0.407373, test_dtw 0.179351
+[2022-04-14 13:46:46] - Epoch: 1
+[2022-04-14 13:46:46] - training...
+[2022-04-14 13:46:52] - [ 9.77150606e-01  2.40920581e-01 -5.64675609e-09] 0.1835867480227822
+[2022-04-14 13:46:52] - evaluating...
+[2022-04-14 13:46:55] - valid_l1 0.187410, test_l1 0.081371
+[2022-04-14 13:46:55] - valid_dtw 0.483609, test_dtw 0.212462
+[2022-04-14 13:46:55] - Epoch: 2
+[2022-04-14 13:46:55] - training...
+[2022-04-14 13:47:01] - [ 7.90914653e-01  1.88951228e-01 -2.63515271e-08] 0.1557404026389122
+[2022-04-14 13:47:01] - evaluating...
+[2022-04-14 13:47:05] - valid_l1 0.140297, test_l1 0.066867
+[2022-04-14 13:47:05] - valid_dtw 0.364085, test_dtw 0.173493
+[2022-04-14 13:47:05] - Epoch: 3
+[2022-04-14 13:47:05] - training...
+[2022-04-14 13:47:10] - [ 5.77099212e-01  1.48190673e-01 -1.63128509e-08] 0.13267468229720467
+[2022-04-14 13:47:10] - evaluating...
+[2022-04-14 13:47:14] - valid_l1 0.257997, test_l1 0.350131
+[2022-04-14 13:47:14] - valid_dtw 0.677981, test_dtw 0.919042
+[2022-04-14 13:47:14] - Epoch: 4
+[2022-04-14 13:47:14] - training...
+[2022-04-14 13:47:20] - [ 4.31705501e-01  8.65560958e-02 -1.19209291e-08] 0.08951078002390109
+[2022-04-14 13:47:20] - evaluating...
+[2022-04-14 13:47:23] - valid_l1 0.214495, test_l1 0.358989
+[2022-04-14 13:47:23] - valid_dtw 0.576759, test_dtw 0.955984
+[2022-04-14 13:47:23] - Epoch: 5
+[2022-04-14 13:47:23] - training...
+[2022-04-14 13:47:29] - [ 3.33237955e-01  6.51223967e-02 -1.28447681e-08] 0.08029239232602872
+[2022-04-14 13:47:29] - evaluating...
+[2022-04-14 13:47:33] - valid_l1 0.179561, test_l1 0.244990
+[2022-04-14 13:47:33] - valid_dtw 0.505707, test_dtw 0.648723
+[2022-04-14 13:47:33] - Epoch: 6
+[2022-04-14 13:47:33] - training...
+[2022-04-14 13:47:38] - [ 4.14705322e-01  1.10471402e-01 -1.62828026e-08] 0.09737608522961014
+[2022-04-14 13:47:38] - evaluating...
+[2022-04-14 13:47:42] - valid_l1 0.174080, test_l1 0.234625
+[2022-04-14 13:47:42] - valid_dtw 0.477097, test_dtw 0.624649
+[2022-04-14 13:47:42] - Epoch: 7
+[2022-04-14 13:47:42] - training...
+[2022-04-14 13:47:48] - [ 4.22997612e-01  1.01194787e-01 -1.13139152e-08] 0.0899323781854228
+[2022-04-14 13:47:48] - evaluating...
+[2022-04-14 13:47:51] - valid_l1 0.234057, test_l1 0.321720
+[2022-04-14 13:47:51] - valid_dtw 0.640657, test_dtw 0.855717
+[2022-04-14 13:47:51] - Epoch: 8
+[2022-04-14 13:47:51] - training...
+[2022-04-14 13:47:57] - [ 3.65276705e-01  7.06995250e-02 -5.33511067e-09] 0.07510718448381674
+[2022-04-14 13:47:57] - evaluating...
+[2022-04-14 13:48:01] - valid_l1 0.216416, test_l1 0.283282
+[2022-04-14 13:48:01] - valid_dtw 0.588455, test_dtw 0.750546
+[2022-04-14 13:48:01] - Epoch: 9
+[2022-04-14 13:48:01] - training...
+[2022-04-14 13:48:07] - [ 4.16023904e-01  6.68472731e-02 -5.05708782e-09] 0.07654905397641032
+[2022-04-14 13:48:07] - evaluating...
+[2022-04-14 13:48:10] - valid_l1 0.250226, test_l1 0.412380
+[2022-04-14 13:48:10] - valid_dtw 0.679145, test_dtw 1.104967
+[2022-04-14 13:48:10] - Epoch: 10
+[2022-04-14 13:48:10] - training...
+[2022-04-14 13:48:16] - [ 3.34891384e-01  8.49560891e-02 -9.12179908e-09] 0.08254731446504593
+[2022-04-14 13:48:16] - evaluating...
+[2022-04-14 13:48:20] - valid_l1 0.202539, test_l1 0.317052
+[2022-04-14 13:48:20] - valid_dtw 0.553490, test_dtw 0.851455
+[2022-04-14 13:48:20] - Epoch: 11
+[2022-04-14 13:48:20] - training...
+[2022-04-14 13:48:26] - [ 3.49756584e-01  6.34835020e-02 -9.59550240e-10] 0.07517224373786073
+[2022-04-14 13:48:26] - evaluating...
+[2022-04-14 13:48:29] - valid_l1 0.136350, test_l1 0.212569
+[2022-04-14 13:48:29] - valid_dtw 0.393530, test_dtw 0.562586
+[2022-04-14 13:48:29] - Epoch: 12
+[2022-04-14 13:48:29] - training...
+[2022-04-14 13:48:35] - [ 4.19676839e-01  1.07603782e-01 -7.23916700e-09] 0.08910313385881875
+[2022-04-14 13:48:35] - evaluating...
+[2022-04-14 13:48:39] - valid_l1 0.142638, test_l1 0.173424
+[2022-04-14 13:48:39] - valid_dtw 0.405993, test_dtw 0.459020
+[2022-04-14 13:48:39] - early stop
+[2022-04-14 13:48:39] - best val score: 0.02318207543964187 @ 2
+[2022-04-14 13:48:39] - inference...
+[2022-04-14 13:48:42] - MSE: train 0.042202, valid 0.024013, test 0.006088
+[2022-04-14 13:48:42] - L1:  train 0.196613, valid 0.143036, test 0.067307
+[2022-04-14 13:48:42] - RMSE: train 0.203297, valid 0.149623, test 0.075346
+[2022-04-14 13:48:42] - DTW: train 0.510820, valid 0.371061, test 0.174345
+[2022-04-14 13:48:42] - TDI: train 0.058144, valid 0.147011, test 0.358971
+[2022-04-14 13:48:42] - Finished.
+[2022-04-14 15:06:40] - create model_king...
+[2022-04-14 15:06:40] - Epoch: 0
+[2022-04-14 15:06:40] - training...
+[2022-04-14 15:06:48] - [ 3.68321870e+00  8.95220019e-01 -1.63128500e-08] 0.19232119110069776
+[2022-04-14 15:06:48] - evaluating...
+[2022-04-14 15:06:52] - valid_l1 0.250881, test_l1 0.099884
+[2022-04-14 15:06:52] - valid_dtw 0.662475, test_dtw 0.288124
+[2022-04-14 15:06:52] - Epoch: 1
+[2022-04-14 15:06:52] - training...
+[2022-04-14 15:06:57] - [ 2.48923970e+00  1.69862582e-01 -2.63515274e-08] 0.08827156299038937
+[2022-04-14 15:06:57] - evaluating...
+[2022-04-14 15:22:44] - create model_king...
+[2022-04-14 15:22:44] - Epoch: 0
+[2022-04-14 15:22:44] - training...
+[2022-04-14 15:22:52] - [ 3.68321870e+00  8.95220019e-01 -1.63128500e-08] 0.19232119110069776
+[2022-04-14 15:22:52] - evaluating...
+[2022-04-14 15:22:56] - valid_l1 0.250881, test_l1 0.099884
+[2022-04-14 15:22:56] - valid_dtw 0.662475, test_dtw 0.288124
+[2022-04-14 15:22:56] - Epoch: 1
+[2022-04-14 15:22:56] - training...
+[2022-04-14 15:23:02] - [ 2.48923970e+00  1.69862582e-01 -2.63515274e-08] 0.08827156299038937
+[2022-04-14 15:23:02] - evaluating...
+[2022-04-14 15:23:06] - valid_l1 0.381546, test_l1 0.118738
+[2022-04-14 15:23:06] - valid_dtw 0.985389, test_dtw 0.312527
+[2022-04-14 15:23:06] - Epoch: 2
+[2022-04-14 15:23:06] - training...
+[2022-04-14 15:23:12] - [ 2.46771025e+00  2.58771716e-01 -1.12935111e-08] 0.11226965388969372
+[2022-04-14 15:23:12] - evaluating...
+[2022-04-14 15:23:15] - valid_l1 0.338145, test_l1 0.118917
+[2022-04-14 15:23:15] - valid_dtw 0.869786, test_dtw 0.312973
+[2022-04-14 15:23:15] - Epoch: 3
+[2022-04-14 15:23:15] - training...
+[2022-04-14 15:23:21] - [ 3.11367153e+00  3.43419751e-01 -1.94499367e-08] 0.12222308528266455
+[2022-04-14 15:23:21] - evaluating...
+[2022-04-14 15:23:25] - valid_l1 0.175236, test_l1 0.111360
+[2022-04-14 15:23:25] - valid_dtw 0.455317, test_dtw 0.290297
+[2022-04-14 15:23:25] - Epoch: 4
+[2022-04-14 15:23:25] - training...
+[2022-04-14 15:23:30] - [ 1.44984578e+00  2.66433276e-01 -2.38418582e-08] 0.1453159806367598
+[2022-04-14 15:23:30] - evaluating...
+[2022-04-14 15:23:35] - valid_l1 0.117011, test_l1 0.088366
+[2022-04-14 15:23:35] - valid_dtw 0.340621, test_dtw 0.252729
+[2022-04-14 15:23:35] - Epoch: 5
+[2022-04-14 15:23:35] - training...
+[2022-04-14 15:23:41] - [ 2.66831924e+00  1.07993619e+00 -8.48220402e-09] 0.3704600945899361
+[2022-04-14 15:23:41] - evaluating...
+[2022-04-14 15:23:44] - valid_l1 0.161924, test_l1 0.107897
+[2022-04-14 15:23:44] - valid_dtw 0.496386, test_dtw 0.322545
+[2022-04-14 15:23:44] - Epoch: 6
+[2022-04-14 15:23:44] - training...
+[2022-04-14 15:23:51] - [2.26017662 0.94446164 0.01218159] 0.3225303119734714
+[2022-04-14 15:23:51] - evaluating...
+[2022-04-14 15:23:54] - valid_l1 0.151503, test_l1 0.104072
+[2022-04-14 15:23:54] - valid_dtw 0.393257, test_dtw 0.270969
+[2022-04-14 15:23:54] - Epoch: 7
+[2022-04-14 15:23:54] - training...
+[2022-04-14 15:24:00] - [1.37499676 0.426905   0.00932577] 0.21208176565797707
+[2022-04-14 15:24:00] - evaluating...
+[2022-04-14 15:24:04] - valid_l1 0.207295, test_l1 0.101739
+[2022-04-14 15:24:04] - valid_dtw 0.534527, test_dtw 0.263922
+[2022-04-14 15:24:04] - Epoch: 8
+[2022-04-14 15:24:04] - training...
+[2022-04-14 15:24:10] - [1.86509163 0.16955859 0.35830996] 0.08745969380987317
+[2022-04-14 15:24:10] - evaluating...
+[2022-04-14 15:24:13] - valid_l1 0.372476, test_l1 0.179201
+[2022-04-14 15:24:13] - valid_dtw 0.987166, test_dtw 0.495102
+[2022-04-14 15:24:13] - Epoch: 9
+[2022-04-14 15:24:13] - training...
+[2022-04-14 15:24:20] - [3.36727507 0.36964293 1.75679945] 0.1363833476054041
+[2022-04-14 15:24:20] - evaluating...
+[2022-04-14 15:24:24] - valid_l1 0.417238, test_l1 0.238367
+[2022-04-14 15:24:24] - valid_dtw 1.078335, test_dtw 0.623835
+[2022-04-14 15:24:24] - Epoch: 10
+[2022-04-14 15:24:24] - training...
+[2022-04-14 15:24:30] - [2.33739727 0.259953   1.74993838] 0.11569675009109472
+[2022-04-14 15:24:30] - evaluating...
+[2022-04-14 15:24:34] - valid_l1 0.298204, test_l1 0.135369
+[2022-04-14 15:24:34] - valid_dtw 0.767015, test_dtw 0.358473
+[2022-04-14 15:24:34] - Epoch: 11
+[2022-04-14 15:24:34] - training...
+[2022-04-14 15:24:35] - create model_king...
+[2022-04-14 15:24:35] - Epoch: 0
+[2022-04-14 15:24:35] - training...
+[2022-04-14 15:24:44] - [ 3.68321870e+00  8.95220019e-01 -1.63128500e-08] 0.19232119110069776
+[2022-04-14 15:24:44] - evaluating...
+[2022-04-14 15:24:49] - valid_l1 0.250881, test_l1 0.099884
+[2022-04-14 15:24:49] - valid_dtw 0.662475, test_dtw 0.288124
+[2022-04-14 15:24:49] - Epoch: 1
+[2022-04-14 15:24:49] - training...
+[2022-04-14 15:24:55] - [ 2.48923970e+00  1.69862582e-01 -2.63515274e-08] 0.08827156299038937
+[2022-04-14 15:24:55] - evaluating...
+[2022-04-14 15:24:59] - valid_l1 0.381546, test_l1 0.118738
+[2022-04-14 15:24:59] - valid_dtw 0.985389, test_dtw 0.312527
+[2022-04-14 15:24:59] - Epoch: 2
+[2022-04-14 15:24:59] - training...
+[2022-04-14 15:25:05] - [ 2.46771025e+00  2.58771716e-01 -1.12935111e-08] 0.11226965388969372
+[2022-04-14 15:25:05] - evaluating...
+[2022-04-14 15:25:08] - valid_l1 0.338145, test_l1 0.118917
+[2022-04-14 15:25:08] - valid_dtw 0.869786, test_dtw 0.312973
+[2022-04-14 15:25:08] - Epoch: 3
+[2022-04-14 15:25:08] - training...
+[2022-04-14 15:25:14] - [ 3.11367153e+00  3.43419751e-01 -1.94499367e-08] 0.12222308528266455
+[2022-04-14 15:25:14] - evaluating...
+[2022-04-14 15:25:17] - valid_l1 0.175236, test_l1 0.111360
+[2022-04-14 15:25:17] - valid_dtw 0.455317, test_dtw 0.290297
+[2022-04-14 15:25:17] - Epoch: 4
+[2022-04-14 15:25:17] - training...
+[2022-04-14 15:25:23] - [ 1.44984578e+00  2.66433276e-01 -2.38418582e-08] 0.1453159806367598
+[2022-04-14 15:25:23] - evaluating...
+[2022-04-14 15:25:27] - valid_l1 0.117011, test_l1 0.088366
+[2022-04-14 15:25:27] - valid_dtw 0.340621, test_dtw 0.252729
+[2022-04-14 15:25:27] - Epoch: 5
+[2022-04-14 15:25:27] - training...
+[2022-04-14 15:25:33] - [ 2.66831924e+00  1.07993619e+00 -8.48220402e-09] 0.3704600945899361
+[2022-04-14 15:25:33] - evaluating...
+[2022-04-14 15:25:37] - valid_l1 0.161924, test_l1 0.107897
+[2022-04-14 15:25:37] - valid_dtw 0.496386, test_dtw 0.322545
+[2022-04-14 15:25:37] - Epoch: 6
+[2022-04-14 15:25:37] - training...
+[2022-04-14 15:25:43] - [2.26017662 0.94446164 0.01218159] 0.3225303119734714
+[2022-04-14 15:25:43] - evaluating...
+[2022-04-14 15:25:46] - valid_l1 0.151503, test_l1 0.104072
+[2022-04-14 15:25:46] - valid_dtw 0.393257, test_dtw 0.270969
+[2022-04-14 15:25:46] - Epoch: 7
+[2022-04-14 15:25:46] - training...
+[2022-04-14 15:25:53] - [1.37499676 0.426905   0.00932577] 0.21208176565797707
+[2022-04-14 15:25:53] - evaluating...
+[2022-04-14 15:25:56] - valid_l1 0.207295, test_l1 0.101739
+[2022-04-14 15:25:56] - valid_dtw 0.534527, test_dtw 0.263922
+[2022-04-14 15:25:56] - Epoch: 8
+[2022-04-14 15:25:56] - training...
+[2022-04-14 15:26:02] - [1.86509163 0.16955859 0.35830996] 0.08745969380987317
+[2022-04-14 15:26:02] - evaluating...
+[2022-04-14 15:26:06] - valid_l1 0.372476, test_l1 0.179201
+[2022-04-14 15:26:06] - valid_dtw 0.987166, test_dtw 0.495102
+[2022-04-14 15:26:06] - Epoch: 9
+[2022-04-14 15:26:06] - training...
+[2022-04-14 15:26:12] - [3.36727507 0.36964293 1.75679945] 0.1363833476054041
+[2022-04-14 15:26:12] - evaluating...
+[2022-04-14 15:26:15] - valid_l1 0.417238, test_l1 0.238367
+[2022-04-14 15:26:15] - valid_dtw 1.078335, test_dtw 0.623835
+[2022-04-14 15:26:15] - Epoch: 10
+[2022-04-14 15:26:15] - training...
+[2022-04-14 15:26:22] - [2.33739727 0.259953   1.74993838] 0.11569675009109472
+[2022-04-14 15:26:22] - evaluating...
+[2022-04-14 15:26:26] - valid_l1 0.298204, test_l1 0.135369
+[2022-04-14 15:26:26] - valid_dtw 0.767015, test_dtw 0.358473
+[2022-04-14 15:26:26] - Epoch: 11
+[2022-04-14 15:26:26] - training...
+[2022-04-14 15:26:32] - [1.83097369 0.11603632 1.88675689] 0.07987934272540242
+[2022-04-14 15:26:32] - evaluating...
+[2022-04-14 15:26:36] - valid_l1 0.303884, test_l1 0.179523
+[2022-04-14 15:26:36] - valid_dtw 0.780528, test_dtw 0.469163
+[2022-04-14 15:26:36] - Epoch: 12
+[2022-04-14 15:26:36] - training...
+[2022-04-14 15:26:41] - [1.73912635 0.13901766 1.78925349] 0.08771094621012085
+[2022-04-14 15:26:41] - evaluating...
+[2022-04-14 15:26:45] - valid_l1 0.265595, test_l1 0.183153
+[2022-04-14 15:26:45] - valid_dtw 0.684161, test_dtw 0.482380
+[2022-04-14 15:26:45] - Epoch: 13
+[2022-04-14 15:26:45] - training...
+[2022-04-14 15:26:51] - [1.43167261 0.1986802  1.69216574] 0.12547328362339422
+[2022-04-14 15:26:51] - evaluating...
+[2022-04-14 15:27:05] - create model_king...
+[2022-04-14 15:27:05] - Epoch: 0
+[2022-04-14 15:27:05] - training...
+[2022-04-14 15:27:14] - [ 3.68321962e+00  8.95220256e-01 -3.00547485e-08] 0.19232124364689776
+[2022-04-14 15:27:14] - evaluating...
+[2022-04-14 15:27:18] - valid_l1 0.250880, test_l1 0.099884
+[2022-04-14 15:27:18] - valid_dtw 0.662475, test_dtw 0.288124
+[2022-04-14 15:27:18] - Epoch: 1
+[2022-04-14 15:27:18] - training...
+[2022-04-14 15:27:25] - [ 2.48923822e+00  1.69862907e-01 -1.32470939e-08] 0.08827162867313937
+[2022-04-14 15:27:25] - evaluating...
+[2022-04-14 15:27:28] - valid_l1 0.381545, test_l1 0.118738
+[2022-04-14 15:27:28] - valid_dtw 0.985388, test_dtw 0.312526
+[2022-04-14 15:27:28] - Epoch: 2
+[2022-04-14 15:27:28] - training...
+[2022-04-14 15:27:35] - [ 2.46770888e+00  2.58771141e-01 -1.13017061e-08] 0.11226949919211238
+[2022-04-14 15:27:35] - evaluating...
+[2022-04-14 15:27:38] - valid_l1 0.338144, test_l1 0.118916
+[2022-04-14 15:27:38] - valid_dtw 0.869785, test_dtw 0.312971
+[2022-04-14 15:27:38] - Epoch: 3
+[2022-04-14 15:27:38] - training...
+[2022-04-14 15:27:45] - [ 3.11365107e+00  3.43416730e-01 -1.68604647e-08] 0.1222226431495265
+[2022-04-14 15:27:45] - evaluating...
+[2022-04-14 15:27:48] - valid_l1 0.175236, test_l1 0.111359
+[2022-04-14 15:27:48] - valid_dtw 0.455319, test_dtw 0.290294
+[2022-04-14 15:27:48] - Epoch: 4
+[2022-04-14 15:27:48] - training...
+[2022-04-14 15:27:54] - [ 1.44984327e+00  2.66433984e-01 -5.68367012e-09] 0.14531647766891279
+[2022-04-14 15:27:54] - evaluating...
+[2022-04-14 15:27:58] - valid_l1 0.117009, test_l1 0.088365
+[2022-04-14 15:27:58] - valid_dtw 0.340617, test_dtw 0.252728
+[2022-04-14 15:27:58] - Epoch: 5
+[2022-04-14 15:27:58] - training...
+[2022-04-14 15:28:04] - [2.66607604 1.07990895 0.02002942] 0.37053698066033813
+[2022-04-14 15:28:04] - evaluating...
+[2022-04-14 15:28:07] - valid_l1 0.161258, test_l1 0.108425
+[2022-04-14 15:28:07] - valid_dtw 0.495262, test_dtw 0.324280
+[2022-04-14 15:28:07] - Epoch: 6
+[2022-04-14 15:28:07] - training...
+[2022-04-14 15:28:13] - [ 2.23265898e+00  9.30006429e-01 -1.19567884e-08] 0.3205351343280391
+[2022-04-14 15:28:13] - evaluating...
+[2022-04-14 15:28:17] - valid_l1 0.154802, test_l1 0.108529
+[2022-04-14 15:28:17] - valid_dtw 0.401659, test_dtw 0.282572
+[2022-04-14 15:28:17] - Epoch: 7
+[2022-04-14 15:28:17] - training...
+[2022-04-14 15:28:23] - [ 1.38388938e+00  4.36877808e-01 -1.41186696e-08] 0.21463792927955327
+[2022-04-14 15:28:23] - evaluating...
+[2022-04-14 15:28:27] - valid_l1 0.204249, test_l1 0.101111
+[2022-04-14 15:28:27] - valid_dtw 0.526680, test_dtw 0.262334
+[2022-04-14 15:28:27] - Epoch: 8
+[2022-04-14 15:28:27] - training...
+[2022-04-14 15:28:33] - [1.81663594 0.16645558 0.31622364] 0.08795571974233578
+[2022-04-14 15:28:33] - evaluating...
+[2022-04-14 15:28:37] - valid_l1 0.369338, test_l1 0.177289
+[2022-04-14 15:28:37] - valid_dtw 0.977645, test_dtw 0.488936
+[2022-04-14 15:28:37] - Epoch: 9
+[2022-04-14 15:28:37] - training...
+[2022-04-14 15:28:43] - [3.27195296 0.35196512 1.78330049] 0.1330583715125134
+[2022-04-14 15:28:43] - evaluating...
+[2022-04-14 15:28:47] - valid_l1 0.396008, test_l1 0.214350
+[2022-04-14 15:28:47] - valid_dtw 1.025896, test_dtw 0.563481
+[2022-04-14 15:28:47] - Epoch: 10
+[2022-04-14 15:28:47] - training...
+[2022-04-14 15:28:54] - [2.25375746 0.20383181 1.80919483] 0.10135170778161601
+[2022-04-14 15:28:54] - evaluating...
+[2022-04-14 15:28:57] - valid_l1 0.315306, test_l1 0.154936
+[2022-04-14 15:28:57] - valid_dtw 0.810098, test_dtw 0.408759
+[2022-04-14 15:28:57] - Epoch: 11
+[2022-04-14 15:28:57] - training...
+[2022-04-14 15:29:03] - [1.80361696 0.12468712 1.7893315 ] 0.08428038352806318
+[2022-04-14 15:29:03] - evaluating...
+[2022-04-14 15:29:07] - valid_l1 0.295122, test_l1 0.163566
+[2022-04-14 15:29:07] - valid_dtw 0.758404, test_dtw 0.428903
+[2022-04-14 15:29:07] - Epoch: 12
+[2022-04-14 15:29:07] - training...
+[2022-04-14 15:29:14] - [1.68170841 0.1502935  1.636658  ] 0.09305993349928605
+[2022-04-14 15:29:14] - evaluating...
+[2022-04-14 15:29:18] - valid_l1 0.261044, test_l1 0.178121
+[2022-04-14 15:29:18] - valid_dtw 0.672696, test_dtw 0.469477
+[2022-04-14 15:29:18] - Epoch: 13
+[2022-04-14 15:29:18] - training...
+[2022-04-14 15:29:24] - [1.40165434 0.21707272 1.54811138] 0.1348322351512156
+[2022-04-14 15:29:24] - evaluating...
+[2022-04-14 15:29:27] - valid_l1 0.226974, test_l1 0.244940
+[2022-04-14 15:29:27] - valid_dtw 0.588315, test_dtw 0.637201
+[2022-04-14 15:29:27] - Epoch: 14
+[2022-04-14 15:29:27] - training...
+[2022-04-14 15:29:34] - [1.23154227 0.28783101 1.49958166] 0.16263976869614502
+[2022-04-14 15:29:34] - evaluating...
+[2022-04-14 15:29:37] - valid_l1 0.217922, test_l1 0.398564
+[2022-04-14 15:29:37] - valid_dtw 0.571902, test_dtw 1.031373
+[2022-04-14 15:29:37] - early stop
+[2022-04-14 15:29:37] - best val score: 0.019647035623590152 @ 4
+[2022-04-14 15:29:37] - inference...
+[2022-04-14 15:29:41] - MSE: train 0.033839, valid 0.019521, test 0.011601
+[2022-04-14 15:29:41] - L1:  train 0.162946, valid 0.116531, test 0.088731
+[2022-04-14 15:29:41] - RMSE: train 0.183205, valid 0.137267, test 0.106681
+[2022-04-14 15:29:41] - DTW: train 0.455169, valid 0.339574, test 0.253193
+[2022-04-14 15:29:41] - TDI: train 0.035024, valid 0.102063, test 0.290301
+[2022-04-14 15:29:41] - Finished.
+[2022-04-14 15:35:03] - create model_king...
+[2022-04-14 15:35:04] - Epoch: 0
+[2022-04-14 15:35:04] - training...
+[2022-04-14 15:42:45] - create model_king...
+[2022-04-14 15:42:45] - Epoch: 0
+[2022-04-14 15:42:45] - training...
+[2022-04-14 15:42:53] - [3.78441628 0.89722129 0.7787835 ] 0.1924400580556769
+[2022-04-14 15:42:53] - evaluating...
+[2022-04-14 15:42:57] - valid_l1 0.250841, test_l1 0.099983
+[2022-04-14 15:42:57] - valid_dtw 0.662422, test_dtw 0.288192
+[2022-04-14 15:42:57] - Epoch: 1
+[2022-04-14 15:42:57] - training...
+[2022-04-14 15:43:03] - [2.59156316 0.17068329 0.88948035] 0.08850153908133507
+[2022-04-14 15:43:03] - evaluating...
+[2022-04-14 15:43:06] - valid_l1 0.381693, test_l1 0.118728
+[2022-04-14 15:43:06] - valid_dtw 0.985615, test_dtw 0.312377
+[2022-04-14 15:43:06] - Epoch: 2
+[2022-04-14 15:43:06] - training...
+[2022-04-14 15:43:12] - [2.56643564 0.26012088 0.84888564] 0.112628602079655
+[2022-04-14 15:43:12] - evaluating...
+[2022-04-14 15:43:16] - valid_l1 0.337244, test_l1 0.117433
+[2022-04-14 15:43:16] - valid_dtw 0.867425, test_dtw 0.309244
+[2022-04-14 15:43:16] - Epoch: 3
+[2022-04-14 15:43:16] - training...
+[2022-04-14 15:43:22] - [3.16484623 0.33901447 0.78358536] 0.12191706680153545
+[2022-04-14 15:43:22] - evaluating...
+[2022-04-14 15:43:25] - valid_l1 0.176555, test_l1 0.107850
+[2022-04-14 15:43:25] - valid_dtw 0.458716, test_dtw 0.280832
+[2022-04-14 15:43:25] - Epoch: 4
+[2022-04-14 15:43:25] - training...
+[2022-04-14 15:43:31] - [1.52991695 0.26012431 0.76065546] 0.14317144139816887
+[2022-04-14 15:43:31] - evaluating...
+[2022-04-14 15:43:35] - valid_l1 0.121045, test_l1 0.088105
+[2022-04-14 15:43:35] - valid_dtw 0.350370, test_dtw 0.252516
+[2022-04-14 15:43:35] - Epoch: 5
+[2022-04-14 15:43:35] - training...
+[2022-04-14 15:43:40] - [2.71587597 1.05673272 0.87220684] 0.36319128855278615
+[2022-04-14 15:43:40] - evaluating...
+[2022-04-14 15:43:44] - valid_l1 0.160021, test_l1 0.108872
+[2022-04-14 15:43:44] - valid_dtw 0.495562, test_dtw 0.329815
+[2022-04-14 15:43:44] - Epoch: 6
+[2022-04-14 15:43:44] - training...
+[2022-04-14 15:43:50] - [2.40947814 0.96185427 1.00763922] 0.3260361920846136
+[2022-04-14 15:43:50] - evaluating...
+[2022-04-14 15:43:54] - valid_l1 0.150480, test_l1 0.100118
+[2022-04-14 15:43:54] - valid_dtw 0.390979, test_dtw 0.261547
+[2022-04-14 15:43:54] - Epoch: 7
+[2022-04-14 15:43:54] - training...
+[2022-04-14 15:43:59] - [1.46666712 0.42046292 0.84021917] 0.21154481329415975
+[2022-04-14 15:43:59] - evaluating...
+[2022-04-14 15:44:03] - valid_l1 0.206021, test_l1 0.101777
+[2022-04-14 15:44:03] - valid_dtw 0.531353, test_dtw 0.264202
+[2022-04-14 15:44:03] - Epoch: 8
+[2022-04-14 15:44:03] - training...
+[2022-04-14 15:44:08] - [1.88984023 0.17046187 0.73488167] 0.08855241674341653
+[2022-04-14 15:44:08] - evaluating...
+[2022-04-14 15:44:12] - valid_l1 0.362543, test_l1 0.166645
+[2022-04-14 15:44:12] - valid_dtw 0.962273, test_dtw 0.462119
+[2022-04-14 15:44:12] - Epoch: 9
+[2022-04-14 15:44:12] - training...
+[2022-04-14 15:44:18] - [3.25540649 0.35528962 0.74814636] 0.13475156457800613
+[2022-04-14 15:44:18] - evaluating...
+[2022-04-14 15:44:22] - valid_l1 0.437018, test_l1 0.274066
+[2022-04-14 15:44:22] - valid_dtw 1.126990, test_dtw 0.714141
+[2022-04-14 15:44:22] - Epoch: 10
+[2022-04-14 15:44:22] - training...
+[2022-04-14 15:44:27] - [2.20046046 0.29339223 0.64390828] 0.1235123366901749
+[2022-04-14 15:44:27] - evaluating...
+[2022-04-14 15:44:31] - valid_l1 0.297973, test_l1 0.139054
+[2022-04-14 15:44:31] - valid_dtw 0.766743, test_dtw 0.368540
+[2022-04-14 15:44:31] - Epoch: 11
+[2022-04-14 15:44:31] - training...
+[2022-04-14 16:14:55] - create model_king...
+[2022-04-14 16:14:55] - Epoch: 0
+[2022-04-14 16:14:55] - training...
Index: loss/path_soft_dtw.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2022 Apple, Inc. All Rights Reserved \n#\n# @Time    : 2022/3/30 21:55\n# @Author  : SeptKing\n# @Email   : WJH0923@mail.dlut.edu.cn\n# @File    : path_soft_dtw.py\n# @Software: PyCharm\nfrom numba import jit\nimport numpy as np\nimport torch\nfrom torch.autograd import Function\n\n@jit(nopython=True)\ndef my_max(x, gamma):\n    # use the log-sum-exp trick\n    max_x = np.max(x)\n    exp_x = np.exp((x - max_x) / gamma)\n    Z = np.sum(exp_x)\n    return gamma * np.log(Z) + max_x, exp_x / Z\n\n\n@jit(nopython=True)\ndef my_min(x, gamma):\n    min_x, argmax_x = my_max(-x, gamma)\n    return - min_x, argmax_x\n\n\n@jit(nopython=True)\ndef my_max_hessian_product(p, z, gamma):\n    return (p * z - p * np.sum(p * z)) / gamma\n\n\n@jit(nopython=True)\ndef my_min_hessian_product(p, z, gamma):\n    return - my_max_hessian_product(p, z, gamma)\n\n\n@jit(nopython=True)\ndef dtw_grad(theta, gamma):\n    m = theta.shape[0]  ##6\n    n = theta.shape[1]  ##6\n    V = np.zeros((m + 1, n + 1))  ##7\n    V[:, 0] = 1e10\n    V[0, :] = 1e10\n    V[0, 0] = 0\n\n    Q = np.zeros((m + 2, n + 2, 3))\n\n    for i in range(1, m + 1):\n        for j in range(1, n + 1):\n            # theta is indexed starting from 0.\n            v, Q[i, j] = my_min(np.array([V[i, j - 1],\n\n                                          V[i - 1, j - 1],\n                                          V[i - 1, j]]), gamma)\n            V[i, j] = theta[i - 1, j - 1] + v\n\n    E = np.zeros((m + 2, n + 2))\n    E[m + 1, :] = 0\n    E[:, n + 1] = 0\n    E[m + 1, n + 1] = 1\n    Q[m + 1, n + 1] = 1\n\n    for i in range(m, 0, -1):\n        for j in range(n, 0, -1):\n            E[i, j] = Q[i, j + 1, 0] * E[i, j + 1] + \\\n                      Q[i + 1, j + 1, 1] * E[i + 1, j + 1] + \\\n                      Q[i + 1, j, 2] * E[i + 1, j]\n\n    return V[m, n], E[1:m + 1, 1:n + 1], Q, E\n\n\n@jit(nopython=True)\ndef dtw_hessian_prod(theta, Z, Q, E, gamma):\n    m = Z.shape[0]\n    n = Z.shape[1]\n\n    V_dot = np.zeros((m + 1, n + 1))\n    V_dot[0, 0] = 0\n\n    Q_dot = np.zeros((m + 2, n + 2, 3))\n    for i in range(1, m + 1):\n        for j in range(1, n + 1):\n            # theta is indexed starting from 0.\n            V_dot[i, j] = Z[i - 1, j - 1] + \\\n                          Q[i, j, 0] * V_dot[i, j - 1] + \\\n                          Q[i, j, 1] * V_dot[i - 1, j - 1] + \\\n                          Q[i, j, 2] * V_dot[i - 1, j]\n\n            v = np.array([V_dot[i, j - 1], V_dot[i - 1, j - 1], V_dot[i - 1, j]])\n            Q_dot[i, j] = my_min_hessian_product(Q[i, j], v, gamma)\n    E_dot = np.zeros((m + 2, n + 2))\n\n    for j in range(n, 0, -1):\n        for i in range(m, 0, -1):\n            E_dot[i, j] = Q_dot[i, j + 1, 0] * E[i, j + 1] + \\\n                          Q[i, j + 1, 0] * E_dot[i, j + 1] + \\\n                          Q_dot[i + 1, j + 1, 1] * E[i + 1, j + 1] + \\\n                          Q[i + 1, j + 1, 1] * E_dot[i + 1, j + 1] + \\\n                          Q_dot[i + 1, j, 2] * E[i + 1, j] + \\\n                          Q[i + 1, j, 2] * E_dot[i + 1, j]\n\n    return V_dot[m, n], E_dot[1:m + 1, 1:n + 1]\n\n\nclass PathDTWBatch(Function):\n    @staticmethod\n    def forward(ctx, D, gamma):  # D.shape: [batch_size, N , N]1，6，6\n        batch_size, N, N = D.shape\n        device = D.device\n        D_cpu = D.detach().cpu().numpy()\n        gamma_gpu = torch.FloatTensor([gamma]).to(device)\n\n        grad_gpu = torch.zeros((batch_size, N, N)).to(device)\n        Q_gpu = torch.zeros((batch_size, N + 2, N + 2, 3)).to(device)\n        E_gpu = torch.zeros((batch_size, N + 2, N + 2)).to(device)\n\n        for k in range(0, batch_size):  # loop over all D in the batch\n            _, grad_cpu_k, Q_cpu_k, E_cpu_k = dtw_grad(D_cpu[k, :, :], gamma)  ##就是去掉d的第一个维度也就是M_1\n            grad_gpu[k, :, :] = torch.FloatTensor(grad_cpu_k).to(device)\n            Q_gpu[k, :, :, :] = torch.FloatTensor(Q_cpu_k).to(device)\n            E_gpu[k, :, :] = torch.FloatTensor(E_cpu_k).to(device)\n        ctx.save_for_backward(grad_gpu, D, Q_gpu, E_gpu, gamma_gpu)\n        return torch.mean(grad_gpu, dim=0)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        device = grad_output.device\n        grad_gpu, D_gpu, Q_gpu, E_gpu, gamma = ctx.saved_tensors\n        D_cpu = D_gpu.detach().cpu().numpy()\n        Q_cpu = Q_gpu.detach().cpu().numpy()\n        E_cpu = E_gpu.detach().cpu().numpy()\n        gamma = gamma.detach().cpu().numpy()[0]\n        Z = grad_output.detach().cpu().numpy()\n\n        batch_size, N, N = D_cpu.shape\n        Hessian = torch.zeros((batch_size, N, N)).to(device)\n        for k in range(0, batch_size):\n            _, hess_k = dtw_hessian_prod(D_cpu[k, :, :], Z, Q_cpu[k, :, :, :], E_cpu[k, :, :], gamma)\n            Hessian[k:k + 1, :, :] = torch.FloatTensor(hess_k).to(device)\n\n        return Hessian, None
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/loss/path_soft_dtw.py b/loss/path_soft_dtw.py
--- a/loss/path_soft_dtw.py	(revision 4d374eb052e73a15d49eb92596cef4473d6d2218)
+++ b/loss/path_soft_dtw.py	(date 1649918620270)
@@ -19,11 +19,13 @@
     max_x = np.max(x)
     exp_x = np.exp((x - max_x) / gamma)
     Z = np.sum(exp_x)
-    return gamma * np.log(Z) + max_x, exp_x / Z
+    ##这个部分有点问题
+    return gamma * (np.log(Z) + max_x), exp_x / Z
 
 
 @jit(nopython=True)
 def my_min(x, gamma):
+    ##返回的是log_sum_exp
     min_x, argmax_x = my_max(-x, gamma)
     return - min_x, argmax_x
 
@@ -40,9 +42,11 @@
 
 @jit(nopython=True)
 def dtw_grad(theta, gamma):
+    ##输入的是一个batch的真实值和预测值之间的损失(6,6),0.05
     m = theta.shape[0]  ##6
     n = theta.shape[1]  ##6
-    V = np.zeros((m + 1, n + 1))  ##7
+    V = np.zeros((m + 1, n + 1))  ##(7,7)
+
     V[:, 0] = 1e10
     V[0, :] = 1e10
     V[0, 0] = 0
@@ -108,12 +112,13 @@
 
 class PathDTWBatch(Function):
     @staticmethod
-    def forward(ctx, D, gamma):  # D.shape: [batch_size, N , N]1，6，6
+    def forward(ctx, D, gamma):  # D.shape: [batch_size, N , N]24，6，6
         batch_size, N, N = D.shape
         device = D.device
         D_cpu = D.detach().cpu().numpy()
         gamma_gpu = torch.FloatTensor([gamma]).to(device)
 
+        ##这24，6，6
         grad_gpu = torch.zeros((batch_size, N, N)).to(device)
         Q_gpu = torch.zeros((batch_size, N + 2, N + 2, 3)).to(device)
         E_gpu = torch.zeros((batch_size, N + 2, N + 2)).to(device)
Index: weather_data/._data_TEM_test.py
===================================================================
diff --git a/weather_data/._data_TEM_test.py b/weather_data/._data_TEM_test.py
deleted file mode 100644
--- a/weather_data/._data_TEM_test.py	(revision 4d374eb052e73a15d49eb92596cef4473d6d2218)
+++ /dev/null	(revision 4d374eb052e73a15d49eb92596cef4473d6d2218)
@@ -1,1 +0,0 @@
-    Mac OS X            	   2  �     �                                    ATTR     �   �   ]                  �     com.apple.quarantine    �   H  com.apple.macl   0082;6250fc12;WeChat; �g���VL��H�+'t��                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    This resource fork intentionally left blank                                                                                                                                                                                                                            ��
\ No newline at end of file
Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"ChangeListManager\">\n    <list default=\"true\" id=\"a2077429-db83-4473-89d8-284d44cf7e56\" name=\"变更\" comment=\"\" />\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\n  </component>\n  <component name=\"FileTemplateManagerImpl\">\n    <option name=\"RECENT_TEMPLATES\">\n      <list>\n        <option value=\"Python Script\" />\n      </list>\n    </option>\n  </component>\n  <component name=\"GitSEFilterConfiguration\">\n    <file-type-list>\n      <filtered-out-file-type name=\"LOCAL_BRANCH\" />\n      <filtered-out-file-type name=\"REMOTE_BRANCH\" />\n      <filtered-out-file-type name=\"TAG\" />\n      <filtered-out-file-type name=\"COMMIT_BY_MESSAGE\" />\n    </file-type-list>\n  </component>\n  <component name=\"MarkdownSettingsMigration\">\n    <option name=\"stateVersion\" value=\"1\" />\n  </component>\n  <component name=\"ProjectId\" id=\"25oj2ddCrC2oAdtkcLc1lUZV5Md\" />\n  <component name=\"ProjectViewState\">\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\n    <option name=\"showLibraryContents\" value=\"true\" />\n  </component>\n  <component name=\"PropertiesComponent\">\n    <property name=\"RunOnceActivity.OpenProjectViewOnStart\" value=\"true\" />\n    <property name=\"RunOnceActivity.ShowReadmeOnStart\" value=\"true\" />\n    <property name=\"WebServerToolWindowFactoryState\" value=\"false\" />\n    <property name=\"last_opened_file_path\" value=\"$PROJECT_DIR$\" />\n    <property name=\"python.debugger.dataview.coloredbydefault\" value=\"false\" />\n    <property name=\"settings.editor.selected.configurable\" value=\"preferences.pluginManager\" />\n  </component>\n  <component name=\"RecentsManager\">\n    <key name=\"CopyFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$\" />\n      <recent name=\"$PROJECT_DIR$/weather_data\" />\n      <recent name=\"$PROJECT_DIR$/model\" />\n    </key>\n  </component>\n  <component name=\"RunManager\" selected=\"Python.weather_traintro\">\n    <configuration default=\"true\" type=\"PythonConfigurationType\" factoryName=\"Python\">\n      <module name=\"AdaRNN-BIT\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <envs>\n        <env name=\"PYTHONUNBUFFERED\" value=\"1\" />\n      </envs>\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"\" />\n      <option name=\"IS_MODULE_SDK\" value=\"false\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"true\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"data_TEM_test\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"AdaRNN-BIT\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$/weather_data\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/weather_data/data_TEM_test.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"true\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <configuration name=\"weather_traintro\" type=\"PythonConfigurationType\" factoryName=\"Python\" temporary=\"true\" nameIsGenerated=\"true\">\n      <module name=\"AdaRNN-BIT\" />\n      <option name=\"INTERPRETER_OPTIONS\" value=\"\" />\n      <option name=\"PARENT_ENVS\" value=\"true\" />\n      <option name=\"SDK_HOME\" value=\"\" />\n      <option name=\"WORKING_DIRECTORY\" value=\"$PROJECT_DIR$\" />\n      <option name=\"IS_MODULE_SDK\" value=\"true\" />\n      <option name=\"ADD_CONTENT_ROOTS\" value=\"true\" />\n      <option name=\"ADD_SOURCE_ROOTS\" value=\"true\" />\n      <EXTENSION ID=\"PythonCoverageRunConfigurationExtension\" runner=\"coverage.py\" />\n      <option name=\"SCRIPT_NAME\" value=\"$PROJECT_DIR$/weather_traintro.py\" />\n      <option name=\"PARAMETERS\" value=\"\" />\n      <option name=\"SHOW_COMMAND_LINE\" value=\"true\" />\n      <option name=\"EMULATE_TERMINAL\" value=\"false\" />\n      <option name=\"MODULE_MODE\" value=\"false\" />\n      <option name=\"REDIRECT_INPUT\" value=\"false\" />\n      <option name=\"INPUT_FILE\" value=\"\" />\n      <method v=\"2\" />\n    </configuration>\n    <recent_temporary>\n      <list>\n        <item itemvalue=\"Python.weather_traintro\" />\n        <item itemvalue=\"Python.data_TEM_test\" />\n      </list>\n    </recent_temporary>\n  </component>\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"应用程序级\" UseSingleDictionary=\"true\" transferred=\"true\" />\n  <component name=\"TaskManager\">\n    <task active=\"true\" id=\"Default\" summary=\"默认任务\">\n      <changelist id=\"a2077429-db83-4473-89d8-284d44cf7e56\" name=\"变更\" comment=\"\" />\n      <created>1646200129456</created>\n      <option name=\"number\" value=\"Default\" />\n      <option name=\"presentableId\" value=\"Default\" />\n      <updated>1646200129456</updated>\n      <workItem from=\"1646200138238\" duration=\"190000\" />\n      <workItem from=\"1646200469597\" duration=\"2326000\" />\n      <workItem from=\"1646268453669\" duration=\"3635000\" />\n      <workItem from=\"1646355578214\" duration=\"31278000\" />\n      <workItem from=\"1646495421468\" duration=\"774000\" />\n      <workItem from=\"1646530530924\" duration=\"23942000\" />\n      <workItem from=\"1646612993123\" duration=\"14275000\" />\n      <workItem from=\"1646699167710\" duration=\"17961000\" />\n      <workItem from=\"1646751949901\" duration=\"4039000\" />\n      <workItem from=\"1646785284058\" duration=\"9859000\" />\n      <workItem from=\"1646816684264\" duration=\"623000\" />\n      <workItem from=\"1646881653608\" duration=\"3519000\" />\n      <workItem from=\"1646963475890\" duration=\"632000\" />\n      <workItem from=\"1647415541282\" duration=\"2496000\" />\n      <workItem from=\"1647444185018\" duration=\"4691000\" />\n      <workItem from=\"1647481837598\" duration=\"3655000\" />\n      <workItem from=\"1647745316940\" duration=\"10000\" />\n      <workItem from=\"1648038720439\" duration=\"1329000\" />\n      <workItem from=\"1648084106706\" duration=\"9928000\" />\n      <workItem from=\"1648168772263\" duration=\"12662000\" />\n      <workItem from=\"1648216734277\" duration=\"28337000\" />\n      <workItem from=\"1648356402711\" duration=\"10574000\" />\n      <workItem from=\"1648427282801\" duration=\"10278000\" />\n      <workItem from=\"1648448645323\" duration=\"18704000\" />\n      <workItem from=\"1648484269321\" duration=\"20666000\" />\n      <workItem from=\"1648599937380\" duration=\"29711000\" />\n      <workItem from=\"1648689823924\" duration=\"670000\" />\n      <workItem from=\"1648691002112\" duration=\"40707000\" />\n      <workItem from=\"1648895216058\" duration=\"307000\" />\n      <workItem from=\"1648977060034\" duration=\"3535000\" />\n      <workItem from=\"1649031961276\" duration=\"42665000\" />\n      <workItem from=\"1649128594631\" duration=\"353000\" />\n      <workItem from=\"1649129034258\" duration=\"51163000\" />\n      <workItem from=\"1649234248594\" duration=\"768000\" />\n      <workItem from=\"1649237033026\" duration=\"2794000\" />\n      <workItem from=\"1649262044912\" duration=\"30041000\" />\n      <workItem from=\"1649413447820\" duration=\"13427000\" />\n      <workItem from=\"1649474747688\" duration=\"15193000\" />\n      <workItem from=\"1649497578875\" duration=\"812000\" />\n      <workItem from=\"1649498974836\" duration=\"37743000\" />\n      <workItem from=\"1649638092528\" duration=\"598000\" />\n      <workItem from=\"1649691247896\" duration=\"633000\" />\n      <workItem from=\"1649727935640\" duration=\"3228000\" />\n      <workItem from=\"1649732442220\" duration=\"6038000\" />\n      <workItem from=\"1649748507700\" duration=\"14792000\" />\n    </task>\n    <servers />\n  </component>\n  <component name=\"TypeScriptGeneratedFilesManager\">\n    <option name=\"version\" value=\"3\" />\n  </component>\n  <component name=\"XDebuggerManager\">\n    <breakpoint-manager>\n      <breakpoints>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/../transferlearning-master/code/deep/adarnn/main_train.py</url>\n          <line>108</line>\n          <option name=\"timeStamp\" value=\"239\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/../transferlearning-master/code/deep/adarnn/main_train.py</url>\n          <line>110</line>\n          <option name=\"timeStamp\" value=\"252\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/weather_train.py</url>\n          <line>379</line>\n          <option name=\"timeStamp\" value=\"353\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/weather_train.py</url>\n          <line>422</line>\n          <option name=\"timeStamp\" value=\"354\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/weather_train.py</url>\n          <line>414</line>\n          <option name=\"timeStamp\" value=\"356\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/weather_train.py</url>\n          <line>429</line>\n          <option name=\"timeStamp\" value=\"357\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/weather_train.py</url>\n          <line>415</line>\n          <option name=\"timeStamp\" value=\"358\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/weather_train.py</url>\n          <line>446</line>\n          <option name=\"timeStamp\" value=\"363\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/weather_train.py</url>\n          <line>457</line>\n          <option name=\"timeStamp\" value=\"364\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>\n          <line>15</line>\n          <option name=\"timeStamp\" value=\"392\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>\n          <line>17</line>\n          <option name=\"timeStamp\" value=\"393\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>\n          <line>18</line>\n          <option name=\"timeStamp\" value=\"394\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>\n          <line>19</line>\n          <option name=\"timeStamp\" value=\"395\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>\n          <line>21</line>\n          <option name=\"timeStamp\" value=\"396\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>\n          <line>22</line>\n          <option name=\"timeStamp\" value=\"397\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>\n          <line>24</line>\n          <option name=\"timeStamp\" value=\"399\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>\n          <line>25</line>\n          <option name=\"timeStamp\" value=\"400\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>\n          <line>27</line>\n          <option name=\"timeStamp\" value=\"401\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>\n          <line>28</line>\n          <option name=\"timeStamp\" value=\"402\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>\n          <line>29</line>\n          <option name=\"timeStamp\" value=\"403\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>\n          <line>30</line>\n          <option name=\"timeStamp\" value=\"404\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>\n          <line>31</line>\n          <option name=\"timeStamp\" value=\"405\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>\n          <line>32</line>\n          <option name=\"timeStamp\" value=\"406\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>78</line>\n          <option name=\"timeStamp\" value=\"407\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/weather_traintro.py</url>\n          <line>118</line>\n          <option name=\"timeStamp\" value=\"415\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/weather_traintro.py</url>\n          <line>119</line>\n          <option name=\"timeStamp\" value=\"416\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/weather_traintro.py</url>\n          <line>120</line>\n          <option name=\"timeStamp\" value=\"417\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/weather_traintro.py</url>\n          <line>121</line>\n          <option name=\"timeStamp\" value=\"418\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/weather_traintro.py</url>\n          <line>477</line>\n          <option name=\"timeStamp\" value=\"419\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/weather_traintro.py</url>\n          <line>517</line>\n          <option name=\"timeStamp\" value=\"420\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/weather_traintro.py</url>\n          <line>518</line>\n          <option name=\"timeStamp\" value=\"421\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>\n          <line>23</line>\n          <option name=\"timeStamp\" value=\"422\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>81</line>\n          <option name=\"timeStamp\" value=\"423\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>84</line>\n          <option name=\"timeStamp\" value=\"424\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>88</line>\n          <option name=\"timeStamp\" value=\"425\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>90</line>\n          <option name=\"timeStamp\" value=\"426\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>82</line>\n          <option name=\"timeStamp\" value=\"447\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>83</line>\n          <option name=\"timeStamp\" value=\"448\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>91</line>\n          <option name=\"timeStamp\" value=\"449\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>92</line>\n          <option name=\"timeStamp\" value=\"450\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>38</line>\n          <option name=\"timeStamp\" value=\"451\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>39</line>\n          <option name=\"timeStamp\" value=\"452\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>40</line>\n          <option name=\"timeStamp\" value=\"453\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>41</line>\n          <option name=\"timeStamp\" value=\"454\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>42</line>\n          <option name=\"timeStamp\" value=\"455\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>43</line>\n          <option name=\"timeStamp\" value=\"456\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>44</line>\n          <option name=\"timeStamp\" value=\"457\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>45</line>\n          <option name=\"timeStamp\" value=\"458\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>46</line>\n          <option name=\"timeStamp\" value=\"459\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>47</line>\n          <option name=\"timeStamp\" value=\"460\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>48</line>\n          <option name=\"timeStamp\" value=\"461\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>49</line>\n          <option name=\"timeStamp\" value=\"462\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>50</line>\n          <option name=\"timeStamp\" value=\"463\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>51</line>\n          <option name=\"timeStamp\" value=\"464\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>52</line>\n          <option name=\"timeStamp\" value=\"465\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>93</line>\n          <option name=\"timeStamp\" value=\"466\" />\n        </line-breakpoint>\n        <line-breakpoint enabled=\"true\" suspend=\"THREAD\" type=\"python-line\">\n          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>\n          <line>94</line>\n          <option name=\"timeStamp\" value=\"467\" />\n        </line-breakpoint>\n      </breakpoints>\n      <default-breakpoints>\n        <breakpoint type=\"python-exception\">\n          <properties notifyOnTerminate=\"true\" exception=\"BaseException\">\n            <option name=\"notifyOnTerminate\" value=\"true\" />\n          </properties>\n        </breakpoint>\n      </default-breakpoints>\n    </breakpoint-manager>\n  </component>\n  <component name=\"com.intellij.coverage.CoverageDataManagerImpl\">\n    <SUITE FILE_PATH=\"coverage/AdaRNN_BIT$main_train__1_.coverage\" NAME=\"main_train (1) 覆盖结果\" MODIFIED=\"1649235410099\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/AdaRNN_BIT$data_process.coverage\" NAME=\"data_process 覆盖结果\" MODIFIED=\"1649055397734\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/weather_data\" />\n    <SUITE FILE_PATH=\"coverage/AdaRNN_BIT$weather_traintro.coverage\" NAME=\"weather_traintro 覆盖结果\" MODIFIED=\"1649768051278\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n    <SUITE FILE_PATH=\"coverage/AdaRNN_BIT$train_weather.coverage\" NAME=\"train_weather 覆盖结果\" MODIFIED=\"1646574636543\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/train\" />\n    <SUITE FILE_PATH=\"coverage/AdaRNN_BIT$main_train.coverage\" NAME=\"main_train 覆盖结果\" MODIFIED=\"1649210421599\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/train\" />\n    <SUITE FILE_PATH=\"coverage/AdaRNN_BIT$gpu_pytorch.coverage\" NAME=\"gpu_pytorch 覆盖结果\" MODIFIED=\"1646222494187\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$/model\" />\n    <SUITE FILE_PATH=\"coverage/AdaRNN_BIT$weather_train.coverage\" NAME=\"weather_train 覆盖结果\" MODIFIED=\"1649413454555\" SOURCE_PROVIDER=\"com.intellij.coverage.DefaultCoverageFileProvider\" RUNNER=\"coverage.py\" COVERAGE_BY_TEST_ENABLED=\"true\" COVERAGE_TRACING_ENABLED=\"false\" WORKING_DIRECTORY=\"$PROJECT_DIR$\" />\n  </component>\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/workspace.xml b/.idea/workspace.xml
--- a/.idea/workspace.xml	(revision 4d374eb052e73a15d49eb92596cef4473d6d2218)
+++ b/.idea/workspace.xml	(date 1650010393280)
@@ -14,6 +14,9 @@
       </list>
     </option>
   </component>
+  <component name="Git.Settings">
+    <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
+  </component>
   <component name="GitSEFilterConfiguration">
     <file-type-list>
       <filtered-out-file-type name="LOCAL_BRANCH" />
@@ -26,11 +29,16 @@
     <option name="stateVersion" value="1" />
   </component>
   <component name="ProjectId" id="25oj2ddCrC2oAdtkcLc1lUZV5Md" />
+  <component name="ProjectLevelVcsManager" settingsEditedManually="true">
+    <ConfirmationsSetting value="2" id="Add" />
+  </component>
   <component name="ProjectViewState">
     <option name="hideEmptyMiddlePackages" value="true" />
     <option name="showLibraryContents" value="true" />
   </component>
   <component name="PropertiesComponent">
+    <property name="ASKED_ADD_EXTERNAL_FILES" value="true" />
+    <property name="GitStage.ChangesTree.GroupingKeys" value="directory&#10;module&#10;repository" />
     <property name="RunOnceActivity.OpenProjectViewOnStart" value="true" />
     <property name="RunOnceActivity.ShowReadmeOnStart" value="true" />
     <property name="WebServerToolWindowFactoryState" value="false" />
@@ -45,21 +53,56 @@
       <recent name="$PROJECT_DIR$/model" />
     </key>
   </component>
-  <component name="RunManager" selected="Python.weather_traintro">
-    <configuration default="true" type="PythonConfigurationType" factoryName="Python">
+  <component name="RunManager" selected="Python.TEM_process">
+    <configuration name="TEM_process" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
+      <module name="AdaRNN-BIT" />
+      <option name="INTERPRETER_OPTIONS" value="" />
+      <option name="PARENT_ENVS" value="true" />
+      <option name="SDK_HOME" value="" />
+      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/weather_data" />
+      <option name="IS_MODULE_SDK" value="true" />
+      <option name="ADD_CONTENT_ROOTS" value="true" />
+      <option name="ADD_SOURCE_ROOTS" value="true" />
+      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
+      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/weather_data/TEM_process.py" />
+      <option name="PARAMETERS" value="" />
+      <option name="SHOW_COMMAND_LINE" value="true" />
+      <option name="EMULATE_TERMINAL" value="false" />
+      <option name="MODULE_MODE" value="false" />
+      <option name="REDIRECT_INPUT" value="false" />
+      <option name="INPUT_FILE" value="" />
+      <method v="2" />
+    </configuration>
+    <configuration name="TEdata_process" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
       <module name="AdaRNN-BIT" />
       <option name="INTERPRETER_OPTIONS" value="" />
       <option name="PARENT_ENVS" value="true" />
-      <envs>
-        <env name="PYTHONUNBUFFERED" value="1" />
-      </envs>
       <option name="SDK_HOME" value="" />
-      <option name="WORKING_DIRECTORY" value="" />
-      <option name="IS_MODULE_SDK" value="false" />
+      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/weather_data" />
+      <option name="IS_MODULE_SDK" value="true" />
       <option name="ADD_CONTENT_ROOTS" value="true" />
       <option name="ADD_SOURCE_ROOTS" value="true" />
       <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
-      <option name="SCRIPT_NAME" value="" />
+      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/weather_data/TEdata_process.py" />
+      <option name="PARAMETERS" value="" />
+      <option name="SHOW_COMMAND_LINE" value="true" />
+      <option name="EMULATE_TERMINAL" value="false" />
+      <option name="MODULE_MODE" value="false" />
+      <option name="REDIRECT_INPUT" value="false" />
+      <option name="INPUT_FILE" value="" />
+      <method v="2" />
+    </configuration>
+    <configuration name="UTG_process" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
+      <module name="AdaRNN-BIT" />
+      <option name="INTERPRETER_OPTIONS" value="" />
+      <option name="PARENT_ENVS" value="true" />
+      <option name="SDK_HOME" value="" />
+      <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/weather_data" />
+      <option name="IS_MODULE_SDK" value="true" />
+      <option name="ADD_CONTENT_ROOTS" value="true" />
+      <option name="ADD_SOURCE_ROOTS" value="true" />
+      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
+      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/weather_data/UTG_process.py" />
       <option name="PARAMETERS" value="" />
       <option name="SHOW_COMMAND_LINE" value="true" />
       <option name="EMULATE_TERMINAL" value="false" />
@@ -68,7 +111,7 @@
       <option name="INPUT_FILE" value="" />
       <method v="2" />
     </configuration>
-    <configuration name="data_TEM_test" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
+    <configuration name="UTdata_process" type="PythonConfigurationType" factoryName="Python" temporary="true" nameIsGenerated="true">
       <module name="AdaRNN-BIT" />
       <option name="INTERPRETER_OPTIONS" value="" />
       <option name="PARENT_ENVS" value="true" />
@@ -78,7 +121,29 @@
       <option name="ADD_CONTENT_ROOTS" value="true" />
       <option name="ADD_SOURCE_ROOTS" value="true" />
       <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
-      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/weather_data/data_TEM_test.py" />
+      <option name="SCRIPT_NAME" value="$PROJECT_DIR$/weather_data/UTdata_process.py" />
+      <option name="PARAMETERS" value="" />
+      <option name="SHOW_COMMAND_LINE" value="true" />
+      <option name="EMULATE_TERMINAL" value="false" />
+      <option name="MODULE_MODE" value="false" />
+      <option name="REDIRECT_INPUT" value="false" />
+      <option name="INPUT_FILE" value="" />
+      <method v="2" />
+    </configuration>
+    <configuration default="true" type="PythonConfigurationType" factoryName="Python">
+      <module name="AdaRNN-BIT" />
+      <option name="INTERPRETER_OPTIONS" value="" />
+      <option name="PARENT_ENVS" value="true" />
+      <envs>
+        <env name="PYTHONUNBUFFERED" value="1" />
+      </envs>
+      <option name="SDK_HOME" value="" />
+      <option name="WORKING_DIRECTORY" value="" />
+      <option name="IS_MODULE_SDK" value="false" />
+      <option name="ADD_CONTENT_ROOTS" value="true" />
+      <option name="ADD_SOURCE_ROOTS" value="true" />
+      <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
+      <option name="SCRIPT_NAME" value="" />
       <option name="PARAMETERS" value="" />
       <option name="SHOW_COMMAND_LINE" value="true" />
       <option name="EMULATE_TERMINAL" value="false" />
@@ -106,10 +171,20 @@
       <option name="INPUT_FILE" value="" />
       <method v="2" />
     </configuration>
+    <list>
+      <item itemvalue="Python.weather_traintro" />
+      <item itemvalue="Python.TEM_process" />
+      <item itemvalue="Python.UTG_process" />
+      <item itemvalue="Python.TEdata_process" />
+      <item itemvalue="Python.UTdata_process" />
+    </list>
     <recent_temporary>
       <list>
+        <item itemvalue="Python.TEM_process" />
+        <item itemvalue="Python.UTdata_process" />
+        <item itemvalue="Python.TEdata_process" />
+        <item itemvalue="Python.UTG_process" />
         <item itemvalue="Python.weather_traintro" />
-        <item itemvalue="Python.data_TEM_test" />
       </list>
     </recent_temporary>
   </component>
@@ -166,11 +241,44 @@
       <workItem from="1649727935640" duration="3228000" />
       <workItem from="1649732442220" duration="6038000" />
       <workItem from="1649748507700" duration="14792000" />
+      <workItem from="1649833938639" duration="24752000" />
+      <workItem from="1649923332223" duration="14830000" />
     </task>
     <servers />
   </component>
   <component name="TypeScriptGeneratedFilesManager">
     <option name="version" value="3" />
+  </component>
+  <component name="Vcs.Log.Tabs.Properties">
+    <option name="TAB_STATES">
+      <map>
+        <entry key="MAIN">
+          <value>
+            <State>
+              <option name="CUSTOM_BOOLEAN_PROPERTIES">
+                <map>
+                  <entry key="Show.Git.Branches" value="false" />
+                </map>
+              </option>
+              <option name="FILTERS">
+                <map>
+                  <entry key="branch">
+                    <value>
+                      <list>
+                        <option value="github/train" />
+                      </list>
+                    </value>
+                  </entry>
+                </map>
+              </option>
+            </State>
+          </value>
+        </entry>
+      </map>
+    </option>
+  </component>
+  <component name="VcsManagerConfiguration">
+    <option name="ADD_EXTERNAL_FILES_SILENTLY" value="true" />
   </component>
   <component name="XDebuggerManager">
     <breakpoint-manager>
@@ -221,244 +329,159 @@
           <option name="timeStamp" value="364" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>
-          <line>15</line>
-          <option name="timeStamp" value="392" />
+          <url>file://$PROJECT_DIR$/weather_traintro.py</url>
+          <line>477</line>
+          <option name="timeStamp" value="419" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>
-          <line>17</line>
-          <option name="timeStamp" value="393" />
+          <url>file://$PROJECT_DIR$/weather_traintro.py</url>
+          <line>517</line>
+          <option name="timeStamp" value="420" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>
-          <line>18</line>
-          <option name="timeStamp" value="394" />
+          <url>file://$PROJECT_DIR$/weather_traintro.py</url>
+          <line>518</line>
+          <option name="timeStamp" value="421" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>
-          <line>19</line>
-          <option name="timeStamp" value="395" />
+          <line>15</line>
+          <option name="timeStamp" value="501" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>
-          <line>21</line>
-          <option name="timeStamp" value="396" />
+          <line>30</line>
+          <option name="timeStamp" value="502" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>
-          <line>22</line>
-          <option name="timeStamp" value="397" />
+          <line>31</line>
+          <option name="timeStamp" value="503" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>
-          <line>24</line>
-          <option name="timeStamp" value="399" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>
-          <line>25</line>
-          <option name="timeStamp" value="400" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>
-          <line>27</line>
-          <option name="timeStamp" value="401" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>
-          <line>28</line>
-          <option name="timeStamp" value="402" />
+          <line>32</line>
+          <option name="timeStamp" value="504" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>
           <line>29</line>
-          <option name="timeStamp" value="403" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>
-          <line>30</line>
-          <option name="timeStamp" value="404" />
+          <option name="timeStamp" value="528" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>
-          <line>31</line>
-          <option name="timeStamp" value="405" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>
-          <line>32</line>
-          <option name="timeStamp" value="406" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>78</line>
-          <option name="timeStamp" value="407" />
+          <line>27</line>
+          <option name="timeStamp" value="529" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/weather_traintro.py</url>
-          <line>118</line>
-          <option name="timeStamp" value="415" />
+          <url>file://$PROJECT_DIR$/loss/ncos.py</url>
+          <line>2</line>
+          <option name="timeStamp" value="533" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/weather_traintro.py</url>
-          <line>119</line>
-          <option name="timeStamp" value="416" />
+          <url>file://$PROJECT_DIR$/loss/ncos.py</url>
+          <line>3</line>
+          <option name="timeStamp" value="534" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/weather_traintro.py</url>
-          <line>120</line>
-          <option name="timeStamp" value="417" />
+          <url>file://$PROJECT_DIR$/loss/ncos.py</url>
+          <line>4</line>
+          <option name="timeStamp" value="535" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/weather_traintro.py</url>
-          <line>121</line>
-          <option name="timeStamp" value="418" />
+          <url>file://$PROJECT_DIR$/loss/ncos.py</url>
+          <line>5</line>
+          <option name="timeStamp" value="536" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/weather_traintro.py</url>
-          <line>477</line>
-          <option name="timeStamp" value="419" />
+          <url>file://$PROJECT_DIR$/loss/ncos.py</url>
+          <line>6</line>
+          <option name="timeStamp" value="537" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/weather_traintro.py</url>
-          <line>517</line>
-          <option name="timeStamp" value="420" />
+          <line>105</line>
+          <option name="timeStamp" value="538" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
           <url>file://$PROJECT_DIR$/weather_traintro.py</url>
-          <line>518</line>
-          <option name="timeStamp" value="421" />
+          <line>104</line>
+          <option name="timeStamp" value="539" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/Dilate_loss.py</url>
-          <line>23</line>
-          <option name="timeStamp" value="422" />
+          <url>file://$PROJECT_DIR$/loss/nloss_transfer.py</url>
+          <line>15</line>
+          <option name="timeStamp" value="546" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>81</line>
-          <option name="timeStamp" value="423" />
+          <url>file://$PROJECT_DIR$/loss/nloss_transfer.py</url>
+          <line>14</line>
+          <option name="timeStamp" value="547" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>84</line>
-          <option name="timeStamp" value="424" />
+          <url>file://$PROJECT_DIR$/model_Sept/Dual_Adarnn.py</url>
+          <line>245</line>
+          <option name="timeStamp" value="549" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>88</line>
-          <option name="timeStamp" value="425" />
+          <url>file://$PROJECT_DIR$/model_Sept/Dual_Adarnn.py</url>
+          <line>221</line>
+          <option name="timeStamp" value="550" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>90</line>
-          <option name="timeStamp" value="426" />
+          <url>file://$PROJECT_DIR$/model_Sept/Dual_Adarnn.py</url>
+          <line>246</line>
+          <option name="timeStamp" value="551" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>82</line>
-          <option name="timeStamp" value="447" />
+          <url>file://$PROJECT_DIR$/model_Sept/Dual_Adarnn.py</url>
+          <line>251</line>
+          <option name="timeStamp" value="552" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>83</line>
-          <option name="timeStamp" value="448" />
+          <url>file://$PROJECT_DIR$/model_Sept/Dual_Adarnn.py</url>
+          <line>254</line>
+          <option name="timeStamp" value="553" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>91</line>
-          <option name="timeStamp" value="449" />
+          <url>file://$PROJECT_DIR$/model_Sept/Dual_Adarnn.py</url>
+          <line>252</line>
+          <option name="timeStamp" value="554" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>92</line>
-          <option name="timeStamp" value="450" />
+          <url>file://$PROJECT_DIR$/model_Sept/Dual_Adarnn.py</url>
+          <line>253</line>
+          <option name="timeStamp" value="555" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>38</line>
-          <option name="timeStamp" value="451" />
+          <url>file://$PROJECT_DIR$/model_Sept/Dual_Adarnn.py</url>
+          <line>255</line>
+          <option name="timeStamp" value="556" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>39</line>
-          <option name="timeStamp" value="452" />
+          <url>file://$PROJECT_DIR$/model_Sept/Dual_Adarnn.py</url>
+          <line>256</line>
+          <option name="timeStamp" value="557" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>40</line>
-          <option name="timeStamp" value="453" />
+          <url>file://$PROJECT_DIR$/model_Sept/Dual_Adarnn.py</url>
+          <line>257</line>
+          <option name="timeStamp" value="558" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>41</line>
-          <option name="timeStamp" value="454" />
+          <url>file://$PROJECT_DIR$/model_Sept/Dual_Adarnn.py</url>
+          <line>258</line>
+          <option name="timeStamp" value="559" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>42</line>
-          <option name="timeStamp" value="455" />
+          <url>file://$PROJECT_DIR$/model_Sept/Dual_Adarnn.py</url>
+          <line>247</line>
+          <option name="timeStamp" value="560" />
         </line-breakpoint>
         <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>43</line>
-          <option name="timeStamp" value="456" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>44</line>
-          <option name="timeStamp" value="457" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>45</line>
-          <option name="timeStamp" value="458" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>46</line>
-          <option name="timeStamp" value="459" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>47</line>
-          <option name="timeStamp" value="460" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>48</line>
-          <option name="timeStamp" value="461" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>49</line>
-          <option name="timeStamp" value="462" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>50</line>
-          <option name="timeStamp" value="463" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>51</line>
-          <option name="timeStamp" value="464" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>52</line>
-          <option name="timeStamp" value="465" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>93</line>
-          <option name="timeStamp" value="466" />
-        </line-breakpoint>
-        <line-breakpoint enabled="true" suspend="THREAD" type="python-line">
-          <url>file://$PROJECT_DIR$/loss/soft_dtw.py</url>
-          <line>94</line>
-          <option name="timeStamp" value="467" />
+          <url>file://$PROJECT_DIR$/model_Sept/Dual_Adarnn.py</url>
+          <line>248</line>
+          <option name="timeStamp" value="561" />
         </line-breakpoint>
       </breakpoints>
       <default-breakpoints>
@@ -473,10 +496,11 @@
   <component name="com.intellij.coverage.CoverageDataManagerImpl">
     <SUITE FILE_PATH="coverage/AdaRNN_BIT$main_train__1_.coverage" NAME="main_train (1) 覆盖结果" MODIFIED="1649235410099" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/AdaRNN_BIT$data_process.coverage" NAME="data_process 覆盖结果" MODIFIED="1649055397734" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/weather_data" />
-    <SUITE FILE_PATH="coverage/AdaRNN_BIT$weather_traintro.coverage" NAME="weather_traintro 覆盖结果" MODIFIED="1649768051278" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/AdaRNN_BIT$weather_traintro.coverage" NAME="weather_traintro 覆盖结果" MODIFIED="1649924131764" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
     <SUITE FILE_PATH="coverage/AdaRNN_BIT$train_weather.coverage" NAME="train_weather 覆盖结果" MODIFIED="1646574636543" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/train" />
     <SUITE FILE_PATH="coverage/AdaRNN_BIT$main_train.coverage" NAME="main_train 覆盖结果" MODIFIED="1649210421599" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/train" />
     <SUITE FILE_PATH="coverage/AdaRNN_BIT$gpu_pytorch.coverage" NAME="gpu_pytorch 覆盖结果" MODIFIED="1646222494187" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/model" />
     <SUITE FILE_PATH="coverage/AdaRNN_BIT$weather_train.coverage" NAME="weather_train 覆盖结果" MODIFIED="1649413454555" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
+    <SUITE FILE_PATH="coverage/AdaRNN_BIT$.coverage" NAME=" 覆盖结果" MODIFIED="1649837615689" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$" />
   </component>
 </project>
\ No newline at end of file
Index: weather_data/UTG_process.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2022 Apple, Inc. All Rights Reserved \n#\n# @Time    : 2022/4/12 10:25\n# @Author  : SeptKing\n# @Email   : WJH0923@mail.dlut.edu.cn\n# @File    : UTG_process.py\n# @Software: PyCharm\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport weather_data.data_QX as data_QX\nimport datetime\nfrom loss.nloss_transfer import TransferLoss\nimport torch\nimport math\nfrom weather_data.data_vlsm import pad_all_cases\nfrom weather_data import UTG_process\nimport random\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nSEED = 1234\nrandom.seed(SEED)\n\n\ndef get_split_time(num_domain=2, mode='pre_process', data_file=None, station=None, dis_type='mmd'):\n    spilt_time = {\n        '2': [('2011-1-1 0:0', '2015-11-30 23:0'), ('2015-12-2 0:0', '2020-2-15 23:0')]\n    }\n    if mode == 'pre_process':\n        return spilt_time[str(num_domain)]\n    if mode == 'tdc':\n        return TDC(num_domain, data_file, station, dis_type=dis_type)\n    else:\n        print(\"error in mode\")\n\n\ndef TDC(num_domain, data_file, station, dis_type='mmd'):\n    start_time = datetime.datetime.strptime(\n        '2011-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n    end_time = datetime.datetime.strptime(\n        '2020-2-15 23:00:00', '%Y-%m-%d %H:%M:%S')\n    num_day = (end_time - start_time).days  ##一共有多少天\n    split_N = 10  ##分为10个点\n    data = pd.read_pickle(data_file)[station]\n    feat = data[0]  ##选取训练集数据\n    feat = feat.reshape(-1,24,feat.shape[1])\n    feat = feat[0:num_day]\n    feat = torch.tensor(feat, dtype=torch.float32)\n    feat = feat.reshape(-1, feat.shape[2])  ##对数据按照小时维度进行展开(num_day*24,6)\n    print(feat.size())\n\n    selected = [0, 10]\n    candidate = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    start = 0\n\n    if num_domain in [2, 3, 5, 7, 10]:\n        while len(selected) - 2 < num_domain - 1:\n            distance_list = []\n            for can in candidate:\n                selected.append(can)\n                selected.sort()\n                dis_temp = 0\n                for i in range(1, len(selected) - 1):\n                    for j in range(i, len(selected) - 1):\n                        index_part1_start = start + math.floor(selected[i - 1] / split_N * num_day)\n                        index_part1_end = start + math.floor(selected[i] / split_N * num_day)\n                        feat_part1 = feat[index_part1_start: index_part1_end]\n                        index_part2_start = start + math.floor(selected[j] / split_N * num_day)\n                        index_part2_end = start + math.floor(selected[j + 1] / split_N * num_day)\n                        feat_part2 = feat[index_part2_start:index_part2_end]\n                        criterion_transder = TransferLoss(loss_type=dis_type, input_dim=feat_part1.shape[1])\n                        # dis_temp += criterion_transder.compute(torch.as_tensor(torch.from_numpy(feat_part1), dtype=torch.float32), torch.as_tensor(torch.from_numpy(feat_part2), dtype=torch.float32))\n                        dis_temp += criterion_transder.compute(feat_part1,feat_part2)\n                distance_list.append(dis_temp)\n                selected.remove(can)\n            can_index = distance_list.index(max(distance_list))  ##计算最大的can——index\n            selected.append(candidate[can_index])\n            candidate.remove(candidate[can_index])\n        selected.sort()\n        res = []\n        for i in range(1, len(selected)):\n            if i == 1:\n                sel_start_time = start_time + datetime.timedelta(days=int(num_day / split_N * selected[i - 1]), hours=0)\n            else:\n                sel_start_time = start_time + datetime.timedelta(days=int(num_day / split_N * selected[i - 1]) + 1,\n                                                                 hours=0)\n            sel_end_time = start_time + datetime.timedelta(days=int(num_day / split_N * selected[i]), hours=23)\n            sel_start_time = datetime.datetime.strftime(sel_start_time, '%Y-%m-%d %H:%M')\n            sel_end_time = datetime.datetime.strftime(sel_end_time, '%Y-%m-%d %H:%M')\n            res.append((sel_start_time, sel_end_time))\n        print(res)\n        return res\n    else:\n        print(\"error in number of domain\")\n\n##训练数据生成部分\n\ndef train_val_test_generate(feat, ytrue, model_params):\n    model_params = {\n        'dim_in': 17,\n        'output_length': 6,\n        'min_before': 10,\n        'max_before': 10,\n        'min_after': 10,\n        'max_after': 10,\n    }\n    train_x, train_y, len_x_samples, len_before_x_samples = pad_all_cases(\n        feat, ytrue, model_params, model_params['min_before'], model_params['max_before'],\n        model_params['min_after'], model_params['max_after'],\n        model_params['output_length'])\n    ##扩充维度\n    train_y = np.expand_dims(train_y, axis=2)\n\n    return train_x, train_y, len_x_samples, len_before_x_samples\n\n\ndef train_test_split_SSIM(train_x, train_y, x_len, x_before_len, model_params, SEED):\n    model_params = {\n        'dim_in': 17,\n        'output_length': 6,\n        'min_before': 10,\n        'max_before': 10,\n        'min_after': 10,\n        'max_after': 10,\n    }\n    index_list = []\n    for index, (x_s, y_s, len_s, len_before_s) in enumerate(zip(train_x, train_y, x_len, x_before_len)):\n        if (np.isnan(x_s).any()) or (np.isnan(y_s).any()):\n            index_list.append(index)\n\n    x = np.delete(train_x, index_list, axis=0)\n    y = np.delete(train_y, index_list, axis=0)\n    x_len = np.delete(x_len, index_list, axis=0)\n    x_before_len = np.delete(x_before_len, index_list, axis=0)\n\n    # print('x:{}'.format(x.shape))\n    # print('y:{}'.format(y.shape))\n\n    return x, y, x_len, x_before_len\n\n\ndef train_qld_single_station(x, y):\n    train_sampling_params = {\n        'dim_in': 17,\n        'output_length': 6,\n        'min_before': 10,\n        'max_before': 10,\n        'min_after': 10,\n        'max_after': 10,\n    }\n    feat_train, y_train, feat_train_len, feat_train_before_len = train_val_test_generate(x, y, train_sampling_params)\n    # feat_train, y_train, feat_train_len, feat_train_before_len = train_test_split_SSIM(\n    #     x_sample, y_sample, sample_len, sample_before_len,train_sampling_params, SEED)\n\n    # print('x_train:{}'.format(feat_train.shape))\n    # print('y_train:{}'.format(y_train.shape))\n\n    feat_train = np.split(feat_train, [10, 16], axis=1)\n    feat_train.pop(1)\n\n    return feat_train, y_train\n\n\n##从后向前进行修改\ndef load_weather_data_multi_domain(file_path, batch_size=6, station='Jintang', number_domain=2, mode='pre_process',\n                                   dis_type='mmd'):\n    # mode: 'auto', 'pre_process'\n    data_file = os.path.join(file_path, \"UTG_weather.pkl\")\n\n    ##选取训练数据，计算均值和方差\n    mean_train, std_train = data_QX.get_weather_data_statistic(data_file, station=station,\n                                                               start_time='2011-1-1 0:0',\n                                                               end_time='2020-2-15 23:0')\n    ##对训练数据进行分割，形成分割list\n    split_time_list = get_split_time(number_domain, mode=mode, data_file=data_file, station=station, dis_type=dis_type)\n    train_list = []  ##如果分成两段就有两个train——loader\n    ##对于每个分割列表应用vlstm形成(n,leq,dim)\n    for i in range(len(split_time_list)):\n        time_temp = split_time_list[i]\n\n        feat, ytrue = data_QX.create_dataset(data_file, station=station, start_date=time_temp[0],\n                                             end_date=time_temp[1], mean=None, std=None)\n\n        ##feat是一个list,主要有两个元素，第一个元素是array(770,10,16),第二个元素也是，然后将array转换成\n        feat_train, y_train = train_qld_single_station(feat, ytrue)\n\n        # print(feat_train)\n        # print(y_train)\n        train_loader = data_QX.create_train_dataset(\n            feat_train, y_train, batch_size=batch_size, mean=mean_train, std=std_train)\n\n\n        train_list.append(train_loader)\n\n    ##对于验证集和测试集的数据准备\n    feat_v, ytrue_v = data_QX.create_dataset(\n        data_file, station=station, start_date='2019-5-1 0:0', end_date='2020-12-31 23:0', mean=None, std=None)\n    feat_valid, y_valid = train_qld_single_station(feat_v, ytrue_v)\n    valid_vld_loader = data_QX.create_train_dataset(\n        feat_valid, y_valid, batch_size=batch_size, mean=mean_train, std=std_train)\n\n    ##测试集数据调整\n    feat_te, ytrue_te = data_QX.create_dataset(\n        data_file, station=station, start_date='2019-4-1 0:0', end_date='2020-5-31 23:0', mean=None, std=None)\n    feat_test, y_test = train_qld_single_station(feat_te, ytrue_te)\n    test_loader = data_QX.create_train_dataset(\n        feat_test, y_test, batch_size=batch_size, mean=mean_train, std=std_train)\n    return train_list, valid_vld_loader, test_loader\n\n\nif __name__ == '__main__':\n    file_path = r'/Volumes/王九和/科研/农业大数据相关/实验/实验程序/AdaRNN-BIT/weather_data'\n    train_list, valid_vld_loader, test_loder = load_weather_data_multi_domain(file_path, batch_size=2,\n                                                                              station='Jintang', number_domain=5,\n                                                                              mode='tdc', dis_type='mmd')
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/weather_data/UTG_process.py b/weather_data/UTG_process.py
--- a/weather_data/UTG_process.py	(revision 4d374eb052e73a15d49eb92596cef4473d6d2218)
+++ b/weather_data/UTG_process.py	(date 1650009142410)
@@ -28,7 +28,7 @@
 
 def get_split_time(num_domain=2, mode='pre_process', data_file=None, station=None, dis_type='mmd'):
     spilt_time = {
-        '2': [('2011-1-1 0:0', '2015-11-30 23:0'), ('2015-12-2 0:0', '2020-2-15 23:0')]
+        '2': [('2011-1-1 0:0', '2015-11-30 23:0'), ('2015-12-2 0:0', '2020-3-15 23:0')]
     }
     if mode == 'pre_process':
         return spilt_time[str(num_domain)]
@@ -42,7 +42,7 @@
     start_time = datetime.datetime.strptime(
         '2011-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')
     end_time = datetime.datetime.strptime(
-        '2020-2-15 23:00:00', '%Y-%m-%d %H:%M:%S')
+        '2020-3-15 23:00:00', '%Y-%m-%d %H:%M:%S')
     num_day = (end_time - start_time).days  ##一共有多少天
     split_N = 10  ##分为10个点
     data = pd.read_pickle(data_file)[station]
@@ -174,7 +174,7 @@
     ##选取训练数据，计算均值和方差
     mean_train, std_train = data_QX.get_weather_data_statistic(data_file, station=station,
                                                                start_time='2011-1-1 0:0',
-                                                               end_time='2020-2-15 23:0')
+                                                               end_time='2020-3-15 23:0')
     ##对训练数据进行分割，形成分割list
     split_time_list = get_split_time(number_domain, mode=mode, data_file=data_file, station=station, dis_type=dis_type)
     train_list = []  ##如果分成两段就有两个train——loader
@@ -198,7 +198,7 @@
 
     ##对于验证集和测试集的数据准备
     feat_v, ytrue_v = data_QX.create_dataset(
-        data_file, station=station, start_date='2019-5-1 0:0', end_date='2020-12-31 23:0', mean=None, std=None)
+        data_file, station=station, start_date='2020-6-1 0:0', end_date='2020-12-31 23:0', mean=None, std=None)
     feat_valid, y_valid = train_qld_single_station(feat_v, ytrue_v)
     valid_vld_loader = data_QX.create_train_dataset(
         feat_valid, y_valid, batch_size=batch_size, mean=mean_train, std=std_train)
Index: loss/Dilate_loss.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2022 Apple, Inc. All Rights Reserved \n#\n# @Time    : 2022/3/30 21:55\n# @Author  : SeptKing\n# @Email   : WJH0923@mail.dlut.edu.cn\n# @File    : Dilate_loss.py\n# @Software: PyCharm\nimport torch\nfrom . import soft_dtw\nfrom . import path_soft_dtw\n\n\ndef dilate_loss(outputs, targets, alpha, gamma, device):\n    # outputs, targets: shape (batch_size, N_output, 1)（24，6，1）\n    batch_size, N_output = outputs.shape[0:2]\n    loss_shape = 0\n    softdtw_batch = soft_dtw.SoftDTWBatch.apply\n    ##24，6，6\n    D = torch.zeros((batch_size, N_output, N_output)).to(device)\n    for k in range(batch_size):\n        Dk = soft_dtw.pairwise_distances(targets[k, :, :].view(-1, 1), outputs[k, :, :].view(-1, 1))\n        D[k:k + 1, :, :] = Dk\n    loss_shape = softdtw_batch(D, gamma)\n\n    path_dtw = path_soft_dtw.PathDTWBatch.apply\n    path = path_dtw(D, gamma)\n    Omega = soft_dtw.pairwise_distances(torch.arange(1, N_output+1).view(N_output, 1)).to(device)  ##是个对称矩阵\n    loss_temporal = torch.sum(path * Omega) / (N_output * N_output)\n    loss = alpha * loss_shape + (1 - alpha) * loss_temporal\n    return loss, loss_shape, loss_temporal
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/loss/Dilate_loss.py b/loss/Dilate_loss.py
--- a/loss/Dilate_loss.py	(revision 4d374eb052e73a15d49eb92596cef4473d6d2218)
+++ b/loss/Dilate_loss.py	(date 1649921072350)
@@ -26,6 +26,7 @@
     loss_shape = softdtw_batch(D, gamma)
 
     path_dtw = path_soft_dtw.PathDTWBatch.apply
+    ##(24,6,6)d表示的是一个x，y之间的距离
     path = path_dtw(D, gamma)
     Omega = soft_dtw.pairwise_distances(torch.arange(1, N_output+1).view(N_output, 1)).to(device)  ##是个对称矩阵
     loss_temporal = torch.sum(path * Omega) / (N_output * N_output)
Index: loss/soft_dtw.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2022 Apple, Inc. All Rights Reserved \n#\n# @Time    : 2022/3/24 16:12\n# @Author  : SeptKing\n# @Email   : WJH0923@mail.dlut.edu.cn\n# @File    : soft_dtw.py\n# @Software: PyCharm\nimport numpy as np\nimport torch\nfrom numba import jit\nfrom torch.autograd import Function\n\n\ndef pairwise_distances(x, y=None):\n    '''\n    Input: x is a Nxd matrix\n           y is an optional Mxd matirx\n    Output: dist is a NxM matrix where dist[i,j] is the square norm between x[i,:] and y[j,:]\n            if y is not given then use 'y=x'.\n    i.e. dist[i,j] = ||x[i,:]-y[j,:]||^2\n    '''\n    x_norm = (x ** 2).sum(1).view(-1, 1)\n    if y is not None:\n        y_t = torch.transpose(y, 0, 1)\n        y_norm = (y ** 2).sum(1).view(1, -1)\n    else:\n        y_t = torch.transpose(x, 0, 1)\n        y_norm = x_norm.view(1, -1)\n\n    dist = x_norm + y_norm - 2.0 * torch.mm(x, y_t)\n    ##返回夹紧函数\n    return torch.clamp(dist, 0.0, float('inf'))\n\n\n@jit(nopython=True)\ndef compute_softdtw(D, gamma):\n    N = D.shape[0]  ##1\n    M = D.shape[1]  ##1\n    R = np.zeros((N + 2, M + 2)) + 1e8\n    R[0, 0] = 0\n    for j in range(1, M + 1):  ##(1,6)\n        for i in range(1, N + 1):  ##(1,6)\n            r0 = -R[i - 1, j - 1] / gamma\n            r1 = -R[i - 1, j] / gamma\n            r2 = -R[i, j - 1] / gamma\n            rmax = max(max(r0, r1), r2)\n            rsum = np.exp(r0 - rmax) + np.exp(r1 - rmax) + np.exp(r2 - rmax)\n            softmin = - gamma * (np.log(rsum) + rmax)\n            R[i, j] = D[i - 1, j - 1] + softmin\n    return R\n\n\n@jit(nopython=True)\ndef compute_softdtw_backward(D_, R, gamma):\n    N = D_.shape[0]\n    M = D_.shape[1]\n    D = np.zeros((N + 2, M + 2))\n    E = np.zeros((N + 2, M + 2))\n    D[1:N + 1, 1:M + 1] = D_\n    E[-1, -1] = 1\n    R[:, -1] = -1e8\n    R[-1, :] = -1e8\n    R[-1, -1] = R[-2, -2]\n    for j in range(M, 0, -1):\n        for i in range(N, 0, -1):\n            a0 = (R[i + 1, j] - R[i, j] - D[i + 1, j]) / gamma\n            b0 = (R[i, j + 1] - R[i, j] - D[i, j + 1]) / gamma\n            c0 = (R[i + 1, j + 1] - R[i, j] - D[i + 1, j + 1]) / gamma\n            a = np.exp(a0)\n            b = np.exp(b0)\n            c = np.exp(c0)\n            E[i, j] = E[i + 1, j] * a + E[i, j + 1] * b + E[i + 1, j + 1] * c\n    return E[1:N + 1, 1:M + 1]\n\n\nclass SoftDTWBatch(Function):\n    @staticmethod\n    def forward(ctx, D, gamma=1.0):  # D.shape: [batch_size, N , N]##ctx类似于self\n        dev = D.device\n        batch_size, N, N = D.shape\n        gamma = torch.FloatTensor([gamma]).to(dev)\n        D_ = D.detach().cpu().numpy()  ##去除梯度信息然后将其传入cpu然后转为numpy（）\n        g_ = gamma.item()  ##获取元素的值\n\n        total_loss = 0\n        R = torch.zeros((batch_size, N + 2, N + 2)).to(dev)\n        for k in range(0, batch_size):  # loop over all D in the batch\n            Rk = torch.FloatTensor(compute_softdtw(D_[k, :, :], g_)).to(dev)\n            R[k:k + 1, :, :] = Rk\n            total_loss = total_loss + Rk[-2, -2]\n        ctx.save_for_backward(D, R, gamma)  ##将输入保存起来，在backward中使用\n        return total_loss / batch_size\n\n    @staticmethod  ##说明该方法属于静态方法\n    def backward(ctx, grad_output):\n        dev = grad_output.device\n        D, R, gamma = ctx.saved_tensors\n        batch_size, N, N = D.shape\n        D_ = D.detach().cpu().numpy()\n        R_ = R.detach().cpu().numpy()\n        g_ = gamma.item()\n\n        E = torch.zeros((batch_size, N, N)).to(dev)\n        for k in range(batch_size):\n            Ek = torch.FloatTensor(compute_softdtw_backward(D_[k, :, :], R_[k, :, :], g_)).to(dev)\n            E[k:k + 1, :, :] = Ek\n\n        return grad_output * E, None\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/loss/soft_dtw.py b/loss/soft_dtw.py
--- a/loss/soft_dtw.py	(revision 4d374eb052e73a15d49eb92596cef4473d6d2218)
+++ b/loss/soft_dtw.py	(date 1649909679290)
@@ -46,8 +46,11 @@
             r0 = -R[i - 1, j - 1] / gamma
             r1 = -R[i - 1, j] / gamma
             r2 = -R[i, j - 1] / gamma
+            # r_text = np.exp(r0)+np.exp(r1)+np.exp(r2)
+            # softmin = -gamma*(np.log(r_text))
             rmax = max(max(r0, r1), r2)
             rsum = np.exp(r0 - rmax) + np.exp(r1 - rmax) + np.exp(r2 - rmax)
+            ftt = np.log(rsum) + rmax
             softmin = - gamma * (np.log(rsum) + rmax)
             R[i, j] = D[i - 1, j - 1] + softmin
     return R
@@ -87,8 +90,10 @@
 
         total_loss = 0
         R = torch.zeros((batch_size, N + 2, N + 2)).to(dev)
-        for k in range(0, batch_size):  # loop over all D in the batch
-            Rk = torch.FloatTensor(compute_softdtw(D_[k, :, :], g_)).to(dev)
+        for k in range(0, batch_size):
+            # loop over all D in the batch
+            mmdd = compute_softdtw(D_[k, :, :], g_)
+            Rk = torch.FloatTensor(mmdd).to(dev)
             R[k:k + 1, :, :] = Rk
             total_loss = total_loss + Rk[-2, -2]
         ctx.save_for_backward(D, R, gamma)  ##将输入保存起来，在backward中使用
Index: loss/ncos.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import torch.nn as nn\n\ndef cosine(source, target):\n    source, target = source.mean(), target.mean()\n    cos = nn.CosineSimilarity(dim = 0)\n    loss = cos(source, target)\n    return loss.mean()
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/loss/ncos.py b/loss/ncos.py
--- a/loss/ncos.py	(revision 4d374eb052e73a15d49eb92596cef4473d6d2218)
+++ b/loss/ncos.py	(date 1649922162310)
@@ -1,7 +1,7 @@
 import torch.nn as nn
 
 def cosine(source, target):
-    source, target = source.mean(), target.mean()
+    ##source, target = source.mean(), target.mean()
     cos = nn.CosineSimilarity(dim = 0)
     loss = cos(source, target)
     return loss.mean()
\ No newline at end of file
Index: weather_data/UTdata_process.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/weather_data/UTdata_process.py b/weather_data/UTdata_process.py
new file mode 100755
--- /dev/null	(date 1650009142400)
+++ b/weather_data/UTdata_process.py	(date 1650009142400)
@@ -0,0 +1,219 @@
+#!/usr/bin/python3.6
+# -*- coding: utf-8 -*-
+#
+# Copyright (C) 2022 Apple, Inc. All Rights Reserved 
+#
+# @Time    : 2022/4/15 15:00
+# @Author  : SeptKing
+# @Email   : WJH0923@mail.dlut.edu.cn
+# @File    : UTdata_process.py
+# @Software: PyCharm
+import os
+
+import numpy as np
+import pandas as pd
+import weather_data.data_QX as data_QX
+import datetime
+from loss.nloss_transfer import TransferLoss
+import torch
+import math
+from weather_data.data_vlsm import pad_all_cases
+from weather_data import UTG_process
+import random
+
+device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
+SEED = 1234
+random.seed(SEED)
+
+
+def get_split_time(num_domain=2, mode='pre_process', data_file=None, station=None, dis_type='mmd'):
+    spilt_time = {
+        '2': [('2011-1-1 0:0', '2015-11-30 23:0'), ('2015-12-2 0:0', '2020-3-15 23:0')]
+    }
+    if mode == 'pre_process':
+        return spilt_time[str(num_domain)]
+    if mode == 'tdc':
+        return TDC(num_domain, data_file, station, dis_type=dis_type)
+    else:
+        print("error in mode")
+
+
+def TDC(num_domain, data_file, station, dis_type='mmd'):
+    start_time = datetime.datetime.strptime(
+        '2011-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')
+    end_time = datetime.datetime.strptime(
+        '2020-3-15 23:00:00', '%Y-%m-%d %H:%M:%S')
+    num_day = (end_time - start_time).days  ##一共有多少天
+    split_N = 10  ##分为10个点
+    data = pd.read_pickle(data_file)[station]
+    feat = data[0]  ##选取训练集数据
+    feat = feat.reshape(-1,24,feat.shape[1])
+    feat = feat[0:num_day]
+    feat = torch.tensor(feat, dtype=torch.float32)
+    feat = feat.reshape(-1, feat.shape[2])  ##对数据按照小时维度进行展开(num_day*24,6)
+    print(feat.size())
+
+    selected = [0, 10]
+    candidate = [1, 2, 3, 4, 5, 6, 7, 8, 9]
+    start = 0
+
+    if num_domain in [2, 3, 5, 7, 10]:
+        while len(selected) - 2 < num_domain - 1:
+            distance_list = []
+            for can in candidate:
+                selected.append(can)
+                selected.sort()
+                dis_temp = 0
+                for i in range(1, len(selected) - 1):
+                    for j in range(i, len(selected) - 1):
+                        index_part1_start = start + math.floor(selected[i - 1] / split_N * num_day)
+                        index_part1_end = start + math.floor(selected[i] / split_N * num_day)
+                        feat_part1 = feat[index_part1_start: index_part1_end]
+                        index_part2_start = start + math.floor(selected[j] / split_N * num_day)
+                        index_part2_end = start + math.floor(selected[j + 1] / split_N * num_day)
+                        feat_part2 = feat[index_part2_start:index_part2_end]
+                        criterion_transder = TransferLoss(loss_type=dis_type, input_dim=feat_part1.shape[1])
+                        # dis_temp += criterion_transder.compute(torch.as_tensor(torch.from_numpy(feat_part1), dtype=torch.float32), torch.as_tensor(torch.from_numpy(feat_part2), dtype=torch.float32))
+                        dis_temp += criterion_transder.compute(feat_part1,feat_part2)
+                distance_list.append(dis_temp)
+                selected.remove(can)
+            can_index = distance_list.index(max(distance_list))  ##计算最大的can——index
+            selected.append(candidate[can_index])
+            candidate.remove(candidate[can_index])
+        selected.sort()
+        res = []
+        for i in range(1, len(selected)):
+            if i == 1:
+                sel_start_time = start_time + datetime.timedelta(days=int(num_day / split_N * selected[i - 1]), hours=0)
+            else:
+                sel_start_time = start_time + datetime.timedelta(days=int(num_day / split_N * selected[i - 1]) + 1,
+                                                                 hours=0)
+            sel_end_time = start_time + datetime.timedelta(days=int(num_day / split_N * selected[i]), hours=23)
+            sel_start_time = datetime.datetime.strftime(sel_start_time, '%Y-%m-%d %H:%M')
+            sel_end_time = datetime.datetime.strftime(sel_end_time, '%Y-%m-%d %H:%M')
+            res.append((sel_start_time, sel_end_time))
+        print(res)
+        return res
+    else:
+        print("error in number of domain")
+
+##训练数据生成部分
+
+def train_val_test_generate(feat, ytrue, model_params):
+    model_params = {
+        'dim_in': 17,
+        'output_length': 6,
+        'min_before': 10,
+        'max_before': 10,
+        'min_after': 10,
+        'max_after': 10,
+    }
+    train_x, train_y, len_x_samples, len_before_x_samples = pad_all_cases(
+        feat, ytrue, model_params, model_params['min_before'], model_params['max_before'],
+        model_params['min_after'], model_params['max_after'],
+        model_params['output_length'])
+    ##扩充维度
+    train_y = np.expand_dims(train_y, axis=2)
+
+    return train_x, train_y, len_x_samples, len_before_x_samples
+
+
+def train_test_split_SSIM(train_x, train_y, x_len, x_before_len, model_params, SEED):
+    model_params = {
+        'dim_in': 17,
+        'output_length': 6,
+        'min_before': 10,
+        'max_before': 10,
+        'min_after': 10,
+        'max_after': 10,
+    }
+    index_list = []
+    for index, (x_s, y_s, len_s, len_before_s) in enumerate(zip(train_x, train_y, x_len, x_before_len)):
+        if (np.isnan(x_s).any()) or (np.isnan(y_s).any()):
+            index_list.append(index)
+
+    x = np.delete(train_x, index_list, axis=0)
+    y = np.delete(train_y, index_list, axis=0)
+    x_len = np.delete(x_len, index_list, axis=0)
+    x_before_len = np.delete(x_before_len, index_list, axis=0)
+
+    # print('x:{}'.format(x.shape))
+    # print('y:{}'.format(y.shape))
+
+    return x, y, x_len, x_before_len
+
+
+def train_qld_single_station(x, y):
+    train_sampling_params = {
+        'dim_in': 17,
+        'output_length': 6,
+        'min_before': 10,
+        'max_before': 10,
+        'min_after': 10,
+        'max_after': 10,
+    }
+    feat_train, y_train, feat_train_len, feat_train_before_len = train_val_test_generate(x, y, train_sampling_params)
+    # feat_train, y_train, feat_train_len, feat_train_before_len = train_test_split_SSIM(
+    #     x_sample, y_sample, sample_len, sample_before_len,train_sampling_params, SEED)
+
+    # print('x_train:{}'.format(feat_train.shape))
+    # print('y_train:{}'.format(y_train.shape))
+
+    feat_train = np.split(feat_train, [10, 16], axis=1)
+    feat_train.pop(1)
+
+    return feat_train, y_train
+
+
+##从后向前进行修改
+def load_weather_data_multi_domain(file_path, batch_size=6, station='Jintang', number_domain=2, mode='pre_process',
+                                   dis_type='mmd'):
+    # mode: 'auto', 'pre_process'
+    data_file = os.path.join(file_path, "UTG_data.pkl")
+
+    ##选取训练数据，计算均值和方差
+    mean_train, std_train = data_QX.get_weather_data_statistic(data_file, station=station,
+                                                               start_time='2011-1-1 0:0',
+                                                               end_time='2020-3-15 23:0')
+    ##对训练数据进行分割，形成分割list
+    split_time_list = get_split_time(number_domain, mode=mode, data_file=data_file, station=station, dis_type=dis_type)
+    train_list = []  ##如果分成两段就有两个train——loader
+    ##对于每个分割列表应用vlstm形成(n,leq,dim)
+    for i in range(len(split_time_list)):
+        time_temp = split_time_list[i]
+
+        feat, ytrue = data_QX.create_dataset(data_file, station=station, start_date=time_temp[0],
+                                             end_date=time_temp[1], mean=None, std=None)
+
+        ##feat是一个list,主要有两个元素，第一个元素是array(770,10,16),第二个元素也是，然后将array转换成
+        feat_train, y_train = train_qld_single_station(feat, ytrue)
+
+        # print(feat_train)
+        # print(y_train)
+        train_loader = data_QX.create_train_dataset(
+            feat_train, y_train, batch_size=batch_size, mean=mean_train, std=std_train)
+
+
+        train_list.append(train_loader)
+
+    ##对于验证集和测试集的数据准备
+    feat_v, ytrue_v = data_QX.create_dataset(
+        data_file, station=station, start_date='2020-6-1 0:0', end_date='2020-12-31 23:0', mean=None, std=None)
+    feat_valid, y_valid = train_qld_single_station(feat_v, ytrue_v)
+    valid_vld_loader = data_QX.create_train_dataset(
+        feat_valid, y_valid, batch_size=batch_size, mean=mean_train, std=std_train)
+
+    ##测试集数据调整
+    feat_te, ytrue_te = data_QX.create_dataset(
+        data_file, station=station, start_date='2019-4-1 0:0', end_date='2020-5-31 23:0', mean=None, std=None)
+    feat_test, y_test = train_qld_single_station(feat_te, ytrue_te)
+    test_loader = data_QX.create_train_dataset(
+        feat_test, y_test, batch_size=batch_size, mean=mean_train, std=std_train)
+    return train_list, valid_vld_loader, test_loader
+
+
+if __name__ == '__main__':
+    file_path = r'/Volumes/王九和/科研/农业大数据相关/实验/实验程序/AdaRNN-BIT/weather_data'
+    train_list, valid_vld_loader, test_loder = load_weather_data_multi_domain(file_path, batch_size=2,
+                                                                              station='Jintang', number_domain=5,
+                                                                              mode='tdc', dis_type='mmd')
\ No newline at end of file
Index: weather_data/TEM_process.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2022 Apple, Inc. All Rights Reserved \n#\n# @Time    : 2022/4/8 10:01\n# @Author  : SeptKing\n# @Email   : WJH0923@mail.dlut.edu.cn\n# @File    : TEM_process.py\n# @Software: PyCharm\nimport os\n\nimport numpy as np\nimport pandas as pd\nimport weather_data.data_QX as data_QX\nimport datetime\nfrom loss.nloss_transfer import TransferLoss\nimport torch\nimport math\nfrom weather_data.data_vlsm import pad_all_cases\nfrom weather_data import TEM_process\nimport random\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nSEED = 1234\nrandom.seed(SEED)\n\n\ndef get_split_time(num_domain=2, mode='pre_process', data_file=None, station=None, dis_type='mmd'):\n    spilt_time = {\n        '2': [('2011-1-1 0:0', '2015-11-30 23:0'), ('2015-12-2 0:0', '2020-2-15 23:0')]\n    }\n    if mode == 'pre_process':\n        return spilt_time[str(num_domain)]\n    if mode == 'tdc':\n        return TDC(num_domain, data_file, station, dis_type=dis_type)\n    else:\n        print(\"error in mode\")\n\n\ndef TDC(num_domain, data_file, station, dis_type='mmd'):\n    start_time = datetime.datetime.strptime(\n        '2011-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n    end_time = datetime.datetime.strptime(\n        '2020-2-15 23:00:00', '%Y-%m-%d %H:%M:%S')\n    num_day = (end_time - start_time).days  ##一共有多少天\n    split_N = 10  ##分为10个点\n    data = pd.read_pickle(data_file)[station]\n    feat = data[0]  ##选取训练集数据\n    feat = feat.reshape(-1,24,feat.shape[1])\n    feat = feat[0:num_day]\n    feat = torch.tensor(feat, dtype=torch.float32)\n    feat = feat.reshape(-1, feat.shape[2])  ##对数据按照小时维度进行展开(num_day*24,6)\n    print(feat.size())\n\n    selected = [0, 10]\n    candidate = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n    start = 0\n\n    if num_domain in [2, 3, 5, 7, 10]:\n        while len(selected) - 2 < num_domain - 1:\n            distance_list = []\n            for can in candidate:\n                selected.append(can)\n                selected.sort()\n                dis_temp = 0\n                for i in range(1, len(selected) - 1):\n                    for j in range(i, len(selected) - 1):\n                        index_part1_start = start + math.floor(selected[i - 1] / split_N * num_day)\n                        index_part1_end = start + math.floor(selected[i] / split_N * num_day)\n                        feat_part1 = feat[index_part1_start: index_part1_end]\n                        index_part2_start = start + math.floor(selected[j] / split_N * num_day)\n                        index_part2_end = start + math.floor(selected[j + 1] / split_N * num_day)\n                        feat_part2 = feat[index_part2_start:index_part2_end]\n                        criterion_transder = TransferLoss(loss_type=dis_type, input_dim=feat_part1.shape[1])\n                        # dis_temp += criterion_transder.compute(torch.as_tensor(torch.from_numpy(feat_part1), dtype=torch.float32), torch.as_tensor(torch.from_numpy(feat_part2), dtype=torch.float32))\n                        dis_temp += criterion_transder.compute(feat_part1,feat_part2)\n                distance_list.append(dis_temp)\n                selected.remove(can)\n            can_index = distance_list.index(max(distance_list))  ##计算最大的can——index\n            selected.append(candidate[can_index])\n            candidate.remove(candidate[can_index])\n        selected.sort()\n        res = []\n        for i in range(1, len(selected)):\n            if i == 1:\n                sel_start_time = start_time + datetime.timedelta(days=int(num_day / split_N * selected[i - 1]), hours=0)\n            else:\n                sel_start_time = start_time + datetime.timedelta(days=int(num_day / split_N * selected[i - 1]) + 1,\n                                                                 hours=0)\n            sel_end_time = start_time + datetime.timedelta(days=int(num_day / split_N * selected[i]), hours=23)\n            sel_start_time = datetime.datetime.strftime(sel_start_time, '%Y-%m-%d %H:%M')\n            sel_end_time = datetime.datetime.strftime(sel_end_time, '%Y-%m-%d %H:%M')\n            res.append((sel_start_time, sel_end_time))\n        print(res)\n        return res\n    else:\n        print(\"error in number of domain\")\n\n##训练数据生成部分\n\ndef train_val_test_generate(feat, ytrue, model_params):\n    model_params = {\n        'dim_in': 17,\n        'output_length': 6,\n        'min_before': 10,\n        'max_before': 10,\n        'min_after': 10,\n        'max_after': 10,\n    }\n    train_x, train_y, len_x_samples, len_before_x_samples = pad_all_cases(\n        feat, ytrue, model_params, model_params['min_before'], model_params['max_before'],\n        model_params['min_after'], model_params['max_after'],\n        model_params['output_length'])\n    ##扩充维度\n    train_y = np.expand_dims(train_y, axis=2)\n\n    return train_x, train_y, len_x_samples, len_before_x_samples\n\n\ndef train_test_split_SSIM(train_x, train_y, x_len, x_before_len, model_params, SEED):\n    model_params = {\n        'dim_in': 17,\n        'output_length': 6,\n        'min_before': 10,\n        'max_before': 10,\n        'min_after': 10,\n        'max_after': 10,\n    }\n    index_list = []\n    for index, (x_s, y_s, len_s, len_before_s) in enumerate(zip(train_x, train_y, x_len, x_before_len)):\n        if (np.isnan(x_s).any()) or (np.isnan(y_s).any()):\n            index_list.append(index)\n\n    x = np.delete(train_x, index_list, axis=0)\n    y = np.delete(train_y, index_list, axis=0)\n    x_len = np.delete(x_len, index_list, axis=0)\n    x_before_len = np.delete(x_before_len, index_list, axis=0)\n\n    # print('x:{}'.format(x.shape))\n    # print('y:{}'.format(y.shape))\n\n    return x, y, x_len, x_before_len\n\n\ndef train_qld_single_station(x, y):\n    train_sampling_params = {\n        'dim_in': 17,\n        'output_length': 6,\n        'min_before': 10,\n        'max_before': 10,\n        'min_after': 10,\n        'max_after': 10,\n    }\n    feat_train, y_train, feat_train_len, feat_train_before_len = train_val_test_generate(x, y, train_sampling_params)\n    # feat_train, y_train, feat_train_len, feat_train_before_len = train_test_split_SSIM(\n    #     x_sample, y_sample, sample_len, sample_before_len,train_sampling_params, SEED)\n\n    # print('x_train:{}'.format(feat_train.shape))\n    # print('y_train:{}'.format(y_train.shape))\n\n    feat_train = np.split(feat_train, [10, 16], axis=1)\n    feat_train.pop(1)\n\n    return feat_train, y_train\n\n\n##从后向前进行修改\ndef load_weather_data_multi_domain(file_path, batch_size=6, station='Jintang', number_domain=2, mode='pre_process',\n                                   dis_type='mmd'):\n    # mode: 'auto', 'pre_process'\n    data_file = os.path.join(file_path, \"QX_weather.pkl\")\n\n    ##选取训练数据，计算均值和方差\n    mean_train, std_train = data_QX.get_weather_data_statistic(data_file, station=station,\n                                                               start_time='2011-1-1 0:0',\n                                                               end_time='2020-2-15 23:0')\n    ##对训练数据进行分割，形成分割list\n    split_time_list = get_split_time(number_domain, mode=mode, data_file=data_file, station=station, dis_type=dis_type)\n    train_list = []  ##如果分成两段就有两个train——loader\n    ##对于每个分割列表应用vlstm形成(n,leq,dim)\n    for i in range(len(split_time_list)):\n        time_temp = split_time_list[i]\n\n        feat, ytrue = data_QX.create_dataset(data_file, station=station, start_date=time_temp[0],\n                                             end_date=time_temp[1], mean=None, std=None)\n\n        ##feat是一个list,主要有两个元素，第一个元素是array(770,10,16),第二个元素也是，然后将array转换成\n        feat_train, y_train = train_qld_single_station(feat, ytrue)\n\n        # print(feat_train)\n        # print(y_train)\n        train_loader = data_QX.create_train_dataset(\n            feat_train, y_train, batch_size=batch_size, mean=mean_train, std=std_train)\n\n\n        train_list.append(train_loader)\n\n    ##对于验证集和测试集的数据准备\n    feat_v, ytrue_v = data_QX.create_dataset(\n        data_file, station=station, start_date='2019-5-1 0:0', end_date='2020-12-31 23:0', mean=None, std=None)\n    feat_valid, y_valid = train_qld_single_station(feat_v, ytrue_v)\n    valid_vld_loader = data_QX.create_train_dataset(\n        feat_valid, y_valid, batch_size=batch_size, mean=mean_train, std=std_train)\n\n    ##测试集数据调整\n    feat_te, ytrue_te = data_QX.create_dataset(\n        data_file, station=station, start_date='2019-4-1 0:0', end_date='2020-5-31 23:0', mean=None, std=None)\n    feat_test, y_test = train_qld_single_station(feat_te, ytrue_te)\n    test_loader = data_QX.create_train_dataset(\n        feat_test, y_test, batch_size=batch_size, mean=mean_train, std=std_train)\n    return train_list, valid_vld_loader, test_loader\n\n\nif __name__ == '__main__':\n    file_path = r'/Volumes/王九和/科研/农业大数据相关/实验/实验程序/AdaRNN-BIT/weather_data'\n    train_list, valid_vld_loader, test_loder = load_weather_data_multi_domain(file_path, batch_size=2,\n                                                                              station='Jintang', number_domain=5,\n                                                                              mode='tdc', dis_type='mmd')\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/weather_data/TEM_process.py b/weather_data/TEM_process.py
--- a/weather_data/TEM_process.py	(revision 4d374eb052e73a15d49eb92596cef4473d6d2218)
+++ b/weather_data/TEM_process.py	(date 1650010367890)
@@ -28,7 +28,7 @@
 
 def get_split_time(num_domain=2, mode='pre_process', data_file=None, station=None, dis_type='mmd'):
     spilt_time = {
-        '2': [('2011-1-1 0:0', '2015-11-30 23:0'), ('2015-12-2 0:0', '2020-2-15 23:0')]
+        '2': [('2011-1-1 0:0', '2015-11-30 23:0'), ('2015-12-2 0:0', '2020-3-15 23:0')]
     }
     if mode == 'pre_process':
         return spilt_time[str(num_domain)]
@@ -42,7 +42,7 @@
     start_time = datetime.datetime.strptime(
         '2011-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')
     end_time = datetime.datetime.strptime(
-        '2020-2-15 23:00:00', '%Y-%m-%d %H:%M:%S')
+        '2020-3-15 23:00:00', '%Y-%m-%d %H:%M:%S')
     num_day = (end_time - start_time).days  ##一共有多少天
     split_N = 10  ##分为10个点
     data = pd.read_pickle(data_file)[station]
@@ -169,12 +169,12 @@
 def load_weather_data_multi_domain(file_path, batch_size=6, station='Jintang', number_domain=2, mode='pre_process',
                                    dis_type='mmd'):
     # mode: 'auto', 'pre_process'
-    data_file = os.path.join(file_path, "QX_weather.pkl")
+    data_file = os.path.join(file_path, "TEM_weather.pkl")
 
     ##选取训练数据，计算均值和方差
     mean_train, std_train = data_QX.get_weather_data_statistic(data_file, station=station,
                                                                start_time='2011-1-1 0:0',
-                                                               end_time='2020-2-15 23:0')
+                                                               end_time='2020-3-15 23:0')
     ##对训练数据进行分割，形成分割list
     split_time_list = get_split_time(number_domain, mode=mode, data_file=data_file, station=station, dis_type=dis_type)
     train_list = []  ##如果分成两段就有两个train——loader
@@ -198,7 +198,7 @@
 
     ##对于验证集和测试集的数据准备
     feat_v, ytrue_v = data_QX.create_dataset(
-        data_file, station=station, start_date='2019-5-1 0:0', end_date='2020-12-31 23:0', mean=None, std=None)
+        data_file, station=station, start_date='2020-6-1 0:0', end_date='2020-12-31 23:0', mean=None, std=None)
     feat_valid, y_valid = train_qld_single_station(feat_v, ytrue_v)
     valid_vld_loader = data_QX.create_train_dataset(
         feat_valid, y_valid, batch_size=batch_size, mean=mean_train, std=std_train)
@@ -215,5 +215,5 @@
 if __name__ == '__main__':
     file_path = r'/Volumes/王九和/科研/农业大数据相关/实验/实验程序/AdaRNN-BIT/weather_data'
     train_list, valid_vld_loader, test_loder = load_weather_data_multi_domain(file_path, batch_size=2,
-                                                                              station='Jintang', number_domain=5,
+                                                                              station='Jintang', number_domain=3,
                                                                               mode='tdc', dis_type='mmd')
Index: outputs_Jintang_DualAdaRNN_weather_cosine_20_0.05_0.0005/run.log
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>[2022-04-09 23:56:38] - create model_king...\n[2022-04-09 23:56:38] - Epoch: 0\n[2022-04-09 23:56:38] - training...\n[2022-04-09 23:57:16] - create model_king...\n[2022-04-09 23:57:16] - Epoch: 0\n[2022-04-09 23:57:16] - training...\n[2022-04-10 00:04:16] - [-2.31969056 -0.30319098  0.01081533] 0.06449885454821101\n[2022-04-10 00:04:16] - evaluating...\n[2022-04-10 00:04:45] - valid_l1 0.087966, test_l1 0.079351\n[2022-04-10 00:04:45] - valid_dtw 0.255410, test_dtw 0.229427\n[2022-04-10 00:04:45] - Epoch: 1\n[2022-04-10 00:04:45] - training...\n[2022-04-10 00:05:03] - [-2.31969056 -0.30319098  0.01081533] 0.06449885454821101\n[2022-04-10 00:05:03] - evaluating...\n[2022-04-10 00:05:33] - valid_l1 0.087966, test_l1 0.079351\n[2022-04-10 00:05:33] - valid_dtw 0.255410, test_dtw 0.229427\n[2022-04-10 00:05:33] - Epoch: 1\n[2022-04-10 00:05:33] - training...\n[2022-04-10 00:12:14] - [-2.88059369 -0.35256733  0.00799316] 0.046078629586648975\n[2022-04-10 00:12:14] - evaluating...\n[2022-04-10 00:12:42] - valid_l1 0.125819, test_l1 0.119027\n[2022-04-10 00:12:42] - valid_dtw 0.387967, test_dtw 0.366660\n[2022-04-10 00:12:42] - Epoch: 2\n[2022-04-10 00:12:42] - training...\n[2022-04-10 00:13:12] - [-2.88059369 -0.35256733  0.00799316] 0.046078629586648975\n[2022-04-10 00:13:12] - evaluating...\n[2022-04-10 00:13:40] - valid_l1 0.125819, test_l1 0.119027\n[2022-04-10 00:13:40] - valid_dtw 0.387967, test_dtw 0.366660\n[2022-04-10 00:13:40] - Epoch: 2\n[2022-04-10 00:13:40] - training...\n[2022-04-10 00:20:11] - [-2.94620415e+00 -3.51414282e-01 -1.79141100e-08] 0.04573239990949721\n[2022-04-10 00:20:11] - evaluating...\n[2022-04-10 00:20:39] - valid_l1 0.135873, test_l1 0.127416\n[2022-04-10 00:20:39] - valid_dtw 0.404239, test_dtw 0.376411\n[2022-04-10 00:20:39] - Epoch: 3\n[2022-04-10 00:20:39] - training...\n[2022-04-10 00:21:20] - [-2.94620415e+00 -3.51414282e-01 -1.79141100e-08] 0.04573239990949721\n[2022-04-10 00:21:20] - evaluating...\n[2022-04-10 00:21:48] - valid_l1 0.135873, test_l1 0.127416\n[2022-04-10 00:21:48] - valid_dtw 0.404239, test_dtw 0.376411\n[2022-04-10 00:21:48] - Epoch: 3\n[2022-04-10 00:21:48] - training...\n[2022-04-10 00:28:08] - [-3.01168836e+00 -3.56707975e-01 -1.43705252e-08] 0.043569503065485224\n[2022-04-10 00:28:08] - evaluating...\n[2022-04-10 00:28:36] - valid_l1 0.121195, test_l1 0.109979\n[2022-04-10 00:28:36] - valid_dtw 0.384121, test_dtw 0.350404\n[2022-04-10 00:28:36] - Epoch: 4\n[2022-04-10 00:28:36] - training...\n[2022-04-10 00:29:27] - [-3.01168836e+00 -3.56707975e-01 -1.43705252e-08] 0.043569503065485224\n[2022-04-10 00:29:27] - evaluating...\n[2022-04-10 00:29:56] - valid_l1 0.121195, test_l1 0.109979\n[2022-04-10 00:29:56] - valid_dtw 0.384121, test_dtw 0.350404\n[2022-04-10 00:29:56] - Epoch: 4\n[2022-04-10 00:29:56] - training...\n[2022-04-10 00:36:07] - [-3.05149111e+00 -3.60690551e-01 -1.80387188e-08] 0.043042878475641415\n[2022-04-10 00:36:07] - evaluating...\n[2022-04-10 00:36:35] - valid_l1 0.087379, test_l1 0.077823\n[2022-04-10 00:36:35] - valid_dtw 0.302244, test_dtw 0.267986\n[2022-04-10 00:36:35] - Epoch: 5\n[2022-04-10 00:36:35] - training...\n[2022-04-10 00:37:36] - [-3.05149111e+00 -3.60690551e-01 -1.80387188e-08] 0.043042878475641415\n[2022-04-10 00:37:36] - evaluating...\n[2022-04-10 00:38:05] - valid_l1 0.087379, test_l1 0.077823\n[2022-04-10 00:38:05] - valid_dtw 0.302244, test_dtw 0.267986\n[2022-04-10 00:38:05] - Epoch: 5\n[2022-04-10 00:38:05] - training...\n[2022-04-10 00:44:04] - [-3.04907183e+00 -3.61190882e-01 -1.59065980e-08] 0.04266061294306952\n[2022-04-10 00:44:04] - evaluating...\n[2022-04-10 00:44:32] - valid_l1 0.080472, test_l1 0.071636\n[2022-04-10 00:44:32] - valid_dtw 0.271907, test_dtw 0.241559\n[2022-04-10 00:44:32] - Epoch: 6\n[2022-04-10 00:44:32] - training...\n[2022-04-10 00:45:45] - [-3.04907183e+00 -3.61190882e-01 -1.59065980e-08] 0.04266061294306952\n[2022-04-10 00:45:45] - evaluating...\n[2022-04-10 00:46:14] - valid_l1 0.080472, test_l1 0.071636\n[2022-04-10 00:46:14] - valid_dtw 0.271907, test_dtw 0.241559\n[2022-04-10 00:46:14] - Epoch: 6\n[2022-04-10 00:46:14] - training...\n[2022-04-10 00:52:02] - [-3.07209713e+00 -3.65108022e-01  2.41502774e-03] 0.04051659109146751\n[2022-04-10 00:52:02] - evaluating...\n[2022-04-10 00:52:31] - valid_l1 0.094964, test_l1 0.087368\n[2022-04-10 00:52:31] - valid_dtw 0.303473, test_dtw 0.276724\n[2022-04-10 00:52:31] - Epoch: 7\n[2022-04-10 00:52:31] - training...\n[2022-04-10 00:53:53] - [-3.07209713e+00 -3.65108022e-01  2.41502774e-03] 0.04051659109146751\n[2022-04-10 00:53:53] - evaluating...\n[2022-04-10 00:54:22] - valid_l1 0.094964, test_l1 0.087368\n[2022-04-10 00:54:22] - valid_dtw 0.303473, test_dtw 0.276724\n[2022-04-10 00:54:22] - Epoch: 7\n[2022-04-10 00:54:22] - training...\n[2022-04-10 01:00:02] - [-3.09555713 -0.36492715  0.00660534] 0.040643977830088156\n[2022-04-10 01:00:02] - evaluating...\n[2022-04-10 01:00:30] - valid_l1 0.077489, test_l1 0.075902\n[2022-04-10 01:00:30] - valid_dtw 0.258873, test_dtw 0.246634\n[2022-04-10 01:00:30] - Epoch: 8\n[2022-04-10 01:00:30] - training...\n[2022-04-10 01:02:02] - [-3.09555713 -0.36492715  0.00660534] 0.040643977830088156\n[2022-04-10 01:02:02] - evaluating...\n[2022-04-10 01:02:30] - valid_l1 0.077489, test_l1 0.075902\n[2022-04-10 01:02:30] - valid_dtw 0.258873, test_dtw 0.246634\n[2022-04-10 01:02:30] - Epoch: 8\n[2022-04-10 01:02:30] - training...\n[2022-04-10 01:08:00] - [-3.08876657 -0.36533379  0.01632659] 0.040281565432882055\n[2022-04-10 01:08:00] - evaluating...\n[2022-04-10 01:08:28] - valid_l1 0.075807, test_l1 0.072614\n[2022-04-10 01:08:28] - valid_dtw 0.268445, test_dtw 0.252157\n[2022-04-10 01:08:28] - Epoch: 9\n[2022-04-10 01:08:28] - training...\n[2022-04-10 01:10:11] - [-3.08876657 -0.36533379  0.01632659] 0.040281565432882055\n[2022-04-10 01:10:11] - evaluating...\n[2022-04-10 01:10:39] - valid_l1 0.075807, test_l1 0.072614\n[2022-04-10 01:10:39] - valid_dtw 0.268445, test_dtw 0.252157\n[2022-04-10 01:10:39] - Epoch: 9\n[2022-04-10 01:10:39] - training...\n[2022-04-10 01:15:59] - [-2.62101047 -0.36500694  0.10989379] 0.04072797146301329\n[2022-04-10 01:15:59] - evaluating...\n[2022-04-10 01:16:27] - valid_l1 0.084040, test_l1 0.078345\n[2022-04-10 01:16:27] - valid_dtw 0.295761, test_dtw 0.274915\n[2022-04-10 01:16:27] - Epoch: 10\n[2022-04-10 01:16:27] - training...\n[2022-04-10 01:18:20] - [-2.62101047 -0.36500694  0.10989379] 0.04072797146301329\n[2022-04-10 01:18:20] - evaluating...\n[2022-04-10 01:18:48] - valid_l1 0.084040, test_l1 0.078345\n[2022-04-10 01:18:48] - valid_dtw 0.295761, test_dtw 0.274915\n[2022-04-10 01:18:48] - Epoch: 10\n[2022-04-10 01:18:48] - training...\n[2022-04-10 01:23:58] - [-3.03642852 -0.36667245  0.31611701] 0.04007119733592998\n[2022-04-10 01:23:58] - evaluating...\n[2022-04-10 01:24:26] - valid_l1 0.082652, test_l1 0.082284\n[2022-04-10 01:24:26] - valid_dtw 0.285484, test_dtw 0.278665\n[2022-04-10 01:24:26] - Epoch: 11\n[2022-04-10 01:24:26] - training...\n[2022-04-10 01:26:30] - [-3.03642852 -0.36667245  0.31611701] 0.04007119733592998\n[2022-04-10 01:26:30] - evaluating...\n[2022-04-10 01:26:59] - valid_l1 0.082652, test_l1 0.082284\n[2022-04-10 01:26:59] - valid_dtw 0.285484, test_dtw 0.278665\n[2022-04-10 01:26:59] - Epoch: 11\n[2022-04-10 01:26:59] - training...\n[2022-04-10 01:31:58] - [-3.00184165e+00 -3.64456385e-01  5.29635914e-04] 0.041185768206672656\n[2022-04-10 01:31:58] - evaluating...\n[2022-04-10 01:32:26] - valid_l1 0.086364, test_l1 0.082658\n[2022-04-10 01:32:26] - valid_dtw 0.300577, test_dtw 0.285668\n[2022-04-10 01:32:26] - Epoch: 12\n[2022-04-10 01:32:26] - training...\n[2022-04-10 01:34:40] - [-3.00184165e+00 -3.64456385e-01  5.29635914e-04] 0.041185768206672656\n[2022-04-10 01:34:40] - evaluating...\n[2022-04-10 01:35:09] - valid_l1 0.086364, test_l1 0.082658\n[2022-04-10 01:35:09] - valid_dtw 0.300577, test_dtw 0.285668\n[2022-04-10 01:35:09] - Epoch: 12\n[2022-04-10 01:35:09] - training...\n[2022-04-10 01:40:01] - [-3.12180578e+00 -3.65220393e-01 -1.53746729e-08] 0.0405780142454113\n[2022-04-10 01:40:01] - evaluating...\n[2022-04-10 01:40:29] - valid_l1 0.084767, test_l1 0.082979\n[2022-04-10 01:40:29] - valid_dtw 0.307438, test_dtw 0.297434\n[2022-04-10 01:40:29] - Epoch: 13\n[2022-04-10 01:40:29] - training...\n[2022-04-10 01:42:50] - [-3.12180578e+00 -3.65220393e-01 -1.53746729e-08] 0.0405780142454113\n[2022-04-10 01:42:50] - evaluating...\n[2022-04-10 01:43:18] - valid_l1 0.084767, test_l1 0.082979\n[2022-04-10 01:43:18] - valid_dtw 0.307438, test_dtw 0.297434\n[2022-04-10 01:43:18] - Epoch: 13\n[2022-04-10 01:43:18] - training...\n[2022-04-10 01:48:02] - [-3.13855639e+00 -3.62450022e-01 -1.64437367e-08] 0.041404497403747\n[2022-04-10 01:48:02] - evaluating...\n[2022-04-10 01:48:30] - valid_l1 0.075481, test_l1 0.074706\n[2022-04-10 01:48:30] - valid_dtw 0.260462, test_dtw 0.252883\n[2022-04-10 01:48:30] - Epoch: 14\n[2022-04-10 01:48:30] - training...\n[2022-04-10 01:51:00] - [-3.13855639e+00 -3.62450022e-01 -1.64437367e-08] 0.041404497403747\n[2022-04-10 01:51:00] - evaluating...\n[2022-04-10 01:51:28] - valid_l1 0.075481, test_l1 0.074706\n[2022-04-10 01:51:28] - valid_dtw 0.260462, test_dtw 0.252883\n[2022-04-10 01:51:28] - Epoch: 14\n[2022-04-10 01:51:28] - training...\n[2022-04-10 01:56:06] - [-3.08272243e+00 -3.61325799e-01 -1.84870294e-08] 0.04237494786827633\n[2022-04-10 01:56:06] - evaluating...\n[2022-04-10 01:56:34] - valid_l1 0.063688, test_l1 0.060238\n[2022-04-10 01:56:34] - valid_dtw 0.225121, test_dtw 0.210675\n[2022-04-10 01:56:34] - Epoch: 15\n[2022-04-10 01:56:34] - training...\n[2022-04-10 01:59:09] - [-3.08272243e+00 -3.61325799e-01 -1.84870294e-08] 0.04237494786827633\n[2022-04-10 01:59:09] - evaluating...\n[2022-04-10 01:59:38] - valid_l1 0.063688, test_l1 0.060238\n[2022-04-10 01:59:38] - valid_dtw 0.225121, test_dtw 0.210675\n[2022-04-10 01:59:38] - Epoch: 15\n[2022-04-10 01:59:38] - training...\n[2022-04-10 02:04:10] - [-3.11773179 -0.36526309  0.00516978] 0.040634370653371735\n[2022-04-10 02:04:10] - evaluating...\n[2022-04-10 02:04:39] - valid_l1 0.068127, test_l1 0.066209\n[2022-04-10 02:04:39] - valid_dtw 0.251685, test_dtw 0.241212\n[2022-04-10 02:04:39] - Epoch: 16\n[2022-04-10 02:04:39] - training...\n[2022-04-10 02:07:19] - [-3.11773179 -0.36526309  0.00516978] 0.040634370653371735\n[2022-04-10 02:07:19] - evaluating...\n[2022-04-10 02:07:48] - valid_l1 0.068127, test_l1 0.066209\n[2022-04-10 02:07:48] - valid_dtw 0.251685, test_dtw 0.241212\n[2022-04-10 02:07:48] - Epoch: 16\n[2022-04-10 02:07:48] - training...\n[2022-04-10 02:12:13] - [-3.12602767 -0.36479556  0.01984058] 0.04059125285252906\n[2022-04-10 02:12:13] - evaluating...\n[2022-04-10 02:12:41] - valid_l1 0.067910, test_l1 0.068504\n[2022-04-10 02:12:41] - valid_dtw 0.252318, test_dtw 0.246155\n[2022-04-10 02:12:41] - Epoch: 17\n[2022-04-10 02:12:41] - training...\n[2022-04-10 02:15:28] - [-3.12602767 -0.36479556  0.01984058] 0.04059125285252906\n[2022-04-10 02:15:28] - evaluating...\n[2022-04-10 02:15:56] - valid_l1 0.067910, test_l1 0.068504\n[2022-04-10 02:15:56] - valid_dtw 0.252318, test_dtw 0.246155\n[2022-04-10 02:15:56] - Epoch: 17\n[2022-04-10 02:15:56] - training...\n[2022-04-10 02:20:14] - [-3.16384247 -0.36839757  0.00317076] 0.0391466171883867\n[2022-04-10 02:20:14] - evaluating...\n[2022-04-10 02:20:43] - valid_l1 0.078676, test_l1 0.073689\n[2022-04-10 02:20:43] - valid_dtw 0.289557, test_dtw 0.271829\n[2022-04-10 02:20:43] - Epoch: 18\n[2022-04-10 02:20:43] - training...\n[2022-04-10 02:23:38] - [-3.16384247 -0.36839757  0.00317076] 0.0391466171883867\n[2022-04-10 02:23:38] - evaluating...\n[2022-04-10 02:24:06] - valid_l1 0.078676, test_l1 0.073689\n[2022-04-10 02:24:06] - valid_dtw 0.289557, test_dtw 0.271829\n[2022-04-10 02:24:06] - Epoch: 18\n[2022-04-10 02:24:06] - training...\n[2022-04-10 02:28:17] - [-3.11897705e+00 -3.66537326e-01 -1.70248077e-08] 0.03970765429204765\n[2022-04-10 02:28:17] - evaluating...\n[2022-04-10 02:28:46] - valid_l1 0.072874, test_l1 0.071576\n[2022-04-10 02:28:46] - valid_dtw 0.254197, test_dtw 0.249511\n[2022-04-10 02:28:46] - Epoch: 19\n[2022-04-10 02:28:46] - training...\n[2022-04-10 02:31:46] - [-3.11897705e+00 -3.66537326e-01 -1.70248077e-08] 0.03970765429204765\n[2022-04-10 02:31:46] - evaluating...\n[2022-04-10 02:32:16] - valid_l1 0.072874, test_l1 0.071576\n[2022-04-10 02:32:16] - valid_dtw 0.254197, test_dtw 0.249511\n[2022-04-10 02:32:16] - Epoch: 19\n[2022-04-10 02:32:16] - training...\n[2022-04-10 02:36:15] - [-2.66633589 -0.36677045  0.45015808] 0.040270409834758006\n[2022-04-10 02:36:15] - evaluating...\n[2022-04-10 02:36:42] - valid_l1 0.086646, test_l1 0.085540\n[2022-04-10 02:36:42] - valid_dtw 0.309436, test_dtw 0.300236\n[2022-04-10 02:36:42] - Epoch: 20\n[2022-04-10 02:36:42] - training...\n[2022-04-10 02:39:42] - [-2.66633589 -0.36677045  0.45015808] 0.040270409834758006\n[2022-04-10 02:39:42] - evaluating...\n[2022-04-10 02:40:10] - valid_l1 0.086646, test_l1 0.085540\n[2022-04-10 02:40:10] - valid_dtw 0.309436, test_dtw 0.300236\n[2022-04-10 02:40:10] - Epoch: 20\n[2022-04-10 02:40:10] - training...\n[2022-04-10 02:43:53] - [-2.69888738 -0.36769739  0.25102729] 0.03979905054315947\n[2022-04-10 02:43:53] - evaluating...\n[2022-04-10 02:44:20] - valid_l1 0.095054, test_l1 0.089699\n[2022-04-10 02:44:20] - valid_dtw 0.335305, test_dtw 0.311573\n[2022-04-10 02:44:20] - Epoch: 21\n[2022-04-10 02:44:20] - training...\n[2022-04-10 02:47:34] - [-2.69888738 -0.36769739  0.25102729] 0.03979905054315947\n[2022-04-10 02:47:34] - evaluating...\n[2022-04-10 02:48:03] - valid_l1 0.095054, test_l1 0.089699\n[2022-04-10 02:48:03] - valid_dtw 0.335305, test_dtw 0.311573\n[2022-04-10 02:48:03] - Epoch: 21\n[2022-04-10 02:48:03] - training...\n[2022-04-10 02:53:26] - [-2.98272825 -0.36710581  0.35821233] 0.04000590570330013\n[2022-04-10 02:53:26] - evaluating...\n[2022-04-10 02:53:53] - valid_l1 0.078964, test_l1 0.074827\n[2022-04-10 02:53:53] - valid_dtw 0.283984, test_dtw 0.261374\n[2022-04-10 02:53:53] - Epoch: 22\n[2022-04-10 02:53:53] - training...\n[2022-04-10 02:57:49] - [-2.98272825 -0.36710581  0.35821233] 0.04000590570330013\n[2022-04-10 02:57:49] - evaluating...\n[2022-04-10 02:58:18] - valid_l1 0.078964, test_l1 0.074827\n[2022-04-10 02:58:18] - valid_dtw 0.283984, test_dtw 0.261374\n[2022-04-10 02:58:18] - Epoch: 22\n[2022-04-10 02:58:18] - training...\n[2022-04-10 03:04:17] - [-2.99043337 -0.36824214  0.34815555] 0.03911451785509133\n[2022-04-10 03:04:17] - evaluating...\n[2022-04-10 03:04:46] - valid_l1 0.108055, test_l1 0.103960\n[2022-04-10 03:04:46] - valid_dtw 0.368242, test_dtw 0.347299\n[2022-04-10 03:04:46] - Epoch: 23\n[2022-04-10 03:04:46] - training...\n[2022-04-10 03:09:31] - [-2.99043337 -0.36824214  0.34815555] 0.03911451785509133\n[2022-04-10 03:09:32] - evaluating...\n[2022-04-10 03:10:00] - valid_l1 0.108055, test_l1 0.103960\n[2022-04-10 03:10:00] - valid_dtw 0.368242, test_dtw 0.347299\n[2022-04-10 03:10:00] - Epoch: 23\n[2022-04-10 03:10:00] - training...\n[2022-04-10 03:15:28] - [-2.86112212 -0.36694053  0.33540742] 0.03997347103277303\n[2022-04-10 03:15:28] - evaluating...\n[2022-04-10 03:15:55] - valid_l1 0.083617, test_l1 0.077835\n[2022-04-10 03:15:55] - valid_dtw 0.307570, test_dtw 0.282442\n[2022-04-10 03:15:55] - Epoch: 24\n[2022-04-10 03:15:55] - training...\n[2022-04-10 03:22:55] - [-2.86112212 -0.36694053  0.33540742] 0.03997347103277303\n[2022-04-10 03:22:55] - evaluating...\n[2022-04-10 03:23:24] - valid_l1 0.083617, test_l1 0.077835\n[2022-04-10 03:23:24] - valid_dtw 0.307570, test_dtw 0.282442\n[2022-04-10 03:23:24] - Epoch: 24\n[2022-04-10 03:23:24] - training...\n[2022-04-10 03:27:26] - [-2.76740942 -0.37111912  0.3062264 ] 0.038028638218536547\n[2022-04-10 03:27:26] - evaluating...\n[2022-04-10 03:27:54] - valid_l1 0.083279, test_l1 0.075863\n[2022-04-10 03:27:54] - valid_dtw 0.295653, test_dtw 0.265493\n[2022-04-10 03:27:54] - Epoch: 25\n[2022-04-10 03:27:54] - training...\n[2022-04-10 03:35:37] - [-2.76740942 -0.37111912  0.3062264 ] 0.038028638218536547\n[2022-04-10 03:35:37] - evaluating...\n[2022-04-10 03:36:06] - valid_l1 0.083279, test_l1 0.075863\n[2022-04-10 03:36:06] - valid_dtw 0.295653, test_dtw 0.265493\n[2022-04-10 03:36:06] - Epoch: 25\n[2022-04-10 03:36:06] - training...\n[2022-04-10 03:41:13] - [-2.8142739  -0.36949594  0.2261668 ] 0.038509991233480104\n[2022-04-10 03:41:13] - evaluating...\n[2022-04-10 03:41:41] - valid_l1 0.069950, test_l1 0.069587\n[2022-04-10 03:41:41] - valid_dtw 0.257211, test_dtw 0.247415\n[2022-04-10 03:41:41] - Epoch: 26\n[2022-04-10 03:41:41] - training...\n[2022-04-10 03:48:08] - [-2.8142739  -0.36949594  0.2261668 ] 0.038509991233480104\n[2022-04-10 03:48:08] - evaluating...\n[2022-04-10 03:48:37] - valid_l1 0.069950, test_l1 0.069587\n[2022-04-10 03:48:37] - valid_dtw 0.257211, test_dtw 0.247415\n[2022-04-10 03:48:37] - Epoch: 26\n[2022-04-10 03:48:37] - training...\n[2022-04-10 03:56:11] - [-3.03390363 -0.36973362  0.36729719] 0.03829254382915042\n[2022-04-10 03:56:11] - evaluating...\n[2022-04-10 03:56:39] - valid_l1 0.071524, test_l1 0.066172\n[2022-04-10 03:56:39] - valid_dtw 0.255772, test_dtw 0.235380\n[2022-04-10 03:56:39] - Epoch: 27\n[2022-04-10 03:56:39] - training...\n[2022-04-10 04:01:32] - [-3.03390363 -0.36973362  0.36729719] 0.03829254382915042\n[2022-04-10 04:01:33] - evaluating...\n[2022-04-10 04:02:02] - valid_l1 0.071524, test_l1 0.066172\n[2022-04-10 04:02:02] - valid_dtw 0.255772, test_dtw 0.235380\n[2022-04-10 04:02:02] - Epoch: 27\n[2022-04-10 04:02:02] - training...\n[2022-04-10 04:10:43] - [-3.0381735  -0.36805088  0.07099994] 0.039274525512599835\n[2022-04-10 04:10:43] - evaluating...\n[2022-04-10 04:11:12] - valid_l1 0.078320, test_l1 0.074676\n[2022-04-10 04:11:12] - valid_dtw 0.280293, test_dtw 0.262962\n[2022-04-10 04:11:12] - Epoch: 28\n[2022-04-10 04:11:12] - training...\n[2022-04-10 04:17:01] - [-3.0381735  -0.36805088  0.07099994] 0.039274525512599835\n[2022-04-10 04:17:01] - evaluating...\n[2022-04-10 04:17:30] - valid_l1 0.078320, test_l1 0.074676\n[2022-04-10 04:17:30] - valid_dtw 0.280293, test_dtw 0.262962\n[2022-04-10 04:17:30] - Epoch: 28\n[2022-04-10 04:17:30] - training...\n[2022-04-10 04:27:06] - [-3.21070704 -0.36941189  0.02441683] 0.03873937311238113\n[2022-04-10 04:27:06] - evaluating...\n[2022-04-10 04:27:36] - valid_l1 0.080507, test_l1 0.075898\n[2022-04-10 04:27:36] - valid_dtw 0.275401, test_dtw 0.252277\n[2022-04-10 04:27:36] - Epoch: 29\n[2022-04-10 04:27:36] - training...\n[2022-04-10 04:34:11] - [-3.21070704 -0.36941189  0.02441683] 0.03873937311238113\n[2022-04-10 04:34:11] - evaluating...\n[2022-04-10 04:34:40] - valid_l1 0.080507, test_l1 0.075898\n[2022-04-10 04:34:40] - valid_dtw 0.275401, test_dtw 0.252277\n[2022-04-10 04:34:40] - Epoch: 29\n[2022-04-10 04:34:40] - training...\n[2022-04-10 04:44:10] - [-3.11350619 -0.36766992  0.06943515] 0.03934968531210408\n[2022-04-10 04:44:10] - evaluating...\n[2022-04-10 04:44:39] - valid_l1 0.077356, test_l1 0.072388\n[2022-04-10 04:44:39] - valid_dtw 0.272646, test_dtw 0.251899\n[2022-04-10 04:44:39] - Epoch: 30\n[2022-04-10 04:44:39] - training...\n[2022-04-10 04:50:59] - [-3.11350619 -0.36766992  0.06943515] 0.03934968531210408\n[2022-04-10 04:50:59] - evaluating...\n[2022-04-10 04:51:28] - valid_l1 0.077356, test_l1 0.072388\n[2022-04-10 04:51:28] - valid_dtw 0.272646, test_dtw 0.251899\n[2022-04-10 04:51:28] - Epoch: 30\n[2022-04-10 04:51:28] - training...\n[2022-04-10 04:59:37] - [-3.1503003  -0.36972613  0.02764744] 0.0380209752233477\n[2022-04-10 04:59:37] - evaluating...\n[2022-04-10 05:00:05] - valid_l1 0.078334, test_l1 0.074448\n[2022-04-10 05:00:05] - valid_dtw 0.274517, test_dtw 0.257462\n[2022-04-10 05:00:05] - Epoch: 31\n[2022-04-10 05:00:05] - training...\n[2022-04-10 05:08:40] - [-3.1503003  -0.36972613  0.02764744] 0.0380209752233477\n[2022-04-10 05:08:40] - evaluating...\n[2022-04-10 05:09:10] - valid_l1 0.078334, test_l1 0.074448\n[2022-04-10 05:09:10] - valid_dtw 0.274517, test_dtw 0.257462\n[2022-04-10 05:09:10] - Epoch: 31\n[2022-04-10 05:09:10] - training...\n[2022-04-10 05:15:15] - [-3.16536433e+00 -3.68767729e-01  7.49096401e-04] 0.038406467562482366\n[2022-04-10 05:15:15] - evaluating...\n[2022-04-10 05:15:43] - valid_l1 0.071473, test_l1 0.064434\n[2022-04-10 05:15:43] - valid_dtw 0.254070, test_dtw 0.224306\n[2022-04-10 05:15:43] - Epoch: 32\n[2022-04-10 05:15:43] - training...\n[2022-04-10 05:25:36] - [-3.16536433e+00 -3.68767729e-01  7.49096401e-04] 0.038406467562482366\n[2022-04-10 05:25:36] - evaluating...\n[2022-04-10 05:26:06] - valid_l1 0.071473, test_l1 0.064434\n[2022-04-10 05:26:06] - valid_dtw 0.254070, test_dtw 0.224306\n[2022-04-10 05:26:06] - Epoch: 32\n[2022-04-10 05:26:06] - training...\n[2022-04-10 05:33:17] - [-3.20255676e+00 -3.70186092e-01  7.74351178e-04] 0.03811839912339573\n[2022-04-10 05:33:17] - evaluating...\n[2022-04-10 05:33:46] - valid_l1 0.070446, test_l1 0.065361\n[2022-04-10 05:33:46] - valid_dtw 0.262517, test_dtw 0.235052\n[2022-04-10 05:33:46] - Epoch: 33\n[2022-04-10 05:33:46] - training...\n[2022-04-10 05:41:39] - [-3.20255676e+00 -3.70186092e-01  7.74351178e-04] 0.03811839912339573\n[2022-04-10 05:41:40] - evaluating...\n[2022-04-10 05:42:08] - valid_l1 0.070446, test_l1 0.065361\n[2022-04-10 05:42:08] - valid_dtw 0.262517, test_dtw 0.235052\n[2022-04-10 05:42:08] - Epoch: 33\n[2022-04-10 05:42:08] - training...\n[2022-04-10 05:52:51] - [-3.06507115 -0.36847412  0.00907075] 0.03876004409224784\n[2022-04-10 05:52:51] - evaluating...\n[2022-04-10 05:53:20] - valid_l1 0.073716, test_l1 0.071768\n[2022-04-10 05:53:20] - valid_dtw 0.273448, test_dtw 0.256033\n[2022-04-10 05:53:20] - Epoch: 34\n[2022-04-10 05:53:20] - training...\n[2022-04-10 05:58:06] - [-3.06507115 -0.36847412  0.00907075] 0.03876004409224784\n[2022-04-10 05:58:07] - evaluating...\n[2022-04-10 05:58:36] - valid_l1 0.073716, test_l1 0.071768\n[2022-04-10 05:58:36] - valid_dtw 0.273448, test_dtw 0.256033\n[2022-04-10 05:58:36] - Epoch: 34\n[2022-04-10 05:58:36] - training...\n[2022-04-10 06:12:12] - [-3.08873181 -0.36940394  0.10918664] 0.038385817906109905\n[2022-04-10 06:12:12] - evaluating...\n[2022-04-10 06:12:42] - valid_l1 0.080811, test_l1 0.074588\n[2022-04-10 06:12:42] - valid_dtw 0.291715, test_dtw 0.263366\n[2022-04-10 06:12:42] - Epoch: 35\n[2022-04-10 06:12:42] - training...\n[2022-04-10 06:17:52] - [-3.08873181 -0.36940394  0.10918664] 0.038385817906109905\n[2022-04-10 06:17:52] - evaluating...\n[2022-04-10 06:18:22] - valid_l1 0.080811, test_l1 0.074588\n[2022-04-10 06:18:22] - valid_dtw 0.291715, test_dtw 0.263366\n[2022-04-10 06:18:22] - Epoch: 35\n[2022-04-10 06:18:22] - training...\n[2022-04-10 06:34:34] - [-2.94545891 -0.36868794  0.15652352] 0.038825823226592435\n[2022-04-10 06:34:34] - evaluating...\n[2022-04-10 06:35:03] - valid_l1 0.069823, test_l1 0.065332\n[2022-04-10 06:35:03] - valid_dtw 0.250024, test_dtw 0.225211\n[2022-04-10 06:35:03] - Epoch: 36\n[2022-04-10 06:35:03] - training...\n[2022-04-10 06:37:34] - [-2.94545891 -0.36868794  0.15652352] 0.038825823226592435\n[2022-04-10 06:37:34] - evaluating...\n[2022-04-10 06:38:03] - valid_l1 0.069823, test_l1 0.065332\n[2022-04-10 06:38:03] - valid_dtw 0.250024, test_dtw 0.225211\n[2022-04-10 06:38:03] - Epoch: 36\n[2022-04-10 06:38:03] - training...\n[2022-04-10 06:55:17] - [-3.09390249 -0.36886446  0.20418597] 0.03830452674373332\n[2022-04-10 06:55:17] - evaluating...\n[2022-04-10 06:55:46] - valid_l1 0.063890, test_l1 0.058572\n[2022-04-10 06:55:46] - valid_dtw 0.230548, test_dtw 0.206288\n[2022-04-10 06:55:46] - Epoch: 37\n[2022-04-10 06:55:46] - training...\n[2022-04-10 06:57:38] - [-3.09390249 -0.36886446  0.20418597] 0.03830452674373332\n[2022-04-10 06:57:38] - evaluating...\n[2022-04-10 06:58:08] - valid_l1 0.063890, test_l1 0.058572\n[2022-04-10 06:58:08] - valid_dtw 0.230548, test_dtw 0.206288\n[2022-04-10 06:58:08] - Epoch: 37\n[2022-04-10 06:58:08] - training...\n[2022-04-10 07:18:41] - [-3.15468238 -0.36638743  0.00559735] 0.04057808149027249\n[2022-04-10 07:18:42] - evaluating...\n[2022-04-10 07:19:12] - valid_l1 0.071452, test_l1 0.065056\n[2022-04-10 07:19:12] - valid_dtw 0.257011, test_dtw 0.230193\n[2022-04-10 07:19:12] - Epoch: 38\n[2022-04-10 07:19:12] - training...\n[2022-04-10 07:20:05] - [-3.15468238 -0.36638743  0.00559735] 0.04057808149027249\n[2022-04-10 07:20:05] - evaluating...\n[2022-04-10 07:20:35] - valid_l1 0.071452, test_l1 0.065056\n[2022-04-10 07:20:35] - valid_dtw 0.257011, test_dtw 0.230193\n[2022-04-10 07:20:35] - Epoch: 38\n[2022-04-10 07:20:35] - training...\n[2022-04-10 07:41:01] - [-3.09430043 -0.36910856  0.08937136] 0.03843458161617701\n[2022-04-10 07:41:01] - evaluating...\n[2022-04-10 07:41:31] - valid_l1 0.080359, test_l1 0.075572\n[2022-04-10 07:41:31] - valid_dtw 0.268179, test_dtw 0.246880\n[2022-04-10 07:41:31] - Epoch: 39\n[2022-04-10 07:41:31] - training...\n[2022-04-10 07:42:38] - [-3.09430043 -0.36910856  0.08937136] 0.03843458161617701\n[2022-04-10 07:42:39] - evaluating...\n[2022-04-10 07:43:08] - valid_l1 0.080359, test_l1 0.075572\n[2022-04-10 07:43:08] - valid_dtw 0.268179, test_dtw 0.246880\n[2022-04-10 07:43:08] - Epoch: 39\n[2022-04-10 07:43:08] - training...\n[2022-04-10 08:04:44] - [-3.12601546 -0.36992997  0.23316874] 0.037990631914920935\n[2022-04-10 08:04:44] - evaluating...\n[2022-04-10 08:05:14] - valid_l1 0.053448, test_l1 0.045745\n[2022-04-10 08:05:14] - valid_dtw 0.190016, test_dtw 0.159398\n[2022-04-10 08:05:14] - Epoch: 40\n[2022-04-10 08:05:14] - training...\n[2022-04-10 08:05:48] - [-3.12601546 -0.36992997  0.23316874] 0.037990631914920935\n[2022-04-10 08:05:48] - evaluating...\n[2022-04-10 08:06:18] - valid_l1 0.053448, test_l1 0.045745\n[2022-04-10 08:06:18] - valid_dtw 0.190016, test_dtw 0.159398\n[2022-04-10 08:06:18] - Epoch: 40\n[2022-04-10 08:06:18] - training...\n[2022-04-10 08:54:38] - [-3.18247936 -0.36967599  0.02252773] 0.037611194341239794\n[2022-04-10 08:54:38] - evaluating...\n[2022-04-10 08:55:08] - valid_l1 0.081669, test_l1 0.079819\n[2022-04-10 08:55:08] - valid_dtw 0.288255, test_dtw 0.276648\n[2022-04-10 08:55:08] - Epoch: 41\n[2022-04-10 08:55:08] - training...\n[2022-04-10 08:56:13] - [-3.18247936 -0.36967599  0.02252773] 0.037611194341239794\n[2022-04-10 08:56:14] - evaluating...\n[2022-04-10 08:56:43] - valid_l1 0.081669, test_l1 0.079819\n[2022-04-10 08:56:43] - valid_dtw 0.288255, test_dtw 0.276648\n[2022-04-10 08:56:43] - Epoch: 41\n[2022-04-10 08:56:43] - training...\n[2022-04-10 09:19:54] - [-3.20421356 -0.37095146  0.10170524] 0.037308441222186\n[2022-04-10 09:19:54] - evaluating...\n[2022-04-10 09:20:25] - valid_l1 0.085030, test_l1 0.083765\n[2022-04-10 09:20:25] - valid_dtw 0.310482, test_dtw 0.293139\n[2022-04-10 09:20:25] - Epoch: 42\n[2022-04-10 09:20:25] - training...\n[2022-04-10 09:21:58] - [-3.20421356 -0.37095146  0.10170524] 0.037308441222186\n[2022-04-10 09:21:58] - evaluating...\n[2022-04-10 09:22:32] - valid_l1 0.085030, test_l1 0.083765\n[2022-04-10 09:22:32] - valid_dtw 0.310482, test_dtw 0.293139\n[2022-04-10 09:22:32] - Epoch: 42\n[2022-04-10 09:22:32] - training...\n[2022-04-10 09:47:31] - [-3.18926001 -0.36892751  0.1777234 ] 0.039101468501710875\n[2022-04-10 09:47:31] - evaluating...\n[2022-04-10 09:48:04] - valid_l1 0.068805, test_l1 0.059569\n[2022-04-10 09:48:04] - valid_dtw 0.245799, test_dtw 0.208302\n[2022-04-10 09:48:04] - Epoch: 43\n[2022-04-10 09:48:04] - training...\n[2022-04-10 09:50:04] - [-3.18926001 -0.36892751  0.1777234 ] 0.039101468501710875\n[2022-04-10 09:50:04] - evaluating...\n[2022-04-10 09:50:37] - valid_l1 0.068805, test_l1 0.059569\n[2022-04-10 09:50:37] - valid_dtw 0.245799, test_dtw 0.208302\n[2022-04-10 09:50:37] - Epoch: 43\n[2022-04-10 09:50:37] - training...\n[2022-04-10 10:16:52] - [-3.23507281 -0.37153222  0.03685902] 0.03671416497141752\n[2022-04-10 10:16:52] - evaluating...\n[2022-04-10 10:17:28] - valid_l1 0.098567, test_l1 0.098889\n[2022-04-10 10:17:28] - valid_dtw 0.344174, test_dtw 0.337507\n[2022-04-10 10:17:28] - Epoch: 44\n[2022-04-10 10:17:28] - training...\n[2022-04-10 10:19:18] - [-3.23507281 -0.37153222  0.03685902] 0.03671416497141752\n[2022-04-10 10:19:18] - evaluating...\n[2022-04-10 10:19:59] - valid_l1 0.098567, test_l1 0.098889\n[2022-04-10 10:19:59] - valid_dtw 0.344174, test_dtw 0.337507\n[2022-04-10 10:19:59] - Epoch: 44\n[2022-04-10 10:19:59] - training...\n[2022-04-10 10:43:29] - [-3.10581451 -0.36570737  0.16316054] 0.039178213704416744\n[2022-04-10 10:43:29] - evaluating...\n[2022-04-10 10:44:00] - valid_l1 0.071154, test_l1 0.066034\n[2022-04-10 10:44:00] - valid_dtw 0.258570, test_dtw 0.238214\n[2022-04-10 10:44:00] - Epoch: 45\n[2022-04-10 10:44:00] - training...\n[2022-04-10 10:45:38] - [-3.10581451 -0.36570737  0.16316054] 0.039178213704416744\n[2022-04-10 10:45:38] - evaluating...\n[2022-04-10 10:46:08] - valid_l1 0.071154, test_l1 0.066034\n[2022-04-10 10:46:08] - valid_dtw 0.258570, test_dtw 0.238214\n[2022-04-10 10:46:08] - Epoch: 45\n[2022-04-10 10:46:08] - training...\n[2022-04-10 11:10:20] - [-3.2095169  -0.37165083  0.05224837] 0.03576132001672755\n[2022-04-10 11:10:20] - evaluating...\n[2022-04-10 11:10:52] - valid_l1 0.075021, test_l1 0.080854\n[2022-04-10 11:10:52] - valid_dtw 0.241976, test_dtw 0.259068\n[2022-04-10 11:10:52] - Epoch: 46\n[2022-04-10 11:10:52] - training...\n[2022-04-10 11:11:56] - [-3.2095169  -0.37165083  0.05224837] 0.03576132001672755\n[2022-04-10 11:11:56] - evaluating...\n[2022-04-10 11:12:25] - valid_l1 0.075021, test_l1 0.080854\n[2022-04-10 11:12:25] - valid_dtw 0.241976, test_dtw 0.259068\n[2022-04-10 11:12:25] - Epoch: 46\n[2022-04-10 11:12:25] - training...\n[2022-04-10 11:35:31] - [-3.20721191 -0.36665282  0.0453548 ] 0.03930480788612168\n[2022-04-10 11:35:31] - evaluating...\n[2022-04-10 11:36:01] - valid_l1 0.060787, test_l1 0.056328\n[2022-04-10 11:36:01] - valid_dtw 0.207561, test_dtw 0.192993\n[2022-04-10 11:36:01] - Epoch: 47\n[2022-04-10 11:36:01] - training...\n[2022-04-10 11:37:33] - [-3.20721191 -0.36665282  0.0453548 ] 0.03930480788612168\n[2022-04-10 11:37:33] - evaluating...\n[2022-04-10 11:38:02] - valid_l1 0.060787, test_l1 0.056328\n[2022-04-10 11:38:02] - valid_dtw 0.207561, test_dtw 0.192993\n[2022-04-10 11:38:02] - Epoch: 47\n[2022-04-10 11:38:02] - training...\n[2022-04-10 11:54:51] - [-3.22423683 -0.37089127  0.04962185] 0.036735243362066974\n[2022-04-10 11:54:52] - evaluating...\n[2022-04-10 11:55:20] - valid_l1 0.071398, test_l1 0.065858\n[2022-04-10 11:55:20] - valid_dtw 0.260533, test_dtw 0.234321\n[2022-04-10 11:55:20] - Epoch: 48\n[2022-04-10 11:55:20] - training...\n[2022-04-10 11:56:31] - [-3.22423683 -0.37089127  0.04962185] 0.036735243362066974\n[2022-04-10 11:56:31] - evaluating...\n[2022-04-10 11:56:58] - valid_l1 0.071398, test_l1 0.065858\n[2022-04-10 11:56:58] - valid_dtw 0.260533, test_dtw 0.234321\n[2022-04-10 11:56:58] - Epoch: 48\n[2022-04-10 11:56:58] - training...\n[2022-04-10 12:11:27] - [-3.22834245 -0.36914229  0.03352208] 0.03743032888167989\n[2022-04-10 12:11:28] - evaluating...\n[2022-04-10 12:11:56] - valid_l1 0.067616, test_l1 0.067570\n[2022-04-10 12:11:56] - valid_dtw 0.234677, test_dtw 0.230106\n[2022-04-10 12:11:56] - Epoch: 49\n[2022-04-10 12:11:56] - training...\n[2022-04-10 12:12:05] - [-3.22834245 -0.36914229  0.03352208] 0.03743032888167989\n[2022-04-10 12:12:05] - evaluating...\n[2022-04-10 12:12:32] - valid_l1 0.067616, test_l1 0.067570\n[2022-04-10 12:12:32] - valid_dtw 0.234677, test_dtw 0.230106\n[2022-04-10 12:12:32] - Epoch: 49\n[2022-04-10 12:12:32] - training...\n[2022-04-10 12:27:40] - [-3.23853339e+00 -3.69979283e-01  2.68326348e-03] 0.03718649492589237\n[2022-04-10 12:27:40] - evaluating...\n[2022-04-10 12:27:49] - [-3.23853339e+00 -3.69979283e-01  2.68326348e-03] 0.03718649492589237\n[2022-04-10 12:27:49] - evaluating...\n[2022-04-10 12:28:10] - valid_l1 0.074618, test_l1 0.073273\n[2022-04-10 12:28:10] - valid_dtw 0.246618, test_dtw 0.241157\n[2022-04-10 12:28:10] - Epoch: 50\n[2022-04-10 12:28:10] - training...\n[2022-04-10 12:28:18] - valid_l1 0.074618, test_l1 0.073273\n[2022-04-10 12:28:18] - valid_dtw 0.246618, test_dtw 0.241157\n[2022-04-10 12:28:18] - Epoch: 50\n[2022-04-10 12:28:18] - training...\n[2022-04-10 12:41:55] - [-3.26878133e+00 -3.69457299e-01  2.20489711e-03] 0.03697198797101618\n[2022-04-10 12:41:55] - evaluating...\n[2022-04-10 12:41:56] - [-3.26878133e+00 -3.69457299e-01  2.20489711e-03] 0.03697198797101618\n[2022-04-10 12:41:56] - evaluating...\n[2022-04-10 12:42:21] - valid_l1 0.081950, test_l1 0.076480\n[2022-04-10 12:42:21] - valid_dtw 0.288474, test_dtw 0.263936\n[2022-04-10 12:42:21] - Epoch: 51\n[2022-04-10 12:42:21] - training...\n[2022-04-10 12:42:23] - valid_l1 0.081950, test_l1 0.076480\n[2022-04-10 12:42:23] - valid_dtw 0.288474, test_dtw 0.263936\n[2022-04-10 12:42:23] - Epoch: 51\n[2022-04-10 12:42:23] - training...\n[2022-04-10 12:56:12] - [-3.17271335 -0.37069365  0.06543297] 0.03667176332673111\n[2022-04-10 12:56:12] - evaluating...\n[2022-04-10 12:56:14] - [-3.17271335 -0.37069365  0.06543297] 0.03667176332673111\n[2022-04-10 12:56:14] - evaluating...\n[2022-04-10 12:56:39] - valid_l1 0.095275, test_l1 0.083673\n[2022-04-10 12:56:39] - valid_dtw 0.329256, test_dtw 0.284876\n[2022-04-10 12:56:39] - Epoch: 52\n[2022-04-10 12:56:39] - training...\n[2022-04-10 12:56:41] - valid_l1 0.095275, test_l1 0.083673\n[2022-04-10 12:56:41] - valid_dtw 0.329256, test_dtw 0.284876\n[2022-04-10 12:56:41] - Epoch: 52\n[2022-04-10 12:56:41] - training...\n[2022-04-10 13:09:59] - [-3.21851486 -0.36727128  0.00483034] 0.037899118466063954\n[2022-04-10 13:09:59] - evaluating...\n[2022-04-10 13:10:01] - [-3.21851486 -0.36727128  0.00483034] 0.037899118466063954\n[2022-04-10 13:10:01] - evaluating...\n[2022-04-10 13:10:26] - valid_l1 0.103097, test_l1 0.102059\n[2022-04-10 13:10:26] - valid_dtw 0.347973, test_dtw 0.336738\n[2022-04-10 13:10:26] - Epoch: 53\n[2022-04-10 13:10:26] - training...\n[2022-04-10 13:10:28] - valid_l1 0.103097, test_l1 0.102059\n[2022-04-10 13:10:28] - valid_dtw 0.347973, test_dtw 0.336738\n[2022-04-10 13:10:28] - Epoch: 53\n[2022-04-10 13:10:28] - training...\n[2022-04-10 13:24:44] - [-3.09841744 -0.36918465  0.22314879] 0.0364969228092317\n[2022-04-10 13:24:44] - evaluating...\n[2022-04-10 13:24:45] - [-3.09841744 -0.36918465  0.22314879] 0.0364969228092317\n[2022-04-10 13:24:45] - evaluating...\n[2022-04-10 13:25:10] - valid_l1 0.105423, test_l1 0.102988\n[2022-04-10 13:25:10] - valid_dtw 0.356024, test_dtw 0.337855\n[2022-04-10 13:25:10] - Epoch: 54\n[2022-04-10 13:25:10] - training...\n[2022-04-10 13:25:11] - valid_l1 0.105423, test_l1 0.102988\n[2022-04-10 13:25:11] - valid_dtw 0.356024, test_dtw 0.337855\n[2022-04-10 13:25:11] - Epoch: 54\n[2022-04-10 13:25:11] - training...\n[2022-04-10 13:38:46] - [-3.14475117 -0.36827355  0.11465035] 0.03775247726392782\n[2022-04-10 13:38:46] - evaluating...\n[2022-04-10 13:38:46] - [-3.14475117 -0.36827355  0.11465035] 0.03775247726392782\n[2022-04-10 13:38:46] - evaluating...\n[2022-04-10 13:39:14] - valid_l1 0.091338, test_l1 0.091427\n[2022-04-10 13:39:14] - valid_dtw 0.315348, test_dtw 0.310174\n[2022-04-10 13:39:14] - Epoch: 55\n[2022-04-10 13:39:14] - training...\n[2022-04-10 13:39:14] - valid_l1 0.091338, test_l1 0.091427\n[2022-04-10 13:39:14] - valid_dtw 0.315348, test_dtw 0.310174\n[2022-04-10 13:39:14] - Epoch: 55\n[2022-04-10 13:39:14] - training...\n[2022-04-10 13:54:52] - [-3.17819526 -0.36923249  0.02817106] 0.036788558292442854\n[2022-04-10 13:54:52] - evaluating...\n[2022-04-10 13:54:53] - [-3.17819526 -0.36923249  0.02817106] 0.036788558292442854\n[2022-04-10 13:54:53] - evaluating...\n[2022-04-10 13:55:19] - valid_l1 0.096627, test_l1 0.089415\n[2022-04-10 13:55:19] - valid_dtw 0.330164, test_dtw 0.298417\n[2022-04-10 13:55:19] - Epoch: 56\n[2022-04-10 13:55:19] - training...\n[2022-04-10 13:55:20] - valid_l1 0.096627, test_l1 0.089415\n[2022-04-10 13:55:20] - valid_dtw 0.330164, test_dtw 0.298417\n[2022-04-10 13:55:20] - Epoch: 56\n[2022-04-10 13:55:20] - training...\n[2022-04-10 14:10:08] - [-3.13251378 -0.36881267  0.14873101] 0.0379240399010221\n[2022-04-10 14:10:09] - evaluating...\n[2022-04-10 14:10:09] - [-3.13251378 -0.36881267  0.14873101] 0.0379240399010221\n[2022-04-10 14:10:09] - evaluating...\n[2022-04-10 14:10:35] - valid_l1 0.084801, test_l1 0.075203\n[2022-04-10 14:10:35] - valid_dtw 0.305984, test_dtw 0.262826\n[2022-04-10 14:10:35] - Epoch: 57\n[2022-04-10 14:10:35] - training...\n[2022-04-10 14:10:35] - valid_l1 0.084801, test_l1 0.075203\n[2022-04-10 14:10:35] - valid_dtw 0.305984, test_dtw 0.262826\n[2022-04-10 14:10:35] - Epoch: 57\n[2022-04-10 14:10:35] - training...\n[2022-04-10 14:27:51] - [-3.21321157 -0.36818826  0.00900507] 0.03951864724284878\n[2022-04-10 14:27:51] - evaluating...\n[2022-04-10 14:27:53] - [-3.21321157 -0.36818826  0.00900507] 0.03951864724284878\n[2022-04-10 14:27:53] - evaluating...\n[2022-04-10 14:28:18] - valid_l1 0.123539, test_l1 0.121374\n[2022-04-10 14:28:18] - valid_dtw 0.424756, test_dtw 0.413174\n[2022-04-10 14:28:18] - Epoch: 58\n[2022-04-10 14:28:18] - training...\n[2022-04-10 14:28:19] - valid_l1 0.123539, test_l1 0.121374\n[2022-04-10 14:28:19] - valid_dtw 0.424756, test_dtw 0.413174\n[2022-04-10 14:28:19] - Epoch: 58\n[2022-04-10 14:28:19] - training...\n[2022-04-10 14:43:30] - [-2.93831308 -0.36919869  0.23443265] 0.03835610302690512\n[2022-04-10 14:43:30] - evaluating...\n[2022-04-10 14:43:30] - [-2.93831308 -0.36919869  0.23443265] 0.03835610302690512\n[2022-04-10 14:43:30] - evaluating...\n[2022-04-10 14:43:57] - valid_l1 0.093274, test_l1 0.093633\n[2022-04-10 14:43:57] - valid_dtw 0.341356, test_dtw 0.328002\n[2022-04-10 14:43:57] - Epoch: 59\n[2022-04-10 14:43:57] - training...\n[2022-04-10 14:43:57] - valid_l1 0.093274, test_l1 0.093633\n[2022-04-10 14:43:57] - valid_dtw 0.341356, test_dtw 0.328002\n[2022-04-10 14:43:57] - Epoch: 59\n[2022-04-10 14:43:57] - training...\n[2022-04-10 14:59:18] - [-3.16776079 -0.36725763  0.11736051] 0.04051093605584374\n[2022-04-10 14:59:18] - evaluating...\n[2022-04-10 14:59:20] - [-3.16776079 -0.36725763  0.11736051] 0.04051093605584374\n[2022-04-10 14:59:20] - evaluating...\n[2022-04-10 14:59:45] - valid_l1 0.102499, test_l1 0.102463\n[2022-04-10 14:59:45] - valid_dtw 0.346824, test_dtw 0.336710\n[2022-04-10 14:59:45] - Epoch: 60\n[2022-04-10 14:59:45] - training...\n[2022-04-10 14:59:46] - valid_l1 0.102499, test_l1 0.102463\n[2022-04-10 14:59:46] - valid_dtw 0.346824, test_dtw 0.336710\n[2022-04-10 14:59:46] - Epoch: 60\n[2022-04-10 14:59:46] - training...\n[2022-04-10 15:19:27] - [-3.15009984 -0.36888163  0.06144531] 0.039551857194468534\n[2022-04-10 15:19:27] - evaluating...\n[2022-04-10 15:19:28] - [-3.15009984 -0.36888163  0.06144531] 0.039551857194468534\n[2022-04-10 15:19:28] - evaluating...\n[2022-04-10 15:19:55] - valid_l1 0.078338, test_l1 0.075861\n[2022-04-10 15:19:55] - valid_dtw 0.265417, test_dtw 0.250987\n[2022-04-10 15:19:55] - Epoch: 61\n[2022-04-10 15:19:55] - training...\n[2022-04-10 15:19:56] - valid_l1 0.078338, test_l1 0.075861\n[2022-04-10 15:19:56] - valid_dtw 0.265417, test_dtw 0.250987\n[2022-04-10 15:19:56] - Epoch: 61\n[2022-04-10 15:19:56] - training...\n[2022-04-10 15:39:14] - [-3.1366232  -0.36985086  0.04355844] 0.03780673083822562\n[2022-04-10 15:39:14] - evaluating...\n[2022-04-10 15:39:18] - [-3.1366232  -0.36985086  0.04355844] 0.03780673083822562\n[2022-04-10 15:39:18] - evaluating...\n[2022-04-10 15:39:41] - valid_l1 0.107844, test_l1 0.109740\n[2022-04-10 15:39:41] - valid_dtw 0.362848, test_dtw 0.358292\n[2022-04-10 15:39:41] - Epoch: 62\n[2022-04-10 15:39:41] - training...\n[2022-04-10 15:39:44] - valid_l1 0.107844, test_l1 0.109740\n[2022-04-10 15:39:44] - valid_dtw 0.362848, test_dtw 0.358292\n[2022-04-10 15:39:44] - Epoch: 62\n[2022-04-10 15:39:44] - training...\n[2022-04-10 15:58:30] - [-3.18135023 -0.36927316  0.03147213] 0.03835122533238087\n[2022-04-10 15:58:30] - evaluating...\n[2022-04-10 15:58:44] - [-3.18135023 -0.36927316  0.03147213] 0.03835122533238087\n[2022-04-10 15:58:44] - evaluating...\n[2022-04-10 15:58:59] - valid_l1 0.126829, test_l1 0.113272\n[2022-04-10 15:58:59] - valid_dtw 0.429222, test_dtw 0.384041\n[2022-04-10 15:58:59] - Epoch: 63\n[2022-04-10 15:58:59] - training...\n[2022-04-10 15:59:12] - valid_l1 0.126829, test_l1 0.113272\n[2022-04-10 15:59:12] - valid_dtw 0.429222, test_dtw 0.384041\n[2022-04-10 15:59:12] - Epoch: 63\n[2022-04-10 15:59:12] - training...\n[2022-04-10 16:15:48] - [-3.17241512 -0.36969843  0.05015738] 0.037538913882100115\n[2022-04-10 16:15:48] - evaluating...\n[2022-04-10 16:16:02] - [-3.17241512 -0.36969843  0.05015738] 0.037538913882100115\n[2022-04-10 16:16:02] - evaluating...\n[2022-04-10 16:16:16] - valid_l1 0.118997, test_l1 0.121828\n[2022-04-10 16:16:16] - valid_dtw 0.409638, test_dtw 0.408785\n[2022-04-10 16:16:16] - Epoch: 64\n[2022-04-10 16:16:16] - training...\n[2022-04-10 16:16:30] - valid_l1 0.118997, test_l1 0.121828\n[2022-04-10 16:16:30] - valid_dtw 0.409638, test_dtw 0.408785\n[2022-04-10 16:16:30] - Epoch: 64\n[2022-04-10 16:16:30] - training...\n[2022-04-10 16:32:11] - [-3.2203278  -0.37104778  0.00557072] 0.03664540203335958\n[2022-04-10 16:32:11] - evaluating...\n[2022-04-10 16:32:11] - [-3.2203278  -0.37104778  0.00557072] 0.03664540203335958\n[2022-04-10 16:32:11] - evaluating...\n[2022-04-10 16:32:37] - valid_l1 0.091970, test_l1 0.093508\n[2022-04-10 16:32:37] - valid_dtw 0.337976, test_dtw 0.333296\n[2022-04-10 16:32:37] - Epoch: 65\n[2022-04-10 16:32:37] - training...\n[2022-04-10 16:32:38] - valid_l1 0.091970, test_l1 0.093508\n[2022-04-10 16:32:38] - valid_dtw 0.337976, test_dtw 0.333296\n[2022-04-10 16:32:38] - Epoch: 65\n[2022-04-10 16:32:38] - training...\n[2022-04-10 16:49:57] - [-3.24015018 -0.36965744  0.00613411] 0.03751058920200909\n[2022-04-10 16:49:57] - evaluating...\n[2022-04-10 16:49:59] - [-3.24015018 -0.36965744  0.00613411] 0.03751058920200909\n[2022-04-10 16:49:59] - evaluating...\n[2022-04-10 16:50:23] - valid_l1 0.075807, test_l1 0.074970\n[2022-04-10 16:50:23] - valid_dtw 0.273739, test_dtw 0.261950\n[2022-04-10 16:50:23] - Epoch: 66\n[2022-04-10 16:50:23] - training...\n[2022-04-10 16:50:26] - valid_l1 0.075807, test_l1 0.074970\n[2022-04-10 16:50:26] - valid_dtw 0.273739, test_dtw 0.261950\n[2022-04-10 16:50:26] - Epoch: 66\n[2022-04-10 16:50:26] - training...\n[2022-04-10 17:06:10] - [-3.12658088 -0.37088659  0.12976201] 0.037000705954389784\n[2022-04-10 17:06:10] - evaluating...\n[2022-04-10 17:06:13] - [-3.12658088 -0.37088659  0.12976201] 0.037000705954389784\n[2022-04-10 17:06:13] - evaluating...\n[2022-04-10 17:06:37] - valid_l1 0.094113, test_l1 0.095619\n[2022-04-10 17:06:37] - valid_dtw 0.329106, test_dtw 0.327058\n[2022-04-10 17:06:37] - Epoch: 67\n[2022-04-10 17:06:37] - training...\n[2022-04-10 17:06:39] - valid_l1 0.094113, test_l1 0.095619\n[2022-04-10 17:06:39] - valid_dtw 0.329106, test_dtw 0.327058\n[2022-04-10 17:06:39] - Epoch: 67\n[2022-04-10 17:06:39] - training...\n[2022-04-10 17:23:06] - [-3.03854653 -0.36783243  0.28304449] 0.03853402152899119\n[2022-04-10 17:23:07] - evaluating...\n[2022-04-10 17:23:10] - [-3.03854653 -0.36783243  0.28304449] 0.03853402152899119\n[2022-04-10 17:23:10] - evaluating...\n[2022-04-10 17:23:38] - valid_l1 0.101142, test_l1 0.099137\n[2022-04-10 17:23:38] - valid_dtw 0.338654, test_dtw 0.326966\n[2022-04-10 17:23:38] - Epoch: 68\n[2022-04-10 17:23:38] - training...\n[2022-04-10 17:23:42] - valid_l1 0.101142, test_l1 0.099137\n[2022-04-10 17:23:42] - valid_dtw 0.338654, test_dtw 0.326966\n[2022-04-10 17:23:42] - Epoch: 68\n[2022-04-10 17:23:42] - training...\n[2022-04-10 17:42:35] - [-3.07401436 -0.36779767  0.17269334] 0.03796901469375955\n[2022-04-10 17:42:35] - evaluating...\n[2022-04-10 17:42:38] - [-3.07401436 -0.36779767  0.17269334] 0.03796901469375955\n[2022-04-10 17:42:38] - evaluating...\n[2022-04-10 17:43:02] - valid_l1 0.078779, test_l1 0.077098\n[2022-04-10 17:43:02] - valid_dtw 0.266504, test_dtw 0.250735\n[2022-04-10 17:43:02] - Epoch: 69\n[2022-04-10 17:43:02] - training...\n[2022-04-10 17:43:04] - valid_l1 0.078779, test_l1 0.077098\n[2022-04-10 17:43:04] - valid_dtw 0.266504, test_dtw 0.250735\n[2022-04-10 17:43:04] - Epoch: 69\n[2022-04-10 17:43:04] - training...\n[2022-04-10 18:00:10] - [-2.85840192 -0.36923926  0.32958883] 0.03813521569414938\n[2022-04-10 18:00:10] - evaluating...\n[2022-04-10 18:00:11] - [-2.85840192 -0.36923926  0.32958883] 0.03813521569414938\n[2022-04-10 18:00:11] - evaluating...\n[2022-04-10 18:00:37] - valid_l1 0.083697, test_l1 0.076787\n[2022-04-10 18:00:37] - valid_dtw 0.311890, test_dtw 0.276236\n[2022-04-10 18:00:37] - Epoch: 70\n[2022-04-10 18:00:37] - training...\n[2022-04-10 18:00:39] - valid_l1 0.083697, test_l1 0.076787\n[2022-04-10 18:00:39] - valid_dtw 0.311890, test_dtw 0.276236\n[2022-04-10 18:00:39] - Epoch: 70\n[2022-04-10 18:00:39] - training...\n[2022-04-10 18:16:24] - [-2.91490001 -0.3706669   0.29532944] 0.03759554259585804\n[2022-04-10 18:16:24] - evaluating...\n[2022-04-10 18:16:25] - [-2.91490001 -0.3706669   0.29532944] 0.03759554259585804\n[2022-04-10 18:16:25] - evaluating...\n[2022-04-10 18:16:50] - valid_l1 0.077470, test_l1 0.073061\n[2022-04-10 18:16:50] - valid_dtw 0.276859, test_dtw 0.257958\n[2022-04-10 18:16:50] - Epoch: 71\n[2022-04-10 18:16:50] - training...\n[2022-04-10 18:16:51] - valid_l1 0.077470, test_l1 0.073061\n[2022-04-10 18:16:51] - valid_dtw 0.276859, test_dtw 0.257958\n[2022-04-10 18:16:51] - Epoch: 71\n[2022-04-10 18:16:51] - training...\n[2022-04-10 18:33:55] - [-3.12596055 -0.36940532  0.14733422] 0.03740444715622234\n[2022-04-10 18:33:55] - evaluating...\n[2022-04-10 18:33:58] - [-3.12596055 -0.36940532  0.14733422] 0.03740444715622234\n[2022-04-10 18:33:58] - evaluating...\n[2022-04-10 18:34:22] - valid_l1 0.067837, test_l1 0.068366\n[2022-04-10 18:34:22] - valid_dtw 0.246408, test_dtw 0.240651\n[2022-04-10 18:34:22] - Epoch: 72\n[2022-04-10 18:34:22] - training...\n[2022-04-10 18:34:24] - valid_l1 0.067837, test_l1 0.068366\n[2022-04-10 18:34:24] - valid_dtw 0.246408, test_dtw 0.240651\n[2022-04-10 18:34:24] - Epoch: 72\n[2022-04-10 18:34:24] - training...\n[2022-04-10 18:46:28] - [-3.11950051 -0.37164278  0.17789751] 0.03530127436504173\n[2022-04-10 18:46:28] - evaluating...\n[2022-04-10 18:46:28] - [-3.11950051 -0.37164278  0.17789751] 0.03530127436504173\n[2022-04-10 18:46:29] - evaluating...\n[2022-04-10 18:46:53] - valid_l1 0.104336, test_l1 0.103361\n[2022-04-10 18:46:53] - valid_dtw 0.369048, test_dtw 0.357023\n[2022-04-10 18:46:53] - Epoch: 73\n[2022-04-10 18:46:53] - training...\n[2022-04-10 18:46:54] - valid_l1 0.104336, test_l1 0.103361\n[2022-04-10 18:46:54] - valid_dtw 0.369048, test_dtw 0.357023\n[2022-04-10 18:46:54] - Epoch: 73\n[2022-04-10 18:46:54] - training...\n[2022-04-10 18:58:00] - [-3.09686043 -0.37170433  0.1161031 ] 0.036583063132263054\n[2022-04-10 18:58:00] - evaluating...\n[2022-04-10 18:58:01] - [-3.09686043 -0.37170433  0.1161031 ] 0.036583063132263054\n[2022-04-10 18:58:01] - evaluating...\n[2022-04-10 18:58:25] - valid_l1 0.099338, test_l1 0.098453\n[2022-04-10 18:58:25] - valid_dtw 0.345721, test_dtw 0.334925\n[2022-04-10 18:58:25] - Epoch: 74\n[2022-04-10 18:58:25] - training...\n[2022-04-10 18:58:26] - valid_l1 0.099338, test_l1 0.098453\n[2022-04-10 18:58:26] - valid_dtw 0.345721, test_dtw 0.334925\n[2022-04-10 18:58:26] - Epoch: 74\n[2022-04-10 18:58:26] - training...\n[2022-04-10 19:09:22] - [-3.1123186  -0.37035524  0.27518217] 0.03752631482248213\n[2022-04-10 19:09:22] - evaluating...\n[2022-04-10 19:09:23] - [-3.1123186  -0.37035524  0.27518217] 0.03752631482248213\n[2022-04-10 19:09:23] - evaluating...\n[2022-04-10 19:09:47] - valid_l1 0.086596, test_l1 0.093447\n[2022-04-10 19:09:47] - valid_dtw 0.304635, test_dtw 0.320146\n[2022-04-10 19:09:47] - Epoch: 75\n[2022-04-10 19:09:47] - training...\n[2022-04-10 19:09:48] - valid_l1 0.086596, test_l1 0.093447\n[2022-04-10 19:09:48] - valid_dtw 0.304635, test_dtw 0.320146\n[2022-04-10 19:09:48] - Epoch: 75\n[2022-04-10 19:09:48] - training...\n[2022-04-10 19:20:39] - [-3.15520457 -0.37450235  0.13236024] 0.03500254326647493\n[2022-04-10 19:20:39] - evaluating...\n[2022-04-10 19:20:39] - [-3.15520457 -0.37450235  0.13236024] 0.03500254326647493\n[2022-04-10 19:20:39] - evaluating...\n[2022-04-10 19:21:04] - valid_l1 0.103602, test_l1 0.101666\n[2022-04-10 19:21:04] - valid_dtw 0.365325, test_dtw 0.349357\n[2022-04-10 19:21:04] - Epoch: 76\n[2022-04-10 19:21:04] - training...\n[2022-04-10 19:21:04] - valid_l1 0.103602, test_l1 0.101666\n[2022-04-10 19:21:04] - valid_dtw 0.365325, test_dtw 0.349357\n[2022-04-10 19:21:04] - Epoch: 76\n[2022-04-10 19:21:04] - training...\n[2022-04-10 19:31:59] - [-3.01191306 -0.37275479  0.30270852] 0.036822413615489075\n[2022-04-10 19:31:59] - evaluating...\n[2022-04-10 19:32:00] - [-3.01191306 -0.37275479  0.30270852] 0.036822413615489075\n[2022-04-10 19:32:00] - evaluating...\n[2022-04-10 19:32:24] - valid_l1 0.107196, test_l1 0.108655\n[2022-04-10 19:32:24] - valid_dtw 0.392830, test_dtw 0.385441\n[2022-04-10 19:32:24] - Epoch: 77\n[2022-04-10 19:32:24] - training...\n[2022-04-10 19:32:24] - valid_l1 0.107196, test_l1 0.108655\n[2022-04-10 19:32:24] - valid_dtw 0.392830, test_dtw 0.385441\n[2022-04-10 19:32:24] - Epoch: 77\n[2022-04-10 19:32:24] - training...\n[2022-04-10 19:43:20] - [-3.18590519 -0.37315198  0.15781191] 0.0357173206397019\n[2022-04-10 19:43:20] - evaluating...\n[2022-04-10 19:43:20] - [-3.18590519 -0.37315198  0.15781191] 0.0357173206397019\n[2022-04-10 19:43:20] - evaluating...\n[2022-04-10 19:43:45] - valid_l1 0.122320, test_l1 0.120816\n[2022-04-10 19:43:45] - valid_dtw 0.407437, test_dtw 0.402000\n[2022-04-10 19:43:45] - Epoch: 78\n[2022-04-10 19:43:45] - training...\n[2022-04-10 19:43:45] - valid_l1 0.122320, test_l1 0.120816\n[2022-04-10 19:43:45] - valid_dtw 0.407437, test_dtw 0.402000\n[2022-04-10 19:43:45] - Epoch: 78\n[2022-04-10 19:43:45] - training...\n[2022-04-10 19:55:06] - [-3.15411499 -0.37089692  0.20582139] 0.03753258693165414\n[2022-04-10 19:55:06] - evaluating...\n[2022-04-10 19:55:08] - [-3.15411499 -0.37089692  0.20582139] 0.03753258693165414\n[2022-04-10 19:55:08] - evaluating...\n[2022-04-10 19:55:33] - valid_l1 0.084106, test_l1 0.081040\n[2022-04-10 19:55:33] - valid_dtw 0.290962, test_dtw 0.274139\n[2022-04-10 19:55:33] - Epoch: 79\n[2022-04-10 19:55:33] - training...\n[2022-04-10 19:55:34] - valid_l1 0.084106, test_l1 0.081040\n[2022-04-10 19:55:34] - valid_dtw 0.290962, test_dtw 0.274139\n[2022-04-10 19:55:34] - Epoch: 79\n[2022-04-10 19:55:34] - training...\n[2022-04-10 20:07:55] - [-3.11842926 -0.37196299  0.18074117] 0.03715394471377292\n[2022-04-10 20:07:55] - evaluating...\n[2022-04-10 20:07:56] - [-3.11842926 -0.37196299  0.18074117] 0.03715394471377292\n[2022-04-10 20:07:56] - evaluating...\n[2022-04-10 20:08:20] - valid_l1 0.092210, test_l1 0.091947\n[2022-04-10 20:08:20] - valid_dtw 0.315545, test_dtw 0.307823\n[2022-04-10 20:08:20] - Epoch: 80\n[2022-04-10 20:08:20] - training...\n[2022-04-10 20:08:21] - valid_l1 0.092210, test_l1 0.091947\n[2022-04-10 20:08:21] - valid_dtw 0.315545, test_dtw 0.307823\n[2022-04-10 20:08:21] - Epoch: 80\n[2022-04-10 20:08:21] - training...\n[2022-04-10 20:20:24] - [-3.13682418 -0.36978809  0.21878374] 0.03846539628339389\n[2022-04-10 20:20:24] - evaluating...\n[2022-04-10 20:20:25] - [-3.13682418 -0.36978809  0.21878374] 0.03846539628339389\n[2022-04-10 20:20:25] - evaluating...\n[2022-04-10 20:20:50] - valid_l1 0.092237, test_l1 0.087201\n[2022-04-10 20:20:50] - valid_dtw 0.320087, test_dtw 0.297653\n[2022-04-10 20:20:50] - Epoch: 81\n[2022-04-10 20:20:50] - training...\n[2022-04-10 20:20:50] - valid_l1 0.092237, test_l1 0.087201\n[2022-04-10 20:20:50] - valid_dtw 0.320087, test_dtw 0.297653\n[2022-04-10 20:20:50] - Epoch: 81\n[2022-04-10 20:20:50] - training...\n[2022-04-10 20:33:12] - [-3.12782082 -0.37095154  0.13281608] 0.03807458843260464\n[2022-04-10 20:33:12] - evaluating...\n[2022-04-10 20:33:12] - [-3.12782082 -0.37095154  0.13281608] 0.03807458843260464\n[2022-04-10 20:33:12] - evaluating...\n[2022-04-10 20:33:38] - valid_l1 0.082675, test_l1 0.078609\n[2022-04-10 20:33:38] - valid_dtw 0.287263, test_dtw 0.269124\n[2022-04-10 20:33:38] - Epoch: 82\n[2022-04-10 20:33:38] - training...\n[2022-04-10 20:33:38] - valid_l1 0.082675, test_l1 0.078609\n[2022-04-10 20:33:38] - valid_dtw 0.287263, test_dtw 0.269124\n[2022-04-10 20:33:38] - Epoch: 82\n[2022-04-10 20:33:38] - training...\n[2022-04-10 20:45:49] - [-3.17508391 -0.37313844  0.12749897] 0.03705482159180744\n[2022-04-10 20:45:49] - evaluating...\n[2022-04-10 20:45:49] - [-3.17508391 -0.37313844  0.12749897] 0.03705482159180744\n[2022-04-10 20:45:49] - evaluating...\n[2022-04-10 20:46:14] - valid_l1 0.095016, test_l1 0.092617\n[2022-04-10 20:46:14] - valid_dtw 0.328133, test_dtw 0.315197\n[2022-04-10 20:46:14] - Epoch: 83\n[2022-04-10 20:46:14] - training...\n[2022-04-10 20:46:14] - valid_l1 0.095016, test_l1 0.092617\n[2022-04-10 20:46:14] - valid_dtw 0.328133, test_dtw 0.315197\n[2022-04-10 20:46:14] - Epoch: 83\n[2022-04-10 20:46:14] - training...\n[2022-04-10 20:57:42] - [-3.19455511 -0.37143325  0.06683541] 0.03778998073693337\n[2022-04-10 20:57:42] - evaluating...\n[2022-04-10 20:57:42] - [-3.19455511 -0.37143325  0.06683541] 0.03778998073693337\n[2022-04-10 20:57:42] - evaluating...\n[2022-04-10 20:58:07] - valid_l1 0.097877, test_l1 0.103214\n[2022-04-10 20:58:07] - valid_dtw 0.359177, test_dtw 0.366382\n[2022-04-10 20:58:07] - Epoch: 84\n[2022-04-10 20:58:07] - training...\n[2022-04-10 20:58:07] - valid_l1 0.097877, test_l1 0.103214\n[2022-04-10 20:58:07] - valid_dtw 0.359177, test_dtw 0.366382\n[2022-04-10 20:58:07] - Epoch: 84\n[2022-04-10 20:58:07] - training...\n[2022-04-10 21:09:21] - [-3.13806489 -0.36841132  0.18841578] 0.039735049586658834\n[2022-04-10 21:09:21] - evaluating...\n[2022-04-10 21:09:21] - [-3.13806489 -0.36841132  0.18841578] 0.039735049586658834\n[2022-04-10 21:09:21] - evaluating...\n[2022-04-10 21:09:46] - valid_l1 0.092922, test_l1 0.091518\n[2022-04-10 21:09:46] - valid_dtw 0.342051, test_dtw 0.329035\n[2022-04-10 21:09:46] - Epoch: 85\n[2022-04-10 21:09:46] - training...\n[2022-04-10 21:09:46] - valid_l1 0.092922, test_l1 0.091518\n[2022-04-10 21:09:46] - valid_dtw 0.342051, test_dtw 0.329035\n[2022-04-10 21:09:46] - Epoch: 85\n[2022-04-10 21:09:46] - training...\n[2022-04-10 21:21:29] - [-3.17156938 -0.37101101  0.11237271] 0.0380871716730836\n[2022-04-10 21:21:29] - evaluating...\n[2022-04-10 21:21:30] - [-3.17156938 -0.37101101  0.11237271] 0.0380871716730836\n[2022-04-10 21:21:30] - evaluating...\n[2022-04-10 21:21:54] - valid_l1 0.092023, test_l1 0.084746\n[2022-04-10 21:21:54] - valid_dtw 0.324966, test_dtw 0.300735\n[2022-04-10 21:21:54] - Epoch: 86\n[2022-04-10 21:21:54] - training...\n[2022-04-10 21:21:55] - valid_l1 0.092023, test_l1 0.084746\n[2022-04-10 21:21:55] - valid_dtw 0.324966, test_dtw 0.300735\n[2022-04-10 21:21:55] - Epoch: 86\n[2022-04-10 21:21:55] - training...\n[2022-04-10 21:33:50] - [-3.19540314 -0.37089976  0.11248582] 0.03915621501395021\n[2022-04-10 21:33:50] - evaluating...\n[2022-04-10 21:33:51] - [-3.19540314 -0.37089976  0.11248582] 0.03915621501395021\n[2022-04-10 21:33:51] - evaluating...\n[2022-04-10 21:34:16] - valid_l1 0.089570, test_l1 0.091345\n[2022-04-10 21:34:16] - valid_dtw 0.318100, test_dtw 0.315703\n[2022-04-10 21:34:16] - Epoch: 87\n[2022-04-10 21:34:16] - training...\n[2022-04-10 21:34:17] - valid_l1 0.089570, test_l1 0.091345\n[2022-04-10 21:34:17] - valid_dtw 0.318100, test_dtw 0.315703\n[2022-04-10 21:34:17] - Epoch: 87\n[2022-04-10 21:34:17] - training...\n[2022-04-10 21:47:06] - [-3.15944243 -0.37151     0.16618506] 0.03790615170247302\n[2022-04-10 21:47:06] - evaluating...\n[2022-04-10 21:47:08] - [-3.15944243 -0.37151     0.16618506] 0.03790615170247302\n[2022-04-10 21:47:08] - evaluating...\n[2022-04-10 21:47:32] - valid_l1 0.084241, test_l1 0.082106\n[2022-04-10 21:47:32] - valid_dtw 0.301603, test_dtw 0.289986\n[2022-04-10 21:47:32] - Epoch: 88\n[2022-04-10 21:47:32] - training...\n[2022-04-10 21:47:34] - valid_l1 0.084241, test_l1 0.082106\n[2022-04-10 21:47:34] - valid_dtw 0.301603, test_dtw 0.289986\n[2022-04-10 21:47:34] - Epoch: 88\n[2022-04-10 21:47:34] - training...\n[2022-04-10 23:27:30] - [-3.20346505 -0.37360631  0.1325912 ] 0.03674070486239808\n[2022-04-10 23:27:31] - evaluating...\n[2022-04-10 23:27:31] - [-3.20346505 -0.37360631  0.1325912 ] 0.03674070486239808\n[2022-04-10 23:27:31] - evaluating...\n[2022-04-10 23:27:56] - valid_l1 0.105720, test_l1 0.096882\n[2022-04-10 23:27:56] - valid_dtw 0.389069, test_dtw 0.356746\n[2022-04-10 23:27:56] - Epoch: 89\n[2022-04-10 23:27:56] - training...\n[2022-04-10 23:27:56] - valid_l1 0.105720, test_l1 0.096882\n[2022-04-10 23:27:56] - valid_dtw 0.389069, test_dtw 0.356746\n[2022-04-10 23:27:56] - Epoch: 89\n[2022-04-10 23:27:56] - training...\n[2022-04-10 23:40:07] - [-3.1208414  -0.37009814  0.1017518 ] 0.039359315426326265\n[2022-04-10 23:40:07] - evaluating...\n[2022-04-10 23:40:11] - [-3.1208414  -0.37009814  0.1017518 ] 0.039359315426326265\n[2022-04-10 23:40:11] - evaluating...\n[2022-04-10 23:40:32] - valid_l1 0.060138, test_l1 0.056682\n[2022-04-10 23:40:32] - valid_dtw 0.198657, test_dtw 0.190220\n[2022-04-10 23:40:32] - early stop\n[2022-04-10 23:40:32] - best val score: 0.00911357055155066 @ 39\n[2022-04-10 23:40:32] - inference...\n[2022-04-10 23:40:36] - valid_l1 0.060138, test_l1 0.056682\n[2022-04-10 23:40:36] - valid_dtw 0.198657, test_dtw 0.190220\n[2022-04-10 23:40:36] - early stop\n[2022-04-10 23:40:36] - best val score: 0.00911357055155066 @ 39\n[2022-04-10 23:40:36] - inference...\n[2022-04-10 23:40:57] - MSE: train 0.014742, valid 0.009049, test 0.007117\n[2022-04-10 23:40:57] - L1:  train 0.068676, valid 0.053423, test 0.048198\n[2022-04-10 23:40:57] - RMSE: train 0.097278, valid 0.075975, test 0.066648\n[2022-04-10 23:40:57] - DTW: train 0.246992, valid 0.189957, test 0.163563\n[2022-04-10 23:40:57] - TDI: train 1.125671, valid 1.125352, test 1.165114\n[2022-04-10 23:40:57] - Finished.\n[2022-04-10 23:41:00] - MSE: train 0.014742, valid 0.009049, test 0.007117\n[2022-04-10 23:41:00] - L1:  train 0.068676, valid 0.053423, test 0.048198\n[2022-04-10 23:41:00] - RMSE: train 0.097278, valid 0.075975, test 0.066648\n[2022-04-10 23:41:00] - DTW: train 0.246992, valid 0.189957, test 0.163563\n[2022-04-10 23:41:00] - TDI: train 0.281418, valid 0.281338, test 0.291278\n[2022-04-10 23:41:00] - Finished.\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/outputs_Jintang_DualAdaRNN_weather_cosine_20_0.05_0.0005/run.log b/outputs_Jintang_DualAdaRNN_weather_cosine_20_0.05_0.0005/run.log
--- a/outputs_Jintang_DualAdaRNN_weather_cosine_20_0.05_0.0005/run.log	(revision 4d374eb052e73a15d49eb92596cef4473d6d2218)
+++ b/outputs_Jintang_DualAdaRNN_weather_cosine_20_0.05_0.0005/run.log	(date 1649998208480)
@@ -1098,3 +1098,959 @@
 [2022-04-10 23:41:00] - DTW: train 0.246992, valid 0.189957, test 0.163563
 [2022-04-10 23:41:00] - TDI: train 0.281418, valid 0.281338, test 0.291278
 [2022-04-10 23:41:00] - Finished.
+[2022-04-14 16:33:12] - create model_king...
+[2022-04-14 16:33:12] - Epoch: 0
+[2022-04-14 16:33:12] - training...
+[2022-04-14 16:36:34] - [0.96279291 0.25563572 0.95580105] 0.1326297949327338
+[2022-04-14 16:36:34] - evaluating...
+[2022-04-14 16:37:00] - valid_l1 0.064793, test_l1 0.064265
+[2022-04-14 16:37:00] - valid_dtw 0.178300, test_dtw 0.175412
+[2022-04-14 16:37:00] - Epoch: 1
+[2022-04-14 16:37:00] - training...
+[2022-04-14 16:40:17] - [0.55347025 0.11481809 1.2758461 ] 0.08530531857806938
+[2022-04-14 16:40:17] - evaluating...
+[2022-04-14 16:40:43] - valid_l1 0.079740, test_l1 0.067162
+[2022-04-14 16:40:43] - valid_dtw 0.245752, test_dtw 0.211505
+[2022-04-14 16:40:43] - Epoch: 2
+[2022-04-14 16:40:43] - training...
+[2022-04-14 16:43:59] - [0.50395599 0.08930825 1.14906827] 0.07434581809194016
+[2022-04-14 16:43:59] - evaluating...
+[2022-04-14 16:44:25] - valid_l1 0.117092, test_l1 0.106964
+[2022-04-14 16:44:25] - valid_dtw 0.363994, test_dtw 0.331417
+[2022-04-14 16:44:25] - Epoch: 3
+[2022-04-14 16:44:25] - training...
+[2022-04-14 16:47:41] - [0.44112567 0.07807827 0.99226968] 0.06964980599687512
+[2022-04-14 16:47:41] - evaluating...
+[2022-04-14 16:48:07] - valid_l1 0.116363, test_l1 0.108440
+[2022-04-14 16:48:07] - valid_dtw 0.380888, test_dtw 0.353606
+[2022-04-14 16:48:07] - Epoch: 4
+[2022-04-14 16:48:07] - training...
+[2022-04-14 16:51:22] - [0.43322964 0.07431577 0.89062733] 0.06733880014179792
+[2022-04-14 16:51:22] - evaluating...
+[2022-04-14 16:51:48] - valid_l1 0.120144, test_l1 0.109605
+[2022-04-14 16:51:48] - valid_dtw 0.385574, test_dtw 0.353966
+[2022-04-14 16:51:48] - Epoch: 5
+[2022-04-14 16:51:48] - training...
+[2022-04-14 16:55:10] - [0.47302546 0.09134785 0.89651058] 0.07509792737270657
+[2022-04-14 16:55:11] - evaluating...
+[2022-04-14 16:55:36] - valid_l1 0.111037, test_l1 0.104611
+[2022-04-14 16:55:36] - valid_dtw 0.367723, test_dtw 0.342215
+[2022-04-14 16:55:36] - Epoch: 6
+[2022-04-14 16:55:36] - training...
+[2022-04-14 16:58:51] - [0.42508705 0.07702738 0.83518665] 0.07169437769772415
+[2022-04-14 16:58:51] - evaluating...
+[2022-04-14 16:59:16] - valid_l1 0.109927, test_l1 0.096015
+[2022-04-14 16:59:16] - valid_dtw 0.365635, test_dtw 0.325236
+[2022-04-14 16:59:16] - Epoch: 7
+[2022-04-14 16:59:16] - training...
+[2022-04-14 17:02:31] - [0.40074894 0.06588045 0.79211638] 0.06727477693860244
+[2022-04-14 17:02:31] - evaluating...
+[2022-04-14 17:02:56] - valid_l1 0.108177, test_l1 0.099924
+[2022-04-14 17:02:56] - valid_dtw 0.335161, test_dtw 0.305704
+[2022-04-14 17:02:56] - Epoch: 8
+[2022-04-14 17:02:56] - training...
+[2022-04-14 17:06:11] - [0.39492238 0.0643821  0.77334654] 0.06686151382282264
+[2022-04-14 17:06:11] - evaluating...
+[2022-04-14 17:06:36] - valid_l1 0.096599, test_l1 0.090160
+[2022-04-14 17:06:36] - valid_dtw 0.336771, test_dtw 0.312988
+[2022-04-14 17:06:36] - Epoch: 9
+[2022-04-14 17:06:36] - training...
+[2022-04-14 17:09:51] - [0.35006222 0.05400258 0.7304434 ] 0.06373763953832755
+[2022-04-14 17:09:51] - evaluating...
+[2022-04-14 17:10:17] - valid_l1 0.100816, test_l1 0.090689
+[2022-04-14 17:10:17] - valid_dtw 0.347256, test_dtw 0.315872
+[2022-04-14 17:10:17] - Epoch: 10
+[2022-04-14 17:10:17] - training...
+[2022-04-14 17:13:32] - [0.4285521  0.08006178 0.7006593 ] 0.0710184905565995
+[2022-04-14 17:13:32] - evaluating...
+[2022-04-14 17:13:58] - valid_l1 0.102813, test_l1 0.096782
+[2022-04-14 17:13:58] - valid_dtw 0.342151, test_dtw 0.319546
+[2022-04-14 17:13:58] - Epoch: 11
+[2022-04-14 17:13:58] - training...
+[2022-04-14 17:17:13] - [0.38213473 0.06584958 0.7165559 ] 0.0672549352666041
+[2022-04-14 17:17:13] - evaluating...
+[2022-04-14 17:17:38] - valid_l1 0.117102, test_l1 0.108977
+[2022-04-14 17:17:38] - valid_dtw 0.393674, test_dtw 0.364293
+[2022-04-14 17:17:38] - Epoch: 12
+[2022-04-14 17:17:38] - training...
+[2022-04-14 17:20:54] - [0.38669786 0.06957733 0.70109109] 0.06828770398029259
+[2022-04-14 17:20:54] - evaluating...
+[2022-04-14 17:21:19] - valid_l1 0.106825, test_l1 0.101837
+[2022-04-14 17:21:19] - valid_dtw 0.363859, test_dtw 0.342233
+[2022-04-14 17:21:19] - Epoch: 13
+[2022-04-14 17:21:19] - training...
+[2022-04-14 17:24:35] - [0.3795611  0.05968607 0.71662332] 0.0660121217398043
+[2022-04-14 17:24:35] - evaluating...
+[2022-04-14 17:25:00] - valid_l1 0.121934, test_l1 0.110711
+[2022-04-14 17:25:00] - valid_dtw 0.406593, test_dtw 0.371826
+[2022-04-14 17:25:00] - Epoch: 14
+[2022-04-14 17:25:00] - training...
+[2022-04-14 17:28:15] - [0.3960716  0.06182124 0.79925139] 0.06654345487293443
+[2022-04-14 17:28:15] - evaluating...
+[2022-04-14 17:28:41] - valid_l1 0.103949, test_l1 0.097159
+[2022-04-14 17:28:41] - valid_dtw 0.349977, test_dtw 0.324387
+[2022-04-14 17:28:41] - Epoch: 15
+[2022-04-14 17:28:41] - training...
+[2022-04-14 17:31:56] - [0.38177005 0.0733112  0.70960697] 0.07066459065317211
+[2022-04-14 17:31:56] - evaluating...
+[2022-04-14 17:32:22] - valid_l1 0.115072, test_l1 0.109658
+[2022-04-14 17:32:22] - valid_dtw 0.354538, test_dtw 0.333623
+[2022-04-14 17:32:22] - Epoch: 16
+[2022-04-14 17:32:22] - training...
+[2022-04-14 17:35:37] - [0.37204779 0.06386826 0.62935216] 0.06695831633992214
+[2022-04-14 17:35:37] - evaluating...
+[2022-04-14 17:36:02] - valid_l1 0.098933, test_l1 0.096217
+[2022-04-14 17:36:02] - valid_dtw 0.325586, test_dtw 0.308408
+[2022-04-14 17:36:02] - Epoch: 17
+[2022-04-14 17:36:02] - training...
+[2022-04-14 17:39:17] - [0.39514504 0.06780553 0.69903738] 0.0685322689606731
+[2022-04-14 17:39:17] - evaluating...
+[2022-04-14 17:39:43] - valid_l1 0.098289, test_l1 0.097198
+[2022-04-14 17:39:43] - valid_dtw 0.343557, test_dtw 0.325669
+[2022-04-14 17:39:43] - Epoch: 18
+[2022-04-14 17:39:43] - training...
+[2022-04-14 17:42:58] - [0.36911946 0.0557583  0.71284811] 0.06429372093451202
+[2022-04-14 17:42:58] - evaluating...
+[2022-04-14 17:43:24] - valid_l1 0.103814, test_l1 0.094908
+[2022-04-14 17:43:24] - valid_dtw 0.336914, test_dtw 0.305037
+[2022-04-14 17:43:24] - Epoch: 19
+[2022-04-14 17:43:24] - training...
+[2022-04-14 17:46:39] - [0.36215601 0.05673182 0.71786652] 0.06586269475799754
+[2022-04-14 17:46:39] - evaluating...
+[2022-04-14 17:47:05] - valid_l1 0.100694, test_l1 0.098486
+[2022-04-14 17:47:05] - valid_dtw 0.340631, test_dtw 0.323084
+[2022-04-14 17:47:05] - Epoch: 20
+[2022-04-14 17:47:05] - training...
+[2022-04-14 17:50:22] - [0.3719256  0.05946667 0.69113823] 0.06667669847103438
+[2022-04-14 17:50:22] - evaluating...
+[2022-04-14 17:50:48] - valid_l1 0.120093, test_l1 0.103985
+[2022-04-14 17:50:48] - valid_dtw 0.377944, test_dtw 0.330788
+[2022-04-14 17:50:48] - Epoch: 21
+[2022-04-14 17:50:48] - training...
+[2022-04-14 17:54:11] - [0.40902693 0.07006457 0.79265959] 0.06940481378171677
+[2022-04-14 17:54:11] - evaluating...
+[2022-04-14 17:54:37] - valid_l1 0.113325, test_l1 0.105836
+[2022-04-14 17:54:37] - valid_dtw 0.342657, test_dtw 0.314850
+[2022-04-14 17:54:37] - Epoch: 22
+[2022-04-14 17:54:37] - training...
+[2022-04-14 17:57:52] - [0.39707634 0.06181895 0.71545659] 0.06739970142567965
+[2022-04-14 17:57:53] - evaluating...
+[2022-04-14 17:58:18] - valid_l1 0.132575, test_l1 0.119972
+[2022-04-14 17:58:18] - valid_dtw 0.384639, test_dtw 0.348009
+[2022-04-14 17:58:18] - Epoch: 23
+[2022-04-14 17:58:18] - training...
+[2022-04-14 18:01:33] - [0.38441474 0.06015996 0.74632487] 0.06771207449019404
+[2022-04-14 18:01:34] - evaluating...
+[2022-04-14 18:01:59] - valid_l1 0.117318, test_l1 0.108135
+[2022-04-14 18:01:59] - valid_dtw 0.362478, test_dtw 0.328430
+[2022-04-14 18:01:59] - Epoch: 24
+[2022-04-14 18:01:59] - training...
+[2022-04-14 18:05:20] - [0.38644125 0.06289416 0.73251497] 0.06854471876320982
+[2022-04-14 18:05:20] - evaluating...
+[2022-04-14 18:05:47] - valid_l1 0.117019, test_l1 0.111766
+[2022-04-14 18:05:47] - valid_dtw 0.358743, test_dtw 0.335508
+[2022-04-14 18:05:47] - Epoch: 25
+[2022-04-14 18:05:47] - training...
+[2022-04-14 18:09:16] - [0.39651848 0.05670616 0.78601285] 0.06416675061603686
+[2022-04-14 18:09:16] - evaluating...
+[2022-04-14 18:09:43] - valid_l1 0.130252, test_l1 0.121504
+[2022-04-14 18:09:43] - valid_dtw 0.389404, test_dtw 0.358781
+[2022-04-14 18:09:43] - Epoch: 26
+[2022-04-14 18:09:43] - training...
+[2022-04-14 18:13:06] - [0.36004838 0.04881357 0.71566902] 0.06198903986890065
+[2022-04-14 18:13:06] - evaluating...
+[2022-04-14 18:13:33] - valid_l1 0.093747, test_l1 0.083154
+[2022-04-14 18:13:33] - valid_dtw 0.294704, test_dtw 0.256264
+[2022-04-14 18:13:33] - Epoch: 27
+[2022-04-14 18:13:33] - training...
+[2022-04-14 18:16:54] - [0.35896988 0.04817803 0.72112343] 0.06151560175239592
+[2022-04-14 18:16:54] - evaluating...
+[2022-04-14 18:17:20] - valid_l1 0.121880, test_l1 0.119261
+[2022-04-14 18:17:20] - valid_dtw 0.367052, test_dtw 0.352034
+[2022-04-14 18:17:20] - Epoch: 28
+[2022-04-14 18:17:20] - training...
+[2022-04-14 18:20:45] - [0.37943662 0.055074   0.69534517] 0.06381592444403279
+[2022-04-14 18:20:45] - evaluating...
+[2022-04-14 18:21:11] - valid_l1 0.113916, test_l1 0.101129
+[2022-04-14 18:21:11] - valid_dtw 0.337997, test_dtw 0.300931
+[2022-04-14 18:21:11] - Epoch: 29
+[2022-04-14 18:21:11] - training...
+[2022-04-14 18:24:34] - [0.36840828 0.04565107 0.64588034] 0.05987271595382153
+[2022-04-14 18:24:34] - evaluating...
+[2022-04-14 18:25:00] - valid_l1 0.138210, test_l1 0.128453
+[2022-04-14 18:25:00] - valid_dtw 0.396253, test_dtw 0.364965
+[2022-04-14 18:25:00] - Epoch: 30
+[2022-04-14 18:25:00] - training...
+[2022-04-14 18:28:21] - [0.35745988 0.0486537  0.66041694] 0.06114554326225044
+[2022-04-14 18:28:21] - evaluating...
+[2022-04-14 18:28:47] - valid_l1 0.127704, test_l1 0.118570
+[2022-04-14 18:28:47] - valid_dtw 0.365235, test_dtw 0.336543
+[2022-04-14 18:28:47] - Epoch: 31
+[2022-04-14 18:28:47] - training...
+[2022-04-14 18:32:06] - [0.35239777 0.04476208 0.65609711] 0.058988386006059504
+[2022-04-14 18:32:06] - evaluating...
+[2022-04-14 18:32:32] - valid_l1 0.124951, test_l1 0.117950
+[2022-04-14 18:32:32] - valid_dtw 0.369815, test_dtw 0.346118
+[2022-04-14 18:32:32] - Epoch: 32
+[2022-04-14 18:32:32] - training...
+[2022-04-14 18:35:52] - [0.35772408 0.0499534  0.64457351] 0.06147033261849468
+[2022-04-14 18:35:52] - evaluating...
+[2022-04-14 18:36:18] - valid_l1 0.112965, test_l1 0.102907
+[2022-04-14 18:36:18] - valid_dtw 0.335282, test_dtw 0.305497
+[2022-04-14 18:36:18] - Epoch: 33
+[2022-04-14 18:36:18] - training...
+[2022-04-14 18:39:45] - [0.36644484 0.05150753 0.67888296] 0.0625246111667694
+[2022-04-14 18:39:46] - evaluating...
+[2022-04-14 18:40:13] - valid_l1 0.146072, test_l1 0.152117
+[2022-04-14 18:40:13] - valid_dtw 0.418576, test_dtw 0.428686
+[2022-04-14 18:40:13] - Epoch: 34
+[2022-04-14 18:40:13] - training...
+[2022-04-14 18:43:41] - [0.35666412 0.04764374 0.67521946] 0.06087213771459751
+[2022-04-14 18:43:41] - evaluating...
+[2022-04-14 18:44:08] - valid_l1 0.122590, test_l1 0.116072
+[2022-04-14 18:44:08] - valid_dtw 0.358098, test_dtw 0.336938
+[2022-04-14 18:44:08] - Epoch: 35
+[2022-04-14 18:44:08] - training...
+[2022-04-14 18:47:27] - [0.37655545 0.05557868 0.6852353 ] 0.06401150932157398
+[2022-04-14 18:47:27] - evaluating...
+[2022-04-14 18:47:53] - valid_l1 0.119679, test_l1 0.111870
+[2022-04-14 18:47:53] - valid_dtw 0.360355, test_dtw 0.330674
+[2022-04-14 18:47:53] - Epoch: 36
+[2022-04-14 18:47:53] - training...
+[2022-04-14 18:51:12] - [0.34667752 0.04668303 0.64888601] 0.060031397503457574
+[2022-04-14 18:51:12] - evaluating...
+[2022-04-14 18:51:37] - valid_l1 0.128924, test_l1 0.120463
+[2022-04-14 18:51:37] - valid_dtw 0.373469, test_dtw 0.344140
+[2022-04-14 18:51:37] - Epoch: 37
+[2022-04-14 18:51:37] - training...
+[2022-04-14 18:54:54] - [0.35948305 0.05096992 0.68973383] 0.06251816109551075
+[2022-04-14 18:54:54] - evaluating...
+[2022-04-14 18:55:20] - valid_l1 0.124007, test_l1 0.123265
+[2022-04-14 18:55:20] - valid_dtw 0.367904, test_dtw 0.362040
+[2022-04-14 18:55:20] - Epoch: 38
+[2022-04-14 18:55:20] - training...
+[2022-04-14 18:58:49] - [0.32779646 0.04480859 0.66133277] 0.06013854486041499
+[2022-04-14 18:58:49] - evaluating...
+[2022-04-14 18:59:16] - valid_l1 0.122637, test_l1 0.116943
+[2022-04-14 18:59:16] - valid_dtw 0.358408, test_dtw 0.338763
+[2022-04-14 18:59:16] - Epoch: 39
+[2022-04-14 18:59:16] - training...
+[2022-04-14 19:00:18] - create model_king...
+[2022-04-14 19:00:18] - Epoch: 0
+[2022-04-14 19:00:18] - training...
+[2022-04-14 19:02:47] - [0.33401378 0.04489088 0.64040056] 0.06003913546919375
+[2022-04-14 19:02:47] - evaluating...
+[2022-04-14 19:03:14] - valid_l1 0.134430, test_l1 0.128852
+[2022-04-14 19:03:14] - valid_dtw 0.387799, test_dtw 0.368223
+[2022-04-14 19:03:14] - Epoch: 40
+[2022-04-14 19:03:14] - training...
+[2022-04-14 19:03:49] - [9.86184117 3.04465399 0.6206484 ] 0.39165165142569325
+[2022-04-14 19:03:49] - evaluating...
+[2022-04-14 19:04:17] - valid_l1 0.333732, test_l1 0.257326
+[2022-04-14 19:04:17] - valid_dtw 0.858349, test_dtw 0.664974
+[2022-04-14 19:04:17] - Epoch: 1
+[2022-04-14 19:04:17] - training...
+[2022-04-14 19:06:37] - [0.35843877 0.04845311 0.6843079 ] 0.06048280290026862
+[2022-04-14 19:06:37] - evaluating...
+[2022-04-14 19:07:03] - valid_l1 0.125447, test_l1 0.129075
+[2022-04-14 19:07:03] - valid_dtw 0.375182, test_dtw 0.379135
+[2022-04-14 19:07:03] - Epoch: 41
+[2022-04-14 19:07:03] - training...
+[2022-04-14 19:07:38] - [2.16639002 0.21457341 0.67911905] 0.10683236508105035
+[2022-04-14 19:07:38] - evaluating...
+[2022-04-14 19:08:05] - valid_l1 0.298073, test_l1 0.266117
+[2022-04-14 19:08:05] - valid_dtw 0.796669, test_dtw 0.712523
+[2022-04-14 19:08:05] - Epoch: 2
+[2022-04-14 19:08:05] - training...
+[2022-04-14 19:10:24] - [0.36954854 0.0547666  0.67043746] 0.06323279515749082
+[2022-04-14 19:10:24] - evaluating...
+[2022-04-14 19:10:50] - valid_l1 0.110410, test_l1 0.106795
+[2022-04-14 19:10:50] - valid_dtw 0.322616, test_dtw 0.310231
+[2022-04-14 19:10:50] - Epoch: 42
+[2022-04-14 19:10:50] - training...
+[2022-04-14 19:11:27] - [1.14100933 0.24995675 0.62464296] 0.11866238259087156
+[2022-04-14 19:11:27] - evaluating...
+[2022-04-14 19:11:56] - valid_l1 0.208886, test_l1 0.185545
+[2022-04-14 19:11:56] - valid_dtw 0.595047, test_dtw 0.529960
+[2022-04-14 19:11:56] - Epoch: 3
+[2022-04-14 19:11:56] - training...
+[2022-04-14 19:14:18] - [0.34971456 0.05284232 0.67638641] 0.06285431704630977
+[2022-04-14 19:14:18] - evaluating...
+[2022-04-14 19:14:45] - valid_l1 0.147492, test_l1 0.152720
+[2022-04-14 19:14:45] - valid_dtw 0.428195, test_dtw 0.438342
+[2022-04-14 19:14:45] - Epoch: 43
+[2022-04-14 19:14:45] - training...
+[2022-04-14 19:15:23] - [0.7936904  0.15071779 0.93102199] 0.09193869844443144
+[2022-04-14 19:15:23] - evaluating...
+[2022-04-14 19:15:50] - valid_l1 0.212371, test_l1 0.193403
+[2022-04-14 19:15:50] - valid_dtw 0.606111, test_dtw 0.556558
+[2022-04-14 19:15:50] - Epoch: 4
+[2022-04-14 19:15:50] - training...
+[2022-04-14 19:18:14] - [0.33594845 0.04580075 0.65063496] 0.0577822814282394
+[2022-04-14 19:18:14] - evaluating...
+[2022-04-14 19:18:42] - valid_l1 0.134349, test_l1 0.136743
+[2022-04-14 19:18:42] - valid_dtw 0.391466, test_dtw 0.387522
+[2022-04-14 19:18:42] - Epoch: 44
+[2022-04-14 19:18:42] - training...
+[2022-04-14 19:19:19] - [0.70325623 0.09890007 0.75219878] 0.07273086662915416
+[2022-04-14 19:19:19] - evaluating...
+[2022-04-14 19:19:46] - valid_l1 0.174244, test_l1 0.155479
+[2022-04-14 19:19:46] - valid_dtw 0.532905, test_dtw 0.482679
+[2022-04-14 19:19:46] - Epoch: 5
+[2022-04-14 19:19:46] - training...
+[2022-04-14 19:22:13] - [0.33278729 0.05053076 0.62548117] 0.05931788705345383
+[2022-04-14 19:22:13] - evaluating...
+[2022-04-14 19:22:40] - valid_l1 0.131161, test_l1 0.124721
+[2022-04-14 19:22:40] - valid_dtw 0.387417, test_dtw 0.369047
+[2022-04-14 19:22:40] - Epoch: 45
+[2022-04-14 19:22:40] - training...
+[2022-04-14 19:23:18] - [0.65828546 0.10954147 0.63920213] 0.08001994812454945
+[2022-04-14 19:23:18] - evaluating...
+[2022-04-14 19:23:46] - valid_l1 0.246834, test_l1 0.206439
+[2022-04-14 19:23:46] - valid_dtw 0.685487, test_dtw 0.580138
+[2022-04-14 19:23:46] - Epoch: 6
+[2022-04-14 19:23:46] - training...
+[2022-04-14 19:26:07] - [0.35145315 0.05061794 0.6478202 ] 0.05949015633896329
+[2022-04-14 19:26:07] - evaluating...
+[2022-04-14 19:26:36] - valid_l1 0.148144, test_l1 0.143785
+[2022-04-14 19:26:36] - valid_dtw 0.440024, test_dtw 0.424562
+[2022-04-14 19:26:36] - Epoch: 46
+[2022-04-14 19:26:36] - training...
+[2022-04-14 19:27:14] - [0.85285696 0.22475385 0.76501666] 0.10857786575710415
+[2022-04-14 19:27:14] - evaluating...
+[2022-04-14 19:27:42] - valid_l1 0.230099, test_l1 0.219088
+[2022-04-14 19:27:42] - valid_dtw 0.654868, test_dtw 0.620586
+[2022-04-14 19:27:42] - Epoch: 7
+[2022-04-14 19:27:42] - training...
+[2022-04-14 19:30:03] - [0.33873495 0.05142858 0.64517659] 0.058898065678943366
+[2022-04-14 19:30:03] - evaluating...
+[2022-04-14 19:30:33] - valid_l1 0.136453, test_l1 0.132625
+[2022-04-14 19:30:33] - valid_dtw 0.405455, test_dtw 0.387994
+[2022-04-14 19:30:33] - Epoch: 47
+[2022-04-14 19:30:33] - training...
+[2022-04-14 19:31:12] - [0.71014426 0.12433025 0.44268781] 0.07581540937570477
+[2022-04-14 19:31:12] - evaluating...
+[2022-04-14 19:31:39] - valid_l1 0.272051, test_l1 0.293083
+[2022-04-14 19:31:39] - valid_dtw 0.758045, test_dtw 0.798694
+[2022-04-14 19:31:39] - Epoch: 8
+[2022-04-14 19:31:39] - training...
+[2022-04-14 19:34:05] - [0.36198147 0.05717364 0.69972786] 0.06272749252393281
+[2022-04-14 19:34:05] - evaluating...
+[2022-04-14 19:34:32] - valid_l1 0.130543, test_l1 0.130651
+[2022-04-14 19:34:32] - valid_dtw 0.387296, test_dtw 0.386196
+[2022-04-14 19:34:32] - Epoch: 48
+[2022-04-14 19:34:32] - training...
+[2022-04-14 19:35:10] - [0.72133154 0.10764177 0.37763784] 0.07421354026974816
+[2022-04-14 19:35:10] - evaluating...
+[2022-04-14 19:35:37] - valid_l1 0.161441, test_l1 0.156209
+[2022-04-14 19:35:37] - valid_dtw 0.499911, test_dtw 0.491934
+[2022-04-14 19:35:37] - Epoch: 9
+[2022-04-14 19:35:37] - training...
+[2022-04-14 19:38:03] - [0.35227671 0.05495872 0.66277371] 0.06154903204537424
+[2022-04-14 19:38:03] - evaluating...
+[2022-04-14 19:38:30] - valid_l1 0.143404, test_l1 0.148144
+[2022-04-14 19:38:30] - valid_dtw 0.419858, test_dtw 0.424181
+[2022-04-14 19:38:30] - Epoch: 49
+[2022-04-14 19:38:30] - training...
+[2022-04-14 19:39:07] - [0.99554202 0.20337974 0.90443131] 0.10306399321477665
+[2022-04-14 19:39:07] - evaluating...
+[2022-04-14 19:39:34] - valid_l1 0.205780, test_l1 0.183614
+[2022-04-14 19:39:34] - valid_dtw 0.585225, test_dtw 0.525290
+[2022-04-14 19:39:34] - Epoch: 10
+[2022-04-14 19:39:34] - training...
+[2022-04-14 19:42:00] - [0.36054212 0.05938858 0.64580888] 0.06411672762798187
+[2022-04-14 19:42:00] - evaluating...
+[2022-04-14 19:42:29] - valid_l1 0.145707, test_l1 0.144894
+[2022-04-14 19:42:29] - valid_dtw 0.434524, test_dtw 0.430903
+[2022-04-14 19:42:29] - Epoch: 50
+[2022-04-14 19:42:29] - training...
+[2022-04-14 19:43:07] - [0.73187369 0.10620168 0.57371444] 0.080282751654968
+[2022-04-14 19:43:07] - evaluating...
+[2022-04-14 19:43:34] - valid_l1 0.197844, test_l1 0.211347
+[2022-04-14 19:43:34] - valid_dtw 0.575474, test_dtw 0.602735
+[2022-04-14 19:43:34] - Epoch: 11
+[2022-04-14 19:43:34] - training...
+[2022-04-14 19:46:00] - [0.35477398 0.05596844 0.61511435] 0.060957337602188716
+[2022-04-14 19:46:00] - evaluating...
+[2022-04-14 19:46:26] - valid_l1 0.133144, test_l1 0.126788
+[2022-04-14 19:46:26] - valid_dtw 0.396794, test_dtw 0.374298
+[2022-04-14 19:46:26] - Epoch: 51
+[2022-04-14 19:46:26] - training...
+[2022-04-14 19:47:05] - [0.67928314 0.09394628 0.70009517] 0.07701986057165645
+[2022-04-14 19:47:05] - evaluating...
+[2022-04-14 19:47:34] - valid_l1 0.190863, test_l1 0.185239
+[2022-04-14 19:47:34] - valid_dtw 0.569155, test_dtw 0.548459
+[2022-04-14 19:47:34] - Epoch: 12
+[2022-04-14 19:47:34] - training...
+[2022-04-14 19:49:56] - [0.36447255 0.06286554 0.62111561] 0.06511862205439492
+[2022-04-14 19:49:56] - evaluating...
+[2022-04-14 19:50:22] - valid_l1 0.119848, test_l1 0.117914
+[2022-04-14 19:50:22] - valid_dtw 0.365394, test_dtw 0.355061
+[2022-04-14 19:50:22] - Epoch: 52
+[2022-04-14 19:50:22] - training...
+[2022-04-14 19:51:02] - [0.90750143 0.16723167 1.12771389] 0.09136790343301189
+[2022-04-14 19:51:02] - evaluating...
+[2022-04-14 19:51:32] - valid_l1 0.247625, test_l1 0.214319
+[2022-04-14 19:51:32] - valid_dtw 0.678619, test_dtw 0.591062
+[2022-04-14 19:51:32] - Epoch: 13
+[2022-04-14 19:51:32] - training...
+[2022-04-14 19:54:04] - [0.35878764 0.0634061  0.60899525] 0.06406006428196018
+[2022-04-14 19:54:04] - evaluating...
+[2022-04-14 19:54:32] - valid_l1 0.140651, test_l1 0.144381
+[2022-04-14 19:54:32] - valid_dtw 0.428660, test_dtw 0.427874
+[2022-04-14 19:54:32] - Epoch: 53
+[2022-04-14 19:54:32] - training...
+[2022-04-14 19:55:10] - [1.06710571 0.210417   1.41586122] 0.09838954132414401
+[2022-04-14 19:55:10] - evaluating...
+[2022-04-14 19:55:38] - valid_l1 0.254428, test_l1 0.226931
+[2022-04-14 19:55:38] - valid_dtw 0.710628, test_dtw 0.658075
+[2022-04-14 19:55:38] - Epoch: 14
+[2022-04-14 19:55:38] - training...
+[2022-04-14 19:58:07] - [0.33839234 0.05604384 0.61227283] 0.061556067449369825
+[2022-04-14 19:58:07] - evaluating...
+[2022-04-14 19:58:32] - valid_l1 0.138564, test_l1 0.142387
+[2022-04-14 19:58:32] - valid_dtw 0.421334, test_dtw 0.421425
+[2022-04-14 19:58:32] - Epoch: 54
+[2022-04-14 19:58:32] - training...
+[2022-04-14 19:59:03] - [0.98344236 0.11619408 1.45560367] 0.08410959079217417
+[2022-04-14 19:59:03] - evaluating...
+[2022-04-14 19:59:28] - valid_l1 0.253901, test_l1 0.281244
+[2022-04-14 19:59:28] - valid_dtw 0.708324, test_dtw 0.793125
+[2022-04-14 19:59:28] - Epoch: 15
+[2022-04-14 19:59:28] - training...
+[2022-04-14 20:01:50] - [0.33805776 0.05206011 0.60466725] 0.06044941643407022
+[2022-04-14 20:01:50] - evaluating...
+[2022-04-14 20:02:16] - valid_l1 0.127180, test_l1 0.131201
+[2022-04-14 20:02:16] - valid_dtw 0.388034, test_dtw 0.389503
+[2022-04-14 20:02:16] - Epoch: 55
+[2022-04-14 20:02:16] - training...
+[2022-04-14 20:02:43] - [0.9476542  0.16269275 1.14215483] 0.09304535487260586
+[2022-04-14 20:02:43] - evaluating...
+[2022-04-14 20:03:29] - valid_l1 0.226635, test_l1 0.223652
+[2022-04-14 20:03:29] - valid_dtw 0.715081, test_dtw 0.679969
+[2022-04-14 20:03:29] - Epoch: 16
+[2022-04-14 20:03:29] - training...
+[2022-04-14 21:32:45] - [0.33057161 0.05388648 0.60033638] 0.0606050864674319
+[2022-04-14 21:32:45] - evaluating...
+[2022-04-14 21:33:11] - valid_l1 0.129241, test_l1 0.125267
+[2022-04-14 21:33:11] - valid_dtw 0.392446, test_dtw 0.375572
+[2022-04-14 21:33:11] - Epoch: 56
+[2022-04-14 21:33:11] - training...
+[2022-04-14 21:33:33] - [0.91605368 0.16502166 1.13787426] 0.08876200109384114
+[2022-04-14 21:33:33] - evaluating...
+[2022-04-14 21:33:59] - valid_l1 0.233008, test_l1 0.240251
+[2022-04-14 21:33:59] - valid_dtw 0.691530, test_dtw 0.693584
+[2022-04-14 21:33:59] - Epoch: 17
+[2022-04-14 21:33:59] - training...
+[2022-04-14 21:36:43] - [0.33190315 0.05057661 0.58895525] 0.05942368264541142
+[2022-04-14 21:36:43] - evaluating...
+[2022-04-14 21:37:11] - valid_l1 0.132920, test_l1 0.128123
+[2022-04-14 21:37:11] - valid_dtw 0.402505, test_dtw 0.383316
+[2022-04-14 21:37:11] - Epoch: 57
+[2022-04-14 21:37:11] - training...
+[2022-04-14 21:37:28] - [0.97669585 0.15327369 1.12756217] 0.08508019400690507
+[2022-04-14 21:37:28] - evaluating...
+[2022-04-14 21:37:54] - valid_l1 0.248240, test_l1 0.262332
+[2022-04-14 21:37:54] - valid_dtw 0.715832, test_dtw 0.744597
+[2022-04-14 21:37:54] - Epoch: 18
+[2022-04-14 21:37:54] - training...
+[2022-04-14 21:40:42] - [0.34839672 0.05594777 0.61240111] 0.061308619780535985
+[2022-04-14 21:40:42] - evaluating...
+[2022-04-14 21:41:13] - valid_l1 0.135245, test_l1 0.133213
+[2022-04-14 21:41:13] - valid_dtw 0.408282, test_dtw 0.394383
+[2022-04-14 21:41:13] - Epoch: 58
+[2022-04-14 21:41:13] - training...
+[2022-04-14 21:41:31] - [1.10456238 0.2010834  0.9708474 ] 0.09421624634134815
+[2022-04-14 21:41:31] - evaluating...
+[2022-04-14 21:42:06] - valid_l1 0.218145, test_l1 0.199344
+[2022-04-14 21:42:06] - valid_dtw 0.673551, test_dtw 0.629933
+[2022-04-14 21:42:06] - Epoch: 19
+[2022-04-14 21:42:06] - training...
+[2022-04-14 21:45:37] - [0.34987896 0.05352211 0.59070993] 0.06031086697222147
+[2022-04-14 21:45:37] - evaluating...
+[2022-04-14 21:46:10] - valid_l1 0.129029, test_l1 0.131888
+[2022-04-14 21:46:10] - valid_dtw 0.395319, test_dtw 0.395276
+[2022-04-14 21:46:10] - Epoch: 59
+[2022-04-14 21:46:10] - training...
+[2022-04-14 21:46:24] - [0.73122399 0.08113425 1.01954513] 0.07109661665289922
+[2022-04-14 21:46:24] - evaluating...
+[2022-04-14 21:46:59] - valid_l1 0.290986, test_l1 0.261635
+[2022-04-14 21:46:59] - valid_dtw 0.835292, test_dtw 0.757542
+[2022-04-14 21:46:59] - Epoch: 20
+[2022-04-14 21:46:59] - training...
+[2022-04-14 21:50:36] - [0.3455449  0.05614046 0.57526884] 0.0618901619729691
+[2022-04-14 21:50:36] - evaluating...
+[2022-04-14 21:51:08] - valid_l1 0.142428, test_l1 0.142328
+[2022-04-14 21:51:08] - valid_dtw 0.429325, test_dtw 0.425327
+[2022-04-14 21:51:08] - Epoch: 60
+[2022-04-14 21:51:08] - training...
+[2022-04-14 21:51:14] - [0.9125065  0.11316727 0.94536231] 0.08276465559252223
+[2022-04-14 21:51:14] - evaluating...
+[2022-04-14 21:51:48] - valid_l1 0.166542, test_l1 0.146918
+[2022-04-14 21:51:48] - valid_dtw 0.513823, test_dtw 0.474730
+[2022-04-14 21:51:48] - Epoch: 21
+[2022-04-14 21:51:48] - training...
+[2022-04-14 21:55:29] - [0.32769353 0.05517769 0.53619759] 0.060655774248945984
+[2022-04-14 21:55:29] - evaluating...
+[2022-04-14 21:56:00] - valid_l1 0.145495, test_l1 0.142334
+[2022-04-14 21:56:00] - valid_dtw 0.428303, test_dtw 0.414848
+[2022-04-14 21:56:00] - early stop
+[2022-04-14 21:56:00] - best val score: 0.007295668819255089 @ 0
+[2022-04-14 21:56:00] - inference...
+[2022-04-14 21:56:00] - [0.85157289 0.12023308 1.09251951] 0.08425595585284824
+[2022-04-14 21:56:00] - evaluating...
+[2022-04-14 21:56:25] - MSE: train 0.052433, valid 0.046241, test 0.036272
+[2022-04-14 21:56:25] - L1:  train 0.166819, valid 0.161340, test 0.140448
+[2022-04-14 21:56:25] - RMSE: train 0.198481, valid 0.189093, test 0.166793
+[2022-04-14 21:56:25] - DTW: train 0.487976, valid 0.463299, test 0.403690
+[2022-04-14 21:56:25] - TDI: train 0.361242, valid 0.408494, test 0.451192
+[2022-04-14 21:56:25] - Finished.
+[2022-04-14 21:56:26] - valid_l1 0.232414, test_l1 0.221401
+[2022-04-14 21:56:26] - valid_dtw 0.688603, test_dtw 0.673686
+[2022-04-14 21:56:26] - Epoch: 22
+[2022-04-14 21:56:26] - training...
+[2022-04-14 22:00:07] - [0.92584081 0.10854706 0.9363849 ] 0.07927552396781687
+[2022-04-14 22:00:07] - evaluating...
+[2022-04-14 22:00:35] - valid_l1 0.224236, test_l1 0.209739
+[2022-04-14 22:00:35] - valid_dtw 0.693066, test_dtw 0.649616
+[2022-04-14 22:00:35] - Epoch: 23
+[2022-04-14 22:00:35] - training...
+[2022-04-14 22:04:12] - [0.734982   0.09955385 0.83699275] 0.07623312245858344
+[2022-04-14 22:04:12] - evaluating...
+[2022-04-14 22:04:43] - valid_l1 0.248925, test_l1 0.223382
+[2022-04-14 22:04:43] - valid_dtw 0.722700, test_dtw 0.661156
+[2022-04-14 22:04:43] - Epoch: 24
+[2022-04-14 22:04:43] - training...
+[2022-04-14 22:08:37] - [0.78930078 0.11626686 0.89898792] 0.08146456322751772
+[2022-04-14 22:08:37] - evaluating...
+[2022-04-14 22:09:07] - valid_l1 0.194433, test_l1 0.183014
+[2022-04-14 22:09:07] - valid_dtw 0.580652, test_dtw 0.553880
+[2022-04-14 22:09:07] - Epoch: 25
+[2022-04-14 22:09:07] - training...
+[2022-04-14 22:13:00] - [0.68645654 0.0843025  0.75474164] 0.06935001708623162
+[2022-04-14 22:13:00] - evaluating...
+[2022-04-14 22:13:31] - valid_l1 0.246047, test_l1 0.219231
+[2022-04-14 22:13:31] - valid_dtw 0.704528, test_dtw 0.640792
+[2022-04-14 22:13:31] - Epoch: 26
+[2022-04-14 22:13:31] - training...
+[2022-04-14 22:17:16] - [0.76946667 0.09390811 0.77238434] 0.07275145104000891
+[2022-04-14 22:17:16] - evaluating...
+[2022-04-14 22:17:45] - valid_l1 0.175175, test_l1 0.147298
+[2022-04-14 22:17:45] - valid_dtw 0.532256, test_dtw 0.457529
+[2022-04-14 22:17:45] - Epoch: 27
+[2022-04-14 22:17:45] - training...
+[2022-04-14 22:21:23] - [0.79905227 0.09522876 1.03255737] 0.07508424514750565
+[2022-04-14 22:21:23] - evaluating...
+[2022-04-14 22:21:54] - valid_l1 0.238647, test_l1 0.211622
+[2022-04-14 22:21:54] - valid_dtw 0.682030, test_dtw 0.618981
+[2022-04-14 22:21:54] - Epoch: 28
+[2022-04-14 22:21:54] - training...
+[2022-04-14 22:25:42] - [0.7337294  0.09397531 0.99086528] 0.07669521119109446
+[2022-04-14 22:25:42] - evaluating...
+[2022-04-14 22:26:13] - valid_l1 0.214134, test_l1 0.199768
+[2022-04-14 22:26:13] - valid_dtw 0.617433, test_dtw 0.588070
+[2022-04-14 22:26:13] - Epoch: 29
+[2022-04-14 22:26:13] - training...
+[2022-04-14 22:29:57] - [0.84781306 0.08557247 1.19309178] 0.07046711670893027
+[2022-04-14 22:29:57] - evaluating...
+[2022-04-14 22:30:29] - valid_l1 0.234441, test_l1 0.221278
+[2022-04-14 22:30:29] - valid_dtw 0.665220, test_dtw 0.638307
+[2022-04-14 22:30:29] - Epoch: 30
+[2022-04-14 22:30:29] - training...
+[2022-04-14 22:34:19] - [0.77974081 0.11662349 1.05036719] 0.08152920668734644
+[2022-04-14 22:34:19] - evaluating...
+[2022-04-14 22:34:50] - valid_l1 0.226641, test_l1 0.209735
+[2022-04-14 22:34:50] - valid_dtw 0.647237, test_dtw 0.602220
+[2022-04-14 22:34:50] - Epoch: 31
+[2022-04-14 22:34:50] - training...
+[2022-04-14 22:38:35] - [0.75241726 0.09075847 1.26533883] 0.07370114536549811
+[2022-04-14 22:38:35] - evaluating...
+[2022-04-14 22:39:03] - valid_l1 0.318495, test_l1 0.320479
+[2022-04-14 22:39:03] - valid_dtw 0.863778, test_dtw 0.866418
+[2022-04-14 22:39:03] - Epoch: 32
+[2022-04-14 22:39:03] - training...
+[2022-04-14 22:42:53] - [0.84359633 0.10483762 1.67927596] 0.08116750889842896
+[2022-04-14 22:42:53] - evaluating...
+[2022-04-14 22:43:24] - valid_l1 0.176953, test_l1 0.159947
+[2022-04-14 22:43:24] - valid_dtw 0.536383, test_dtw 0.483541
+[2022-04-14 22:43:24] - Epoch: 33
+[2022-04-14 22:43:24] - training...
+[2022-04-14 22:47:00] - [0.80119122 0.10631579 1.39721773] 0.08250627837430938
+[2022-04-14 22:47:00] - evaluating...
+[2022-04-14 22:47:25] - valid_l1 0.184122, test_l1 0.175644
+[2022-04-14 22:47:25] - valid_dtw 0.565131, test_dtw 0.540991
+[2022-04-14 22:47:25] - Epoch: 34
+[2022-04-14 22:47:25] - training...
+[2022-04-14 23:00:15] - [0.79971869 0.11404292 1.27192947] 0.08325867259216711
+[2022-04-14 23:00:15] - evaluating...
+[2022-04-14 23:00:40] - valid_l1 0.107734, test_l1 0.115619
+[2022-04-14 23:00:40] - valid_dtw 0.365100, test_dtw 0.392476
+[2022-04-14 23:00:40] - Epoch: 35
+[2022-04-14 23:00:40] - training...
+[2022-04-15 00:16:58] - [0.77855234 0.10191431 0.8671241 ] 0.07756406733752193
+[2022-04-15 00:16:58] - evaluating...
+[2022-04-15 00:32:25] - valid_l1 0.143551, test_l1 0.156424
+[2022-04-15 00:32:25] - valid_dtw 0.448742, test_dtw 0.467578
+[2022-04-15 00:32:25] - Epoch: 36
+[2022-04-15 00:32:25] - training...
+[2022-04-15 04:37:05] - [0.75900548 0.10845191 1.04435118] 0.07877282989176368
+[2022-04-15 04:37:05] - evaluating...
+[2022-04-15 05:12:04] - valid_l1 0.166469, test_l1 0.144320
+[2022-04-15 05:12:04] - valid_dtw 0.555943, test_dtw 0.495103
+[2022-04-15 05:12:04] - Epoch: 37
+[2022-04-15 05:12:04] - training...
+[2022-04-15 09:00:01] - [0.75274046 0.10827217 0.92705613] 0.07789819015932263
+[2022-04-15 09:00:01] - evaluating...
+[2022-04-15 09:19:30] - valid_l1 0.176429, test_l1 0.174972
+[2022-04-15 09:19:30] - valid_dtw 0.568777, test_dtw 0.548674
+[2022-04-15 09:19:30] - Epoch: 38
+[2022-04-15 09:19:30] - training...
+[2022-04-15 09:22:42] - [0.73659972 0.10033342 0.75970154] 0.07306006752318682
+[2022-04-15 09:22:42] - evaluating...
+[2022-04-15 09:23:07] - valid_l1 0.184237, test_l1 0.171218
+[2022-04-15 09:23:07] - valid_dtw 0.603683, test_dtw 0.551098
+[2022-04-15 09:23:07] - Epoch: 39
+[2022-04-15 09:23:07] - training...
+[2022-04-15 09:26:19] - [0.66743337 0.07409471 0.83957689] 0.06681254206827485
+[2022-04-15 09:26:19] - evaluating...
+[2022-04-15 09:26:44] - valid_l1 0.157842, test_l1 0.153577
+[2022-04-15 09:26:44] - valid_dtw 0.513973, test_dtw 0.484831
+[2022-04-15 09:26:44] - Epoch: 40
+[2022-04-15 09:26:44] - training...
+[2022-04-15 09:30:00] - [0.64235018 0.07147972 0.75823969] 0.06531164746423412
+[2022-04-15 09:30:00] - evaluating...
+[2022-04-15 09:30:27] - valid_l1 0.200402, test_l1 0.210174
+[2022-04-15 09:30:27] - valid_dtw 0.614652, test_dtw 0.633058
+[2022-04-15 09:30:27] - Epoch: 41
+[2022-04-15 09:30:27] - training...
+[2022-04-15 09:33:47] - [0.69237172 0.068341   0.79111849] 0.06447687794951568
+[2022-04-15 09:33:47] - evaluating...
+[2022-04-15 09:34:13] - valid_l1 0.191997, test_l1 0.183870
+[2022-04-15 09:34:13] - valid_dtw 0.587385, test_dtw 0.573330
+[2022-04-15 09:34:13] - Epoch: 42
+[2022-04-15 09:34:13] - training...
+[2022-04-15 09:37:24] - [0.71732087 0.0755095  1.02688801] 0.07131523702545722
+[2022-04-15 09:37:24] - evaluating...
+[2022-04-15 09:37:50] - valid_l1 0.243131, test_l1 0.221850
+[2022-04-15 09:37:50] - valid_dtw 0.698346, test_dtw 0.647474
+[2022-04-15 09:37:50] - Epoch: 43
+[2022-04-15 09:37:50] - training...
+[2022-04-15 09:41:02] - [0.77176283 0.10139872 0.9720961 ] 0.0767552516640241
+[2022-04-15 09:41:03] - evaluating...
+[2022-04-15 09:41:28] - valid_l1 0.134034, test_l1 0.136984
+[2022-04-15 09:41:28] - valid_dtw 0.421075, test_dtw 0.425600
+[2022-04-15 09:41:28] - Epoch: 44
+[2022-04-15 09:41:28] - training...
+[2022-04-15 09:44:41] - [0.71848649 0.09242096 0.89795518] 0.07699326061244521
+[2022-04-15 09:44:41] - evaluating...
+[2022-04-15 09:45:06] - valid_l1 0.239350, test_l1 0.224202
+[2022-04-15 09:45:06] - valid_dtw 0.691181, test_dtw 0.657915
+[2022-04-15 09:45:06] - Epoch: 45
+[2022-04-15 09:45:06] - training...
+[2022-04-15 09:48:19] - [0.78328275 0.07729711 0.87485947] 0.07137442291119045
+[2022-04-15 09:48:19] - evaluating...
+[2022-04-15 09:48:44] - valid_l1 0.222304, test_l1 0.198939
+[2022-04-15 09:48:44] - valid_dtw 0.632935, test_dtw 0.575277
+[2022-04-15 09:48:44] - Epoch: 46
+[2022-04-15 09:48:44] - training...
+[2022-04-15 09:51:57] - [0.7904707  0.13440416 1.02767693] 0.09106783685659556
+[2022-04-15 09:51:57] - evaluating...
+[2022-04-15 09:52:22] - valid_l1 0.235157, test_l1 0.214520
+[2022-04-15 09:52:22] - valid_dtw 0.693433, test_dtw 0.636828
+[2022-04-15 09:52:22] - Epoch: 47
+[2022-04-15 09:52:22] - training...
+[2022-04-15 09:55:35] - [0.7539623  0.0984479  0.98111918] 0.0765857378833164
+[2022-04-15 09:55:35] - evaluating...
+[2022-04-15 09:56:00] - valid_l1 0.219064, test_l1 0.219365
+[2022-04-15 09:56:00] - valid_dtw 0.669360, test_dtw 0.668648
+[2022-04-15 09:56:00] - Epoch: 48
+[2022-04-15 09:56:00] - training...
+[2022-04-15 09:59:13] - [0.72931953 0.08580734 0.79143842] 0.07775687814963267
+[2022-04-15 09:59:13] - evaluating...
+[2022-04-15 09:59:38] - valid_l1 0.189897, test_l1 0.192590
+[2022-04-15 09:59:38] - valid_dtw 0.567154, test_dtw 0.574789
+[2022-04-15 09:59:38] - Epoch: 49
+[2022-04-15 09:59:38] - training...
+[2022-04-15 10:02:52] - [0.69105926 0.07713907 0.86505277] 0.07209203831039201
+[2022-04-15 10:02:52] - evaluating...
+[2022-04-15 10:03:18] - valid_l1 0.221077, test_l1 0.211590
+[2022-04-15 10:03:18] - valid_dtw 0.657881, test_dtw 0.628052
+[2022-04-15 10:03:18] - Epoch: 50
+[2022-04-15 10:03:18] - training...
+[2022-04-15 10:06:32] - [0.66401456 0.07851708 0.76941299] 0.07052757493955525
+[2022-04-15 10:06:32] - evaluating...
+[2022-04-15 10:06:58] - valid_l1 0.249412, test_l1 0.233921
+[2022-04-15 10:06:58] - valid_dtw 0.708871, test_dtw 0.669708
+[2022-04-15 10:06:58] - Epoch: 51
+[2022-04-15 10:06:58] - training...
+[2022-04-15 10:10:14] - [0.64325587 0.06836614 0.81042247] 0.06708527323614834
+[2022-04-15 10:10:14] - evaluating...
+[2022-04-15 10:10:39] - valid_l1 0.198755, test_l1 0.181082
+[2022-04-15 10:10:39] - valid_dtw 0.584809, test_dtw 0.545643
+[2022-04-15 10:10:39] - Epoch: 52
+[2022-04-15 10:10:39] - training...
+[2022-04-15 10:13:56] - [0.63144484 0.06182172 0.81190766] 0.06367834587406396
+[2022-04-15 10:13:56] - evaluating...
+[2022-04-15 10:14:22] - valid_l1 0.259772, test_l1 0.240414
+[2022-04-15 10:14:22] - valid_dtw 0.738318, test_dtw 0.695116
+[2022-04-15 10:14:22] - Epoch: 53
+[2022-04-15 10:14:22] - training...
+[2022-04-15 10:17:36] - [0.63131182 0.06894469 0.82215283] 0.06805476692218082
+[2022-04-15 10:17:36] - evaluating...
+[2022-04-15 10:18:01] - valid_l1 0.250644, test_l1 0.233315
+[2022-04-15 10:18:01] - valid_dtw 0.696295, test_dtw 0.657641
+[2022-04-15 10:18:01] - Epoch: 54
+[2022-04-15 10:18:01] - training...
+[2022-04-15 10:21:15] - [0.61497645 0.06506463 0.72363193] 0.0654062991751764
+[2022-04-15 10:21:15] - evaluating...
+[2022-04-15 10:21:40] - valid_l1 0.292903, test_l1 0.272748
+[2022-04-15 10:21:40] - valid_dtw 0.796581, test_dtw 0.748784
+[2022-04-15 10:21:40] - Epoch: 55
+[2022-04-15 10:21:40] - training...
+[2022-04-15 10:25:05] - [0.67905381 0.08370283 0.92519857] 0.07100128973168986
+[2022-04-15 10:25:05] - evaluating...
+[2022-04-15 10:25:30] - valid_l1 0.302222, test_l1 0.268797
+[2022-04-15 10:25:30] - valid_dtw 0.843887, test_dtw 0.763807
+[2022-04-15 10:25:30] - Epoch: 56
+[2022-04-15 10:25:30] - training...
+[2022-04-15 10:28:45] - [0.64661279 0.06689626 0.88022136] 0.06704371061904314
+[2022-04-15 10:28:45] - evaluating...
+[2022-04-15 10:29:11] - valid_l1 0.207588, test_l1 0.200376
+[2022-04-15 10:29:11] - valid_dtw 0.609288, test_dtw 0.585074
+[2022-04-15 10:29:11] - Epoch: 57
+[2022-04-15 10:29:11] - training...
+[2022-04-15 10:32:30] - [0.69744484 0.08871304 0.84754536] 0.07522195578181654
+[2022-04-15 10:32:30] - evaluating...
+[2022-04-15 10:32:57] - valid_l1 0.232818, test_l1 0.202676
+[2022-04-15 10:32:57] - valid_dtw 0.673808, test_dtw 0.599241
+[2022-04-15 10:32:57] - Epoch: 58
+[2022-04-15 10:32:57] - training...
+[2022-04-15 10:36:21] - [0.70379358 0.08151411 0.87093169] 0.07645656363968563
+[2022-04-15 10:36:21] - evaluating...
+[2022-04-15 10:36:46] - valid_l1 0.255862, test_l1 0.239519
+[2022-04-15 10:36:46] - valid_dtw 0.733232, test_dtw 0.684925
+[2022-04-15 10:36:46] - Epoch: 59
+[2022-04-15 10:36:46] - training...
+[2022-04-15 10:40:02] - [0.68767446 0.07371202 0.81068754] 0.07042822736014324
+[2022-04-15 10:40:02] - evaluating...
+[2022-04-15 10:40:28] - valid_l1 0.267537, test_l1 0.245576
+[2022-04-15 10:40:28] - valid_dtw 0.744232, test_dtw 0.684508
+[2022-04-15 10:40:28] - Epoch: 60
+[2022-04-15 10:40:28] - training...
+[2022-04-15 10:43:50] - [0.6453411 0.0698076 0.7344334] 0.0701852513687279
+[2022-04-15 10:43:50] - evaluating...
+[2022-04-15 10:44:16] - valid_l1 0.265218, test_l1 0.237901
+[2022-04-15 10:44:16] - valid_dtw 0.739597, test_dtw 0.672846
+[2022-04-15 10:44:16] - Epoch: 61
+[2022-04-15 10:44:16] - training...
+[2022-04-15 10:47:38] - [0.62298778 0.06698822 0.68882502] 0.06836851852056676
+[2022-04-15 10:47:38] - evaluating...
+[2022-04-15 10:48:05] - valid_l1 0.248184, test_l1 0.227060
+[2022-04-15 10:48:05] - valid_dtw 0.701851, test_dtw 0.642505
+[2022-04-15 10:48:05] - Epoch: 62
+[2022-04-15 10:48:05] - training...
+[2022-04-15 10:51:27] - [0.60270999 0.06397298 0.66627267] 0.0650719606156524
+[2022-04-15 10:51:27] - evaluating...
+[2022-04-15 10:51:52] - valid_l1 0.287838, test_l1 0.253862
+[2022-04-15 10:51:52] - valid_dtw 0.814860, test_dtw 0.728347
+[2022-04-15 10:51:52] - Epoch: 63
+[2022-04-15 10:51:52] - training...
+[2022-04-15 10:55:12] - [0.57729331 0.06341114 0.70847863] 0.06487038182304766
+[2022-04-15 10:55:12] - evaluating...
+[2022-04-15 10:55:38] - valid_l1 0.237215, test_l1 0.225659
+[2022-04-15 10:55:38] - valid_dtw 0.666987, test_dtw 0.641379
+[2022-04-15 10:55:38] - Epoch: 64
+[2022-04-15 10:55:38] - training...
+[2022-04-15 10:58:53] - [0.60212288 0.07095115 0.65777924] 0.0705039149752461
+[2022-04-15 10:58:54] - evaluating...
+[2022-04-15 10:59:19] - valid_l1 0.289285, test_l1 0.265661
+[2022-04-15 10:59:19] - valid_dtw 0.797124, test_dtw 0.741405
+[2022-04-15 10:59:19] - Epoch: 65
+[2022-04-15 10:59:19] - training...
+[2022-04-15 11:02:35] - [0.58759178 0.06289728 0.66023364] 0.06501440295487418
+[2022-04-15 11:02:35] - evaluating...
+[2022-04-15 11:03:00] - valid_l1 0.223215, test_l1 0.207177
+[2022-04-15 11:03:00] - valid_dtw 0.635763, test_dtw 0.603662
+[2022-04-15 11:03:00] - Epoch: 66
+[2022-04-15 11:03:00] - training...
+[2022-04-15 11:06:15] - [0.59177817 0.06744702 0.65172253] 0.06615980810352734
+[2022-04-15 11:06:15] - evaluating...
+[2022-04-15 11:06:40] - valid_l1 0.256061, test_l1 0.246629
+[2022-04-15 11:06:40] - valid_dtw 0.735570, test_dtw 0.714037
+[2022-04-15 11:06:40] - Epoch: 67
+[2022-04-15 11:06:40] - training...
+[2022-04-15 11:09:55] - [0.54783848 0.05961118 0.58932102] 0.06397842326222505
+[2022-04-15 11:09:55] - evaluating...
+[2022-04-15 11:10:20] - valid_l1 0.220512, test_l1 0.203179
+[2022-04-15 11:10:20] - valid_dtw 0.628400, test_dtw 0.581915
+[2022-04-15 11:10:20] - Epoch: 68
+[2022-04-15 11:10:20] - training...
+[2022-04-15 11:13:34] - [0.57054216 0.06660006 0.62726683] 0.06848046858619927
+[2022-04-15 11:13:35] - evaluating...
+[2022-04-15 11:14:00] - valid_l1 0.203774, test_l1 0.187750
+[2022-04-15 11:14:00] - valid_dtw 0.589712, test_dtw 0.553641
+[2022-04-15 11:14:00] - Epoch: 69
+[2022-04-15 11:14:00] - training...
+[2022-04-15 11:17:14] - [0.66512804 0.10376948 0.65277101] 0.08088085585714955
+[2022-04-15 11:17:14] - evaluating...
+[2022-04-15 11:17:39] - valid_l1 0.235771, test_l1 0.221141
+[2022-04-15 11:17:39] - valid_dtw 0.680394, test_dtw 0.640873
+[2022-04-15 11:17:39] - Epoch: 70
+[2022-04-15 11:17:39] - training...
+[2022-04-15 11:20:54] - [0.57598353 0.06148645 0.57788085] 0.06382528927345249
+[2022-04-15 11:20:54] - evaluating...
+[2022-04-15 11:21:19] - valid_l1 0.224797, test_l1 0.211099
+[2022-04-15 11:21:19] - valid_dtw 0.644618, test_dtw 0.605082
+[2022-04-15 11:21:19] - Epoch: 71
+[2022-04-15 11:21:19] - training...
+[2022-04-15 11:24:34] - [0.61927076 0.07869794 0.66113218] 0.07150410150030725
+[2022-04-15 11:24:34] - evaluating...
+[2022-04-15 11:24:59] - valid_l1 0.228550, test_l1 0.218182
+[2022-04-15 11:24:59] - valid_dtw 0.668985, test_dtw 0.647456
+[2022-04-15 11:24:59] - Epoch: 72
+[2022-04-15 11:24:59] - training...
+[2022-04-15 11:28:14] - [0.53326426 0.05802364 0.59131143] 0.06317022952034061
+[2022-04-15 11:28:14] - evaluating...
+[2022-04-15 11:28:39] - valid_l1 0.253245, test_l1 0.243838
+[2022-04-15 11:28:39] - valid_dtw 0.711992, test_dtw 0.684079
+[2022-04-15 11:28:39] - Epoch: 73
+[2022-04-15 11:28:39] - training...
+[2022-04-15 11:31:54] - [0.58122277 0.06314503 0.53807159] 0.06426045576292545
+[2022-04-15 11:31:54] - evaluating...
+[2022-04-15 11:32:19] - valid_l1 0.234852, test_l1 0.220851
+[2022-04-15 11:32:19] - valid_dtw 0.692238, test_dtw 0.656180
+[2022-04-15 11:32:19] - Epoch: 74
+[2022-04-15 11:32:19] - training...
+[2022-04-15 11:35:34] - [0.6057671  0.06072879 0.55457118] 0.06271663967772086
+[2022-04-15 11:35:34] - evaluating...
+[2022-04-15 11:35:59] - valid_l1 0.268280, test_l1 0.239738
+[2022-04-15 11:35:59] - valid_dtw 0.760473, test_dtw 0.683369
+[2022-04-15 11:35:59] - Epoch: 75
+[2022-04-15 11:35:59] - training...
+[2022-04-15 11:39:14] - [0.55072975 0.05389166 0.52225755] 0.060752619478039276
+[2022-04-15 11:39:14] - evaluating...
+[2022-04-15 11:39:39] - valid_l1 0.212626, test_l1 0.182344
+[2022-04-15 11:39:39] - valid_dtw 0.629212, test_dtw 0.542371
+[2022-04-15 11:39:39] - Epoch: 76
+[2022-04-15 11:39:39] - training...
+[2022-04-15 11:42:54] - [0.54671595 0.05516559 0.54383608] 0.06092381140819394
+[2022-04-15 11:42:54] - evaluating...
+[2022-04-15 11:43:19] - valid_l1 0.236613, test_l1 0.215171
+[2022-04-15 11:43:19] - valid_dtw 0.701412, test_dtw 0.639223
+[2022-04-15 11:43:19] - Epoch: 77
+[2022-04-15 11:43:19] - training...
+[2022-04-15 11:46:33] - [0.5673085  0.06163686 0.57660278] 0.06591913601229514
+[2022-04-15 11:46:33] - evaluating...
+[2022-04-15 11:46:59] - valid_l1 0.204211, test_l1 0.172124
+[2022-04-15 11:46:59] - valid_dtw 0.637790, test_dtw 0.539186
+[2022-04-15 11:46:59] - Epoch: 78
+[2022-04-15 11:46:59] - training...
+[2022-04-15 11:50:13] - [0.58410489 0.05851338 0.58014603] 0.06443178853986406
+[2022-04-15 11:50:13] - evaluating...
+[2022-04-15 11:50:38] - valid_l1 0.262642, test_l1 0.248711
+[2022-04-15 11:50:38] - valid_dtw 0.758250, test_dtw 0.712975
+[2022-04-15 11:50:38] - Epoch: 79
+[2022-04-15 11:50:38] - training...
+[2022-04-15 11:53:53] - [0.60532031 0.06322117 0.55418956] 0.06698870107503538
+[2022-04-15 11:53:53] - evaluating...
+[2022-04-15 11:54:19] - valid_l1 0.203064, test_l1 0.171739
+[2022-04-15 11:54:19] - valid_dtw 0.584497, test_dtw 0.508243
+[2022-04-15 11:54:19] - Epoch: 80
+[2022-04-15 11:54:19] - training...
+[2022-04-15 11:57:33] - [0.58996653 0.06695876 0.51513024] 0.06739185249671004
+[2022-04-15 11:57:33] - evaluating...
+[2022-04-15 11:57:59] - valid_l1 0.241495, test_l1 0.221444
+[2022-04-15 11:57:59] - valid_dtw 0.703864, test_dtw 0.649897
+[2022-04-15 11:57:59] - Epoch: 81
+[2022-04-15 11:57:59] - training...
+[2022-04-15 12:01:13] - [0.54888234 0.05867565 0.49546992] 0.06600315057693568
+[2022-04-15 12:01:13] - evaluating...
+[2022-04-15 12:01:39] - valid_l1 0.228916, test_l1 0.209379
+[2022-04-15 12:01:39] - valid_dtw 0.649179, test_dtw 0.595195
+[2022-04-15 12:01:39] - Epoch: 82
+[2022-04-15 12:01:39] - training...
+[2022-04-15 12:04:53] - [0.57547343 0.06609192 0.49191901] 0.0660930464912514
+[2022-04-15 12:04:54] - evaluating...
+[2022-04-15 12:05:19] - valid_l1 0.215624, test_l1 0.204050
+[2022-04-15 12:05:19] - valid_dtw 0.632751, test_dtw 0.599320
+[2022-04-15 12:05:19] - Epoch: 83
+[2022-04-15 12:05:19] - training...
+[2022-04-15 12:08:34] - [0.56084119 0.06631614 0.47351674] 0.06748072325315019
+[2022-04-15 12:08:34] - evaluating...
+[2022-04-15 12:08:59] - valid_l1 0.248148, test_l1 0.232973
+[2022-04-15 12:08:59] - valid_dtw 0.719840, test_dtw 0.671945
+[2022-04-15 12:08:59] - Epoch: 84
+[2022-04-15 12:08:59] - training...
+[2022-04-15 12:12:14] - [0.60976765 0.06828171 0.5019771 ] 0.068801223853589
+[2022-04-15 12:12:14] - evaluating...
+[2022-04-15 12:12:40] - valid_l1 0.210292, test_l1 0.176277
+[2022-04-15 12:12:40] - valid_dtw 0.610759, test_dtw 0.512545
+[2022-04-15 12:12:40] - Epoch: 85
+[2022-04-15 12:12:40] - training...
+[2022-04-15 12:15:55] - [0.53481966 0.05369441 0.49695019] 0.061017787118995546
+[2022-04-15 12:15:55] - evaluating...
+[2022-04-15 12:16:20] - valid_l1 0.206910, test_l1 0.197705
+[2022-04-15 12:16:20] - valid_dtw 0.627838, test_dtw 0.588965
+[2022-04-15 12:16:20] - Epoch: 86
+[2022-04-15 12:16:20] - training...
+[2022-04-15 12:19:34] - [0.54789009 0.0628489  0.50648002] 0.06496636429171365
+[2022-04-15 12:19:35] - evaluating...
+[2022-04-15 12:20:00] - valid_l1 0.204743, test_l1 0.192761
+[2022-04-15 12:20:00] - valid_dtw 0.621093, test_dtw 0.589543
+[2022-04-15 12:20:00] - Epoch: 87
+[2022-04-15 12:20:00] - training...
+[2022-04-15 12:23:14] - [0.57047567 0.07970783 0.47613504] 0.07260762275357667
+[2022-04-15 12:23:15] - evaluating...
+[2022-04-15 12:23:40] - valid_l1 0.255590, test_l1 0.237454
+[2022-04-15 12:23:40] - valid_dtw 0.768230, test_dtw 0.721328
+[2022-04-15 12:23:40] - Epoch: 88
+[2022-04-15 12:23:40] - training...
+[2022-04-15 12:26:54] - [0.52201815 0.05563942 0.50506989] 0.06139012045486081
+[2022-04-15 12:26:54] - evaluating...
+[2022-04-15 12:27:21] - valid_l1 0.197842, test_l1 0.174876
+[2022-04-15 12:27:21] - valid_dtw 0.612210, test_dtw 0.539114
+[2022-04-15 12:27:21] - Epoch: 89
+[2022-04-15 12:27:21] - training...
+[2022-04-15 12:30:47] - [0.56042378 0.06944895 0.47298523] 0.06685611190820547
+[2022-04-15 12:30:47] - evaluating...
+[2022-04-15 12:31:12] - valid_l1 0.191068, test_l1 0.174477
+[2022-04-15 12:31:12] - valid_dtw 0.599916, test_dtw 0.539370
+[2022-04-15 12:31:12] - Epoch: 90
+[2022-04-15 12:31:12] - training...
+[2022-04-15 12:34:29] - [0.57816096 0.06579124 0.45829025] 0.06667215915158727
+[2022-04-15 12:34:29] - evaluating...
+[2022-04-15 12:34:54] - valid_l1 0.216461, test_l1 0.202513
+[2022-04-15 12:34:54] - valid_dtw 0.648012, test_dtw 0.599739
+[2022-04-15 12:34:54] - Epoch: 91
+[2022-04-15 12:34:54] - training...
+[2022-04-15 12:38:11] - [0.53776542 0.05557229 0.43801009] 0.06004579190753008
+[2022-04-15 12:38:11] - evaluating...
+[2022-04-15 12:38:36] - valid_l1 0.210691, test_l1 0.199510
+[2022-04-15 12:38:36] - valid_dtw 0.653756, test_dtw 0.609325
+[2022-04-15 12:38:36] - Epoch: 92
+[2022-04-15 12:38:36] - training...
+[2022-04-15 12:41:53] - [0.55847776 0.05870867 0.48386077] 0.06267057989857026
+[2022-04-15 12:41:53] - evaluating...
+[2022-04-15 12:42:18] - valid_l1 0.198360, test_l1 0.190699
+[2022-04-15 12:42:18] - valid_dtw 0.622119, test_dtw 0.595180
+[2022-04-15 12:42:18] - Epoch: 93
+[2022-04-15 12:42:18] - training...
+[2022-04-15 12:45:35] - [0.59894665 0.08015695 0.51713856] 0.07163905763396419
+[2022-04-15 12:45:35] - evaluating...
+[2022-04-15 12:46:01] - valid_l1 0.227886, test_l1 0.203473
+[2022-04-15 12:46:01] - valid_dtw 0.660605, test_dtw 0.600354
+[2022-04-15 12:46:01] - Epoch: 94
+[2022-04-15 12:46:01] - training...
+[2022-04-15 12:49:18] - [0.55263746 0.05621559 0.46736337] 0.06162359486369038
+[2022-04-15 12:49:18] - evaluating...
+[2022-04-15 12:49:43] - valid_l1 0.211025, test_l1 0.189918
+[2022-04-15 12:49:43] - valid_dtw 0.632949, test_dtw 0.574285
+[2022-04-15 12:49:43] - early stop
+[2022-04-15 12:49:43] - best val score: 0.02672626548332208 @ 34
+[2022-04-15 12:49:43] - inference...
+[2022-04-15 12:50:08] - MSE: train 0.040903, valid 0.028401, test 0.034764
+[2022-04-15 12:50:08] - L1:  train 0.136351, valid 0.113287, test 0.125127
+[2022-04-15 12:50:08] - RMSE: train 0.176770, valid 0.147246, test 0.160741
+[2022-04-15 12:50:08] - DTW: train 0.451367, valid 0.375987, test 0.410479
+[2022-04-15 12:50:08] - TDI: train 0.024758, valid 0.013938, test 0.013050
+[2022-04-15 12:50:08] - Finished.
Index: run.log
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>[2022-04-08 18:39:34] - create loaders...\n[2022-04-08 23:41:58] - create loaders...\n[2022-04-09 11:28:26] - create loaders...\n[2022-04-09 11:31:32] - create loaders...\n[2022-04-09 12:41:18] - create loaders...\n[2022-04-09 14:04:09] - create loaders...\n[2022-04-09 14:18:38] - create loaders...\n[2022-04-09 14:19:13] - create loaders...\n[2022-04-09 14:24:42] - create loaders...\n[2022-04-09 14:26:33] - create loaders...\n[2022-04-09 14:27:54] - create loaders...\n[2022-04-09 14:31:56] - create loaders...\n[2022-04-09 14:36:35] - create loaders...\n[2022-04-09 15:12:17] - create loaders...\n[2022-04-09 17:52:56] - create loaders...\n[2022-04-09 17:54:30] - create loaders...\n[2022-04-09 19:06:53] - create loaders...\n[2022-04-09 19:06:56] - create loaders...\n[2022-04-09 19:16:45] - create loaders...\n[2022-04-09 19:16:47] - create loaders...\n[2022-04-09 19:16:49] - create loaders...\n[2022-04-09 19:18:59] - create loaders...\n[2022-04-09 19:19:00] - create loaders...\n[2022-04-09 19:19:01] - create loaders...\n[2022-04-09 20:09:36] - create loaders...\n[2022-04-09 20:18:23] - create loaders...\n[2022-04-09 20:20:56] - create loaders...\n[2022-04-09 21:50:47] - create loaders...\n[2022-04-09 23:56:37] - create loaders...\n[2022-04-09 23:57:15] - create loaders...\n[2022-04-10 15:12:01] - create loaders...\n[2022-04-12 14:56:06] - create loaders...\n[2022-04-12 15:01:46] - create loaders...\n[2022-04-12 15:02:11] - create loaders...\n[2022-04-12 15:02:46] - create loaders...\n[2022-04-12 15:11:51] - create loaders...\n[2022-04-12 15:19:49] - create loaders...\n[2022-04-12 15:23:47] - create loaders...\n[2022-04-12 15:24:27] - create loaders...\n[2022-04-12 15:24:51] - create loaders...\n[2022-04-12 15:26:40] - create loaders...\n[2022-04-12 15:28:43] - create loaders...\n[2022-04-12 15:30:24] - create loaders...\n[2022-04-12 15:31:14] - create loaders...\n[2022-04-12 15:32:46] - create loaders...\n[2022-04-12 15:34:42] - create loaders...\n[2022-04-12 15:34:49] - create loaders...\n[2022-04-12 15:48:17] - create loaders...\n[2022-04-12 15:52:00] - create loaders...\n[2022-04-12 15:52:14] - create loaders...\n[2022-04-12 15:52:47] - create loaders...\n[2022-04-12 15:52:56] - create loaders...\n[2022-04-12 15:53:45] - create loaders...\n[2022-04-12 16:16:47] - create loaders...\n[2022-04-12 16:17:01] - create loaders...\n[2022-04-12 16:19:22] - create loaders...\n[2022-04-12 16:26:37] - create loaders...\n[2022-04-12 16:46:25] - create loaders...\n[2022-04-12 16:48:37] - create loaders...\n[2022-04-12 16:50:50] - create loaders...\n[2022-04-12 16:53:29] - create loaders...\n[2022-04-12 16:56:24] - create loaders...\n[2022-04-12 16:56:45] - create loaders...\n[2022-04-12 17:01:00] - create loaders...\n[2022-04-12 20:54:38] - create loaders...\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/run.log b/run.log
--- a/run.log	(revision 4d374eb052e73a15d49eb92596cef4473d6d2218)
+++ b/run.log	(date 1649934016950)
@@ -63,3 +63,23 @@
 [2022-04-12 16:56:45] - create loaders...
 [2022-04-12 17:01:00] - create loaders...
 [2022-04-12 20:54:38] - create loaders...
+[2022-04-13 14:33:12] - create loaders...
+[2022-04-13 16:14:56] - create loaders...
+[2022-04-13 17:36:04] - create loaders...
+[2022-04-13 20:24:30] - create loaders...
+[2022-04-14 10:02:57] - create loaders...
+[2022-04-14 10:04:38] - create loaders...
+[2022-04-14 10:07:37] - create loaders...
+[2022-04-14 10:09:07] - create loaders...
+[2022-04-14 12:13:56] - create loaders...
+[2022-04-14 12:14:42] - create loaders...
+[2022-04-14 13:46:34] - create loaders...
+[2022-04-14 15:06:40] - create loaders...
+[2022-04-14 15:22:44] - create loaders...
+[2022-04-14 15:24:35] - create loaders...
+[2022-04-14 15:27:05] - create loaders...
+[2022-04-14 15:33:29] - create loaders...
+[2022-04-14 15:42:45] - create loaders...
+[2022-04-14 16:14:40] - create loaders...
+[2022-04-14 16:33:11] - create loaders...
+[2022-04-14 19:00:16] - create loaders...
Index: weather_traintro.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#!/usr/bin/python3.6\n# -*- coding: utf-8 -*-\n#\n# Copyright (C) 2022 Apple, Inc. All Rights Reserved \n#\n# @Time    : 2022/3/28 21:14\n# @Author  : SeptKing\n# @Email   : WJH0923@mail.dlut.edu.cn\n# @File    : weather_train.py\n# @Software: PyCharm\nimport torch.nn as nn\nimport torch\nimport torch.optim as optim\nfrom tslearn.metrics import dtw, dtw_path\nimport os\nimport argparse\nimport datetime\nimport numpy as np\nfrom loss import Dilate_loss\nfrom tqdm import tqdm\nfrom untils import utils\nfrom model_Sept.Dual_Adarnn import Dual_Adarnn, Cross_Attention, Decoder, Share_Encoder\nimport weather_data.data_TEM_test as data_process\nimport matplotlib.pyplot as plt\nfrom untils.support import *\nfrom d2l import torch as d2l\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndef pprint(*text):\n    # print with UTC+8 time\n    time = '['+str(datetime.datetime.utcnow() +\n                   datetime.timedelta(hours=8))[:19]+'] -'\n    print(time, *text, flush=True)\n    if args.log_file is None:\n        return\n    with open(args.log_file, 'a') as f:\n        print(time, *text, flush=True, file=f)\n\ndef get_model(name='DualAdarnn'):\n    n_hiddens = [args.hidden_size for i in range(args.num_layers)]\n    share_encoder = Share_Encoder( n_input=args.d_feat, n_hiddens = n_hiddens,dec_layers=args.dec_layers, dropout=args.dropout,model_type=args.model_name,\n                          len_seq=args.len_seq, trans_loss=args.loss_type)\n    cross_attention = Cross_Attention(n_hiddens=n_hiddens)\n    decoder = Decoder(output_dim=args.class_num, n_hiddens=n_hiddens,dec_layers=args.dec_layers, dropout=args.dropout, attention=cross_attention)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    return Dual_Adarnn(share_encoder=share_encoder, decoder=decoder,output_dim=args.class_num, len_seq=args.len_seq, device=device).to(device)\n\ndef train_DualRNN(args, model_king, optimizer, train_loader_list, epoch, teacher_forcing_ratio, alpha, beta, dist_old_before = None, dist_old_after = None, weight_mat_before=None, weight_mat_after=None):\n    model_king.train()\n    criterion = nn.MSELoss()  ##代价函数\n    criterion_1 = nn.L1Loss()  ##代价函数\n    loss_all = []\n    loss_1_all = []\n    dist_mat_before = torch.zeros(args.num_layers, args.len_seq).to(device)  ##[1，10列]\n    dist_mat_after = torch.zeros(args.num_layers, args.len_seq).to(device)\n    len_loader = np.inf\n    for loader in train_loader_list:\n        if len(loader) < len_loader:\n            len_loader = len(loader)\n\n    for data_all in tqdm(zip(*train_loader_list), total=len_loader):##按照batch加载数据，data_all表示的是分段的时间序列\n        optimizer.zero_grad()\n        list_feat_left = []\n        list_feat_right = []\n        list_ytrue = []  ##用的是0，1编码\n\n        for data in data_all:##data——all也是个list\n            fea_left, fea_right, yture = data[0].to(device).float(\n            ), data[1].to(device).float(), data[2].to(device)\n            list_feat_left.append(fea_left)  ##两个tensor\n            list_feat_right.append(fea_right)\n            list_ytrue.append(yture)\n        flag = False\n\n\n        index = get_index(len(data_all)-1)\n\n        for temp_index in index:\n            s1 = temp_index[0]\n            s2 = temp_index[1]\n            if list_feat_left[s1].shape[0] != list_feat_right[s2].shape[0]:\n                flag = True\n                break\n        if flag:\n            continue\n        # out_weight_list_before = []\n        total_loss = torch.zeros(1).to(device)\n\n        for i in range(len(index)):\n            feature_s_left = list_feat_left[index[i][0]]\n            feature_t_left = list_feat_left[index[i][1]]\n            feature_s_right = list_feat_right[index[i][0]]\n            feature_t_right = list_feat_right[index[i][0]]\n            ytrue_s = list_ytrue[index[i][1]]\n            ytrue_t = list_ytrue[index[i][1]]\n            feature_all_left = torch.cat((feature_s_left,feature_t_left), 0)\n            feature_all_right = torch.cat((feature_s_right,feature_t_right),0)\n            feature_all_left = feature_all_left.permute(1,0,2)##10，2，16\n            feature_all_right = feature_all_right.permute(1,0,2)## 10，2，16\n            ytrue_all = torch.cat((ytrue_s,ytrue_t),0)\n            ytrue_all = ytrue_all.permute(1,0,2)##6，2，1\n            # print(feature_all_left.size())\n            # print(feature_all_right.size())\n\n            if epoch < args.pre_epoch:\n                pred_s, pred_t,out_weight_list_before,out_weight_list_after,decoder_att,loss_transfer = model_king.for_custom_pre(\n                    feature_all_left,feature_all_right,ytrue_all,teacher_forcing_ratio )\n\n\n            else:\n                pred_s, pred_t,decoder_att, loss_transfer, dist_before,dist_after,weight_mat_before,weight_mat_after = model_king.for_Boosting(\n                    feature_all_left,feature_all_right,ytrue_all,teacher_forcing_ratio ,weight_mat_before ,weight_mat_after)\n                dist_mat_before = dist_mat_before + dist_before\n                dist_mat_after = dist_mat_after + dist_after\n\n            loss_s = criterion(pred_s, ytrue_s)\n            loss_t = criterion(pred_t, ytrue_t)\n            loss_l1 = criterion_1(pred_s, ytrue_s)\n            Loss_s, loss_shape_s, loss_temporal_s = Dilate_loss.dilate_loss(\n                ytrue_s,pred_s, alpha,beta, device)  ##在这里第一个是真实，第二个是预测\n            Loss_t, loss_shape_t, loss_temporal_t = Dilate_loss.dilate_loss(\n                ytrue_t,pred_t, alpha,beta, device)  ##在这里第一个是真实，第二个是预测\n\n            total_loss = total_loss + Loss_s +Loss_t+ args.dw * loss_transfer\n        # print(\"@\", out_weight_list_before)\n        loss_all.append(\n            [total_loss.item(), (Loss_s+Loss_t).item(),loss_transfer.item()])\n        loss_1_all.append(loss_l1.item())\n        optimizer.zero_grad()\n        total_loss.backward()\n        torch.nn.utils.clip_grad_value_(model_king.parameters(), 3.)\n        optimizer.step()\n    loss = np.array(loss_all).mean(axis=0)\n    loss_l1 = np.array(loss_1_all).mean(axis=0)\n    if epoch >=args.pre_epoch:\n        if epoch > args.pre_epoch:\n            weight_mat_before, weight_mat_after = model_king.update_weight_Boosting(\n                    weight_mat_before,dist_old_before,dist_mat_before,weight_mat_after,dist_old_after,dist_mat_after)\n\n        return loss, loss_l1, weight_mat_before, weight_mat_after, dist_mat_before, dist_mat_after\n\n    else:\n        weight_mat_before = transform_type(out_weight_list_before)\n        weight_mat_after = transform_type(out_weight_list_after)\n        return loss, loss_l1, weight_mat_before, weight_mat_after, None, None\n\n\ndef train_epoch_transfer_Boosting(model, optimizer, train_loader_list, epoch, teacher_forcing_ratio,alpha,beta, dist_old_before = None, dist_old_after = None, weight_mat_before=None, weight_mat_after=None):\n    model.train()\n    criterion = nn.MSELoss()  ##代价函数\n    criterion_1 = nn.L1Loss()  ##代价函数\n    loss_all = []\n    loss_1_all = []\n    dist_mat_before = torch.zeros(args.num_layers, args.len_seq).to(device)  ##[两行，24列]\n    dist_mat_after = torch.zeros(args.num_layers, args.len_seq).to(device)\n    len_loader = np.inf\n    for loader in train_loader_list:\n        if len(loader) < len_loader:\n            len_loader = len(loader)\n    for data_all in tqdm(zip(*train_loader_list), total=len_loader):\n        optimizer.zero_grad()\n        list_feat_left = []\n        list_feat_right = []\n        list_ytrue = []  ##用的是0，1编码\n\n        for data in data_all:\n            fea_left, fea_right, yture = data[0].to(device).float(\n            ), data[1].to(device).float(), data[2].to(device)\n            list_feat_left.append(fea_left)  ##两个tensor\n            list_feat_right.append(fea_right)\n            list_ytrue.append(yture)\n        flag = False\n        index = get_index(len(data_all)-1)\n\n        for temp_index in index:\n            s1 = temp_index[0]\n            s2 = temp_index[1]\n            if list_feat_left[s1].shape[0] != list_feat_right[s2].shape[0]:\n                flag = True\n                break\n        if flag:\n            continue\n\n        total_loss = torch.zeros(1).to(device)\n        for i in range(len(index)):\n            feature_s_left = list_feat_left[index[i][0]]\n            feature_t_left = list_feat_left[index[i][1]]\n            feature_s_right = list_feat_right[index[i][0]]\n            feature_t_right = list_feat_right[index[i][0]]\n            ytrue_s = list_ytrue[index[i][1]]\n            ytrue_t = list_ytrue[index[i][1]]\n            feature_all_left = torch.cat((feature_s_left, feature_t_left), 0)\n            feature_all_right = torch.cat((feature_s_right, feature_t_right), 0)\n            feature_all_left = feature_all_left.permute(1, 0, 2)\n            feature_all_right = feature_all_right.permute(1, 0, 2)\n            ytrue_all = torch.cat((ytrue_s, ytrue_t), 0)\n            ytrue_all = ytrue_all.permute(1, 0, 2)\n\n            pred_s, pred_t, decoder_att, loss_transfer, dist_before, \\\n            dist_after, weight_mat_before, weight_mat_after = model.for_Boosting(\n                feature_all_left, feature_all_right, ytrue_all, teacher_forcing_ratio,\n                weight_mat_before, weight_mat_after)\n            dist_mat_before = dist_mat_before + dist_before\n            dist_mat_after = dist_mat_after + dist_after\n\n            loss_s = criterion(pred_s, ytrue_s)\n            loss_t = criterion(pred_t, ytrue_t)\n            loss_l1 = criterion_1(pred_s, ytrue_s)\n            Loss_s, loss_shape_s, loss_temporal_s = Dilate_loss.dilate_loss(\n                pred_s, ytrue_s, alpha,beta, device)  ##在这里第一个是真实，第二个是预测\n            Loss_t, loss_shape_t, loss_temporal_t = Dilate_loss.dilate_loss(\n                pred_t, ytrue_t,alpha,beta, device)  ##在这里第一个是真实，第二个是预测\n\n            total_loss = total_loss + Loss_s + Loss_t + args.dw * loss_transfer\n        loss_all.append([total_loss.item(), (Loss_s + Loss_t).item(), loss_transfer.item()])\n        loss_1_all.append(loss_l1.item())\n        optimizer.zero_grad()\n        total_loss.backward()\n        torch.nn.utils.clip_grad_value_(model.parameters(), 3.)\n        optimizer.step()\n    loss = np.array(loss_all).mean(axis=0)\n    loss_l1 = np.array(loss_1_all).mean(axis=0)\n    if epoch > 0:\n        weight_mat_before, weight_mat_after = model.update_weight_Boosting(\n                weight_mat_before, dist_old_before, dist_mat_before, weight_mat_after, dist_old_after, dist_mat_after)\n\n    return loss, loss_l1, weight_mat_before, weight_mat_after, dist_mat_before, dist_mat_after\n\n\ndef get_index(num_domain=2):\n    index = []\n    for i in range(num_domain):\n        for j in range(i + 1, num_domain + 1):\n            index.append((i, j))\n    return index\n\n\ndef train_epoch_transfer(args, model, optimizer, train_loader_list,alpha,beta,teacher_forcing_ratio):\n    model.train()\n    criterion = nn.MSELoss()  ##代价函数\n    criterion_1 = nn.L1Loss()  ##代价函数\n    loss_all = []\n    loss_1_all = []\n    dist_mat_before = torch.zeros(args.num_layers, args.len_seq).to(device)  ##[两行，24列]\n    dist_mat_after = torch.zeros(args.num_layers, args.len_seq).to(device)\n    len_loader = np.inf\n    for loader in train_loader_list:\n        if len(loader) < len_loader:\n            len_loader = len(loader)\n    for data_all in tqdm(zip(*train_loader_list), total=len_loader):\n        optimizer.zero_grad()\n        list_feat_left = []\n        list_feat_right = []\n        list_ytrue = []  ##用的是0，1编码\n\n        for data in data_all:\n            fea_left, fea_right, yture = data[0].to(device).float(\n            ), data[1].to(device).float(), data[2].to(device)\n            list_feat_left.append(fea_left)  ##两个tensor\n            list_feat_right.append(fea_right)\n            list_ytrue.append(yture)\n            print(fea_left)\n        flag = False\n        index = get_index(len(data_all - 1))\n\n        for temp_index in index:\n            s1 = temp_index[0]\n            s2 = temp_index[1]\n            if list_feat_left[s1].shape[0] != list_feat_right[s2].shape[0]:\n                flag = True\n                break\n        if flag:\n            continue\n\n        total_loss = torch.zeros(1).to(device)\n        for i in range(len(index)):\n            feature_s_left = list_feat_left[index[i][0]]\n            feature_t_left = list_feat_left[index[i][1]]\n            feature_s_right = list_feat_right[index[i][0]]\n            feature_t_right = list_feat_right[index[i][0]]\n            ytrue_s = list_ytrue[index[i][1]]\n            ytrue_t = list_ytrue[index[i][1]]\n            feature_all_left = torch.cat((feature_s_left, feature_t_left), 0)\n            feature_all_right = torch.cat((feature_s_right, feature_t_right), 0)\n            feature_all_left = feature_all_left.permute(1, 0, 2)\n            feature_all_right = feature_all_right.permute(1, 0, 2)\n            ytrue_all = torch.cat((ytrue_s, ytrue_t), 0)\n            ytrue_all = ytrue_all.permute(1, 0, 2)\n\n            pred_s, pred_t, out_weight_list_before, out_weight_list_after,decoder_att, loss_transfer = model.for_pre_train(\n                feature_all_left, feature_all_right, ytrue_all, teacher_forcing_ratio)\n            loss_s = criterion(pred_s, ytrue_s)\n            loss_t = criterion(pred_t, ytrue_t)\n            loss_l1 = criterion_1(pred_s, ytrue_s)\n            Loss_s, loss_shape_s, loss_temporal_s = Dilate_loss.dilate_loss(\n                pred_s, ytrue_s, alpha, beta, device)  ##在这里第一个是真实，第二个是预测\n            Loss_t, loss_shape_t, loss_temporal_t = Dilate_loss.dilate_loss(\n                pred_t, ytrue_t, alpha,beta, device)  ##在这里第一个是真实，第二个是预测\n\n            total_loss = total_loss + Loss_s + Loss_t + args.dw * loss_transfer\n        loss_all.append([total_loss.item(), (Loss_s + Loss_t).item(), loss_transfer.item()])\n        loss_1_all.append(loss_l1.item())\n        optimizer.zero_grad()\n        total_loss.backward()\n        torch.nn.utils.clip_grad_value_(model.parameters(), 3.)\n        optimizer.step()\n    loss = np.array(loss_all).mean(axis=0)\n    loss_l1 = np.array(loss_1_all).mean(axis=0)\n    return loss, loss_l1, out_weight_list_before, out_weight_list_after\n\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\ndef test_epoch(model, test_loader,teacher_forcing_ratio, batch, N_output,prefix='Test'):\n    model.eval()\n\n    total_loss = 0\n    total_loss_1 = 0\n    total_loss_r = 0\n    total_loss_dtw = 0\n    total_loss_tdi = 0\n    loss_dtw = 0\n    loss_tdi = 0\n    correct = 0\n    criterion = nn.MSELoss()\n    criterion_1 = nn.L1Loss()\n    for fea_left,fea_right, y_truth in tqdm(test_loader, desc=prefix, total=len(test_loader)):\n        fea_left, fea_right, y_truth = fea_left.to(device).float(),fea_right.to(device).float(),y_truth.to(device).float()\n        with torch.no_grad():\n            pred, atten = model.predict_ts(fea_left, fea_right,y_truth,teacher_forcing_ratio)\n        pred_t = pred.permute(1, 0, 2)\n        ran = pred_t.shape[1]\n        ##按照每一个批次求loss\n        for k in range(ran):\n            target = y_truth.permute(1, 0, 2)\n            target_m = target[:, k, :].view(-1).detach().cpu().numpy()\n            pred_y = pred.permute(1, 0, 2)\n            pred_m = pred_y[:, k, :].view(-1).detach().cpu().numpy()\n            # plot_result(pred_m, target_m)\n            fea_left_tensor = fea_left.permute(1, 0, 2)\n            fea_lt = fea_left_tensor[:, k, :]\n            fea_right_tensor = fea_right.permute(1, 0, 2)\n            fea_rt = fea_right_tensor[:, k, :].detach().cpu().numpy()\n            att_k = atten[:, k, :].detach().cpu().numpy()\n            # show_attention(fea_lt, fea_rt, pred_m, att_k)\n            # plt.show()\n            loss_dtw += dtw(target_m, pred_m)\n            path, sim = dtw_path(target_m, pred_m)\n            Dist = 0\n            for i, j in path:\n                Dist += (i - j) * (i - j)\n            loss_tdi += Dist / (N_output * N_output)\n        loss_dtw = loss_dtw / ran\n        loss_tdi = loss_tdi / ran\n        loss = criterion(pred, y_truth)\n        loss_r = torch.sqrt(loss)\n        loss_1 = criterion_1(pred, y_truth)\n\n        total_loss_tdi += loss_tdi\n        total_loss_dtw += loss_dtw\n        total_loss += loss.item()\n        total_loss_1 += loss_1.item()\n        total_loss_r += loss_r.item()\n\n    loss = total_loss / len(test_loader)\n    loss_1 = total_loss_1 / len(test_loader)\n    loss_r = total_loss_r / len(test_loader)\n    loss_tdis = total_loss_tdi / len(test_loader)\n    loss_dtws = total_loss_dtw / len(test_loader)\n    return loss, loss_1, loss_r, loss_dtws, loss_tdis\n\n\ndef test_epoch_inference(model, test_loader, batch, N_output, teacher_forcing_ratio, prefix='Test'):\n    model.eval()\n    total_loss = 0\n    total_loss_1 = 0\n    total_loss_r = 0\n    total_loss_dtw = 0\n    total_loss_tdi = 0\n    loss_dtw = 0\n    loss_tdi = 0\n    correct = 0\n    criterion = nn.MSELoss()\n    criterion_1 = nn.L1Loss()\n    i = 0\n    for fea_left, fea_right, y_truth in tqdm(test_loader, desc=prefix, total=len(test_loader)):\n        fea_left, fea_right, y_truth = fea_left.to(device).float(), fea_right.to(device).float(), y_truth.to(\n            device).float()\n        with torch.no_grad():\n            pred,atten = model.predict_ts(fea_left, fea_right, y_truth,teacher_forcing_ratio )\n        pred_t = pred.permute(1, 0, 2)\n        ran = pred_t.shape[1]\n        ##按照每一个批次求loss\n        for k in range(ran):\n            target = y_truth.permute(1, 0, 2)\n            target_m = target[:, k, :].view(-1).detach().cpu().numpy()\n            pred_y = pred.permute(1, 0, 2)\n            pred_m = pred_y[:, k, :].view(-1).detach().cpu().numpy()\n            # plot_result(pred_m, target_m)\n            fea_left_tensor = fea_left.permute(1, 0, 2)\n            fea_lt = fea_left_tensor[:, k, :]\n            fea_right_tensor = fea_right.permute(1, 0, 2)\n            fea_rt = fea_right_tensor[:, k, :].detach().cpu().numpy()\n            att_k = atten[:, k, :].detach().cpu().numpy()\n            # show_attention(fea_lt, fea_rt, pred_m, att_k)\n            # plt.show()\n            loss_dtw += dtw(target_m, pred_m)\n            path, sim = dtw_path(target_m, pred_m)\n            Dist = 0\n            for h, j in path:\n                Dist += (h - j) * (h - j)\n            loss_tdi += Dist / (N_output * N_output)\n        loss_dtw = loss_dtw / ran\n        loss_tdi = loss_tdi / ran\n        loss = criterion(pred, y_truth)\n        loss_r = torch.sqrt(loss)\n        loss_1 = criterion_1(pred, y_truth)\n        total_loss_tdi += loss_tdi\n        total_loss_dtw += loss_dtw\n        total_loss += loss.item()\n        total_loss_1 += loss_1.item()\n        total_loss_r += loss_r.item()\n\n        if y_truth.shape[0] == batch:\n            if i == 0:\n                y_list = y_truth.to(device).numpy()\n                predict_list = pred.to(device).numpy()\n            else:\n                y_list = np.hstack((y_list, y_truth.cpu().numpy()))\n                predict_list = np.hstack((predict_list, pred.cpu().numpy()))\n\n        i = i + 1\n    loss = total_loss / len(test_loader)\n    loss_1 = total_loss_1 / len(test_loader)\n    loss_r = total_loss_r / len(test_loader)\n    loss_tdis = total_loss_tdi / len(test_loader)\n    loss_dtws = total_loss_dtw / len(test_loader)\n    return loss, loss_1, loss_r,y_list, predict_list,loss_tdis,loss_dtws\n\n\ndef inference(model, data_loader, batch, N_output, teacher_forcing_ratio ):\n    loss, loss_1, loss_r, y_list, predict_list, loss_tdis,loss_dtws = test_epoch_inference(\n        model, data_loader, batch, N_output, teacher_forcing_ratio, prefix='Inference')\n    return loss, loss_1, loss_r, y_list, predict_list,loss_tdis,loss_dtws\n\n\ndef inference_all(output_path, model, model_path, loaders,batch, N_output, teacher_forcing_ratio):\n    pprint('inference...')\n    loss_list = []\n    loss_l1_list = []\n    loss_r_list = []\n    loss_dtw_list = []\n    loss_tdi_list = []\n    model.load_state_dict(torch.load(model_path))\n    i = 0\n    list_name = ['train', 'valid', 'test']\n    for loader in loaders:\n        loss, loss_1, loss_r, label_list, predict_list,loss_tdis,loss_dtws = inference(\n            model, loader,batch, N_output, teacher_forcing_ratio)\n        loss_list.append(loss)\n        loss_l1_list.append(loss_1)\n        loss_r_list.append(loss_r)\n        loss_dtw_list.append(loss_dtws)\n        loss_tdi_list.append(loss_tdis)\n        i = i + 1\n    return loss_list, loss_l1_list, loss_r_list, loss_dtw_list, loss_tdi_list\n\n\ndef transform_type(init_weight):\n    weight = torch.ones(args.num_layers, args.len_seq).to(device)##1行10列\n    for i in range(args.num_layers):\n        for j in range(args.len_seq):\n            weight[i, j] = init_weight[i][j].item()\n    return weight\n\ndef main_transfer(args):\n    print(args)\n\n    output_path = args.outdir + '_' + args.station + '_' + args.model_name + '_weather_' + \\\n                  args.loss_type + '_' + str(args.pre_epoch) + \\\n                  '_' + str(args.dw) + '_' + str(args.lr)\n    save_model_name = args.model_name + '_' + args.loss_type + \\\n                      '_' + str(args.dw) + '_' + str(args.lr) + '.pkl'\n    utils.dir_exist(output_path)\n    pprint('create loaders...')\n\n    train_loader_list, valid_loader, test_loader = data_process.load_weather_data_multi_domain(\n        args.data_path, args.batch_size, args.station, args.num_domain, args.data_mode)  ##进行了数据的分割，也就是数据的载入过程\n\n    args.log_file = os.path.join(output_path, 'run.log')\n    pprint('create model_king...')\n    ##模型部分\n\n    model = get_model(args.model_name)\n    num_model = count_parameters(model)\n    print('#model_king params:', num_model)\n\n    optimizer = optim.Adam(model.parameters(), lr=args.lr)  ##优化器的设置采用adam的优化器\n    animator = d2l.Animator(xlabel='epoch', ylabel='loss', xlim=[1, 200])\n    best_score = np.inf\n    best_epoch, stop_round = 0, 0\n\n    weight_mat_before, weight_mat_after, dist_mat_before, dist_mat_after = None, None, None, None\n    teacher_forcing_ratio=args.teacher_forcing_ratio\n    alpha = args.alpha\n    beta = args.beta\n    batch = args.batch_size\n    N_output = args.output_size\n\n    for epoch in range(args.n_epochs):\n        pprint('Epoch:', epoch)\n        pprint('training...')\n        if args.model_name in ['Boosting']:\n            loss, loss1, weight_mat_before, weight_mat_after, dist_mat_before, dist_mat_after = train_epoch_transfer_Boosting(\n                model, optimizer, train_loader_list, epoch, teacher_forcing_ratio,alpha,beta,dist_mat_before, dist_mat_after , weight_mat_before, weight_mat_after)\n        elif args.model_name in ['DualAdarnn']:\n            loss, loss1, weight_mat_before, weight_mat_after, dist_mat_before, dist_mat_after = train_DualRNN(\n                args, model, optimizer, train_loader_list, epoch,teacher_forcing_ratio, alpha, beta, dist_mat_before, dist_mat_after, weight_mat_before, weight_mat_after)\n        else:\n            print(\"error in model_name!\")\n        pprint(loss, loss1)\n\n        pprint('evaluating...')\n        train_loss, train_loss_l1, train_loss_r,train_loss_dtw, train_loss_tdi = test_epoch(\n            model, train_loader_list[0],teacher_forcing_ratio,batch,N_output, prefix='Train')\n        val_loss, val_loss_l1, val_loss_r, val_loss_dtw, val_loss_tdi = test_epoch(\n            model, valid_loader,teacher_forcing_ratio,batch,N_output, prefix='Valid')\n        test_loss, test_loss_l1, test_loss_r, test_loss_tdw, test_loss_tdi = test_epoch(\n            model, test_loader, teacher_forcing_ratio, batch,N_output, prefix='Test')\n\n        pprint('valid_l1 %.6f, test_l1 %.6f' %\n               (val_loss_l1, test_loss_l1))\n        pprint('valid_dtw %.6f, test_dtw %.6f' %\n               (val_loss_dtw, test_loss_tdw))\n\n        if val_loss < best_score:\n            best_score = val_loss\n            stop_round = 0\n            best_epoch = epoch\n            torch.save(model.state_dict(), os.path.join(\n                output_path, save_model_name))\n        else:\n            stop_round += 1\n            if stop_round >= args.early_stop:\n                pprint('early stop')\n                break\n\n    pprint('best val score:', best_score, '@', best_epoch)\n\n    loaders = train_loader_list[0], valid_loader, test_loader\n    loss_list, loss_l1_list, loss_r_list,loss_dtw_list, loss_tdi_list = inference_all(output_path, model, os.path.join(\n        output_path, save_model_name), loaders,batch,N_output, teacher_forcing_ratio)\n    pprint('MSE: train %.6f, valid %.6f, test %.6f' %\n           (loss_list[0], loss_list[1], loss_list[2]))\n    pprint('L1:  train %.6f, valid %.6f, test %.6f' %\n           (loss_l1_list[0], loss_l1_list[1], loss_l1_list[2]))\n    pprint('RMSE: train %.6f, valid %.6f, test %.6f' %\n           (loss_r_list[0], loss_r_list[1], loss_r_list[2]))\n    pprint('DTW: train %.6f, valid %.6f, test %.6f' %\n           (loss_dtw_list[0],loss_dtw_list[1], loss_dtw_list[2]))\n    pprint('TDI: train %.6f, valid %.6f, test %.6f' %\n           (loss_tdi_list[0], loss_tdi_list[1], loss_tdi_list[2]))\n    pprint('Finished.')\n\n\ndef get_args():\n    parser = argparse.ArgumentParser()\n\n    # model_king\n    ##share部分\n    parser.add_argument('--model_name', default='DualAdarnn')\n    parser.add_argument('--d_feat', type=int, default=17)  ##特征数\n    parser.add_argument('--hidden_size', type=int, default=64)\n    parser.add_argument('--num_layers', type=int, default=2)\n    parser.add_argument('--dropout', type=float, default=0.01)\n    parser.add_argument('--dec_layers', type=int, default=1)\n    parser.add_argument('--class_num', type=int, default=1)\n    parser.add_argument('--pre_epoch', type=int, default=5)  # 30, 40, 50\n\n    # training\n    parser.add_argument('--n_epochs', type=int, default=15)\n    parser.add_argument('--lr', type=float, default=5e-4)\n    parser.add_argument('--early_stop', type=int, default=10)\n    parser.add_argument('--smooth_steps', type=int, default=5)\n    parser.add_argument('--batch_size', type=int, default=24)  ##batch_size是分批\n    parser.add_argument('--dw', type=float, default=0.05)  # 0.05, 1.0, 5.0, 0.05\n    parser.add_argument('--loss_type', type=str, default='cosine')\n    parser.add_argument('--station', type=str, default='Jintang')\n    parser.add_argument('--data_mode', type=str,default='tdc')\n    parser.add_argument('--num_domain', type=int, default=3)\n    parser.add_argument('--len_seq', type=int, default=10)\n    parser.add_argument('--teacher_forcing_ratio', type=float, default=0.5)\n    parser.add_argument('--alpha', type=float, default=0.75)\n    parser.add_argument('--beta', type=float, default=0.05)\n    parser.add_argument('--output_size', type=int, default=6)\n\n    # other\n    parser.add_argument('--seed', type=int, default=10)\n    parser.add_argument('--data_path', default=r'/Volumes/王九和/科研/农业大数据相关/实验/实验程序/AdaRNN-BIT/weather_data')\n    parser.add_argument('--outdir', default='./outputs')\n    parser.add_argument('--overwrite', action='store_true')\n    parser.add_argument('--log_file', type=str, default='run.log')\n    parser.add_argument('--gpu_id', type=int, default=0)\n    parser.add_argument('--len_win', type=int, default=0)\n    args = parser.parse_args()\n\n    return args\n\n\nif __name__ == '__main__':\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    args = get_args()\n    np.random.seed(args.seed)\n    torch.manual_seed(args.seed)\n    torch.cuda.manual_seed_all(args.seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n    main_transfer(args)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/weather_traintro.py b/weather_traintro.py
--- a/weather_traintro.py	(revision 4d374eb052e73a15d49eb92596cef4473d6d2218)
+++ b/weather_traintro.py	(date 1649934013390)
@@ -20,7 +20,7 @@
 from tqdm import tqdm
 from untils import utils
 from model_Sept.Dual_Adarnn import Dual_Adarnn, Cross_Attention, Decoder, Share_Encoder
-import weather_data.data_TEM_test as data_process
+import weather_data.UTG_process as data_process
 import matplotlib.pyplot as plt
 from untils.support import *
 from d2l import torch as d2l
@@ -577,12 +577,12 @@
     parser.add_argument('--dropout', type=float, default=0.01)
     parser.add_argument('--dec_layers', type=int, default=1)
     parser.add_argument('--class_num', type=int, default=1)
-    parser.add_argument('--pre_epoch', type=int, default=5)  # 30, 40, 50
+    parser.add_argument('--pre_epoch', type=int, default=20)  # 30, 40, 50
 
     # training
-    parser.add_argument('--n_epochs', type=int, default=15)
+    parser.add_argument('--n_epochs', type=int, default=150)
     parser.add_argument('--lr', type=float, default=5e-4)
-    parser.add_argument('--early_stop', type=int, default=10)
+    parser.add_argument('--early_stop', type=int, default=60)
     parser.add_argument('--smooth_steps', type=int, default=5)
     parser.add_argument('--batch_size', type=int, default=24)  ##batch_size是分批
     parser.add_argument('--dw', type=float, default=0.05)  # 0.05, 1.0, 5.0, 0.05
@@ -592,8 +592,8 @@
     parser.add_argument('--num_domain', type=int, default=3)
     parser.add_argument('--len_seq', type=int, default=10)
     parser.add_argument('--teacher_forcing_ratio', type=float, default=0.5)
-    parser.add_argument('--alpha', type=float, default=0.75)
-    parser.add_argument('--beta', type=float, default=0.05)
+    parser.add_argument('--alpha', type=float, default=0.85)
+    parser.add_argument('--beta', type=float, default=0.01)
     parser.add_argument('--output_size', type=int, default=6)
 
     # other
